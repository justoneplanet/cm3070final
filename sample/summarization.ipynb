{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mac OS\n",
    "# %pip install -U tensorflow==2.16.2 tensorflow-macos==2.16.2 keras==3.4.1 keras-nlp\n",
    "# For AWS SageMaker\n",
    "# %%pip install -U tensorflow==2.16.2 tensorflow-datasets keras==3.4.1 keras-nlp datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 2.16.2 is expected. The running version is 2.16.2\n",
      "Keras 3.4.1 is expected. The running version is 3.4.1\n",
      "KerasNLP 0.12.1 is expected. The running version is 0.12.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_nlp\n",
    "print(\"Tensorflow 2.16.2 is expected. The running version is\", tf.__version__)\n",
    "print(\"Keras 3.4.1 is expected. The running version is\", keras.__version__)\n",
    "print(\"KerasNLP 0.12.1 is expected. The running version is\", keras_nlp.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "# SageMaker cannot use @keras.saving\n",
    "from keras import saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "def is_running_on_apple_sillicon():\n",
    "    return platform.system() == \"Darwin\" and platform.processor() == \"arm\"\n",
    "\n",
    "DEVELOPMENT = is_running_on_apple_sillicon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(history, title=None, keys=[\"loss\", \"masked_acc\"]):\n",
    "    \"\"\"\n",
    "    Display the plot that indicates the loss and accuracy.\n",
    "    :param history: history object from the tensorflow fit function.\n",
    "    :param title: title text.\n",
    "    :param keys: keys for plotting.\n",
    "    \"\"\"\n",
    "    flg, axes = plt.subplots(1, 2, tight_layout=True)\n",
    "    if title is not None:\n",
    "        flg.suptitle(t=title, fontsize=14)\n",
    "    for i, key in enumerate(keys):\n",
    "        value = history.history[key]\n",
    "        val_loss = history.history[f\"val_{key}\"]\n",
    "        epochs = range(1, len(value) + 1)\n",
    "        axes[i].plot(epochs, value, label=f\"Training {key}\")\n",
    "        axes[i].plot(epochs, val_loss, label=f\"Validation {key}\")\n",
    "        axes[i].set_title(f\"Training and validation {key}\")\n",
    "        axes[i].set_xlabel(\"epochs\")\n",
    "        axes[i].set_ylabel(key)\n",
    "        axes[i].legend()\n",
    "    plt.show()\n",
    "\n",
    "    for key in keys:\n",
    "        if 'loss' in key:\n",
    "            print(\n",
    "                np.min(history.history[f\"val_{key}\"]),\n",
    "                \"The best number of epocs for the validation loss is\",\n",
    "                np.argmin(history.history[f\"val_{key}\"]) + 1,\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                np.max(history.history[f\"val_{key}\"]),\n",
    "                \"The best number of epocs for the validation accuracy is\",\n",
    "                np.argmax(history.history[f\"val_{key}\"]) + 1,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://github.com/keras-team/keras-nlp/blob/50e041487b1d8b30b34c5fb738db3ed3406363bc/examples/machine_translation/data.py\n",
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase,\n",
    "        \"[%s]\" % re.escape(strip_chars),\n",
    "        \"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "@saving.register_keras_serializable()\n",
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "        # nn.py:609: UserWarning:\n",
    "        # \"`sparse_categorical_crossentropy` received `from_logits=True`,\n",
    "        # but the `output` argument was produced by a Softmax activation and thus does not represent logits.\n",
    "        # Was this intended?\n",
    "        # When logits is True, softmax activation function has not processed the values.\n",
    "        # from_logits=True,\n",
    "        reduction='none'\n",
    "    )\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "# def masked_acc(y_true, y_pred):\n",
    "#     # Calculate the loss for each item in the batch.\n",
    "#     y_pred = tf.argmax(y_pred, axis=-1)\n",
    "#     y_pred = tf.cast(y_pred, dtype=y_true.dtype)\n",
    "#     match = tf.cast(y_true == y_pred, dtype=tf.float32)\n",
    "#     mask = tf.cast(y_true != 0, dtype=tf.float32)\n",
    "#     return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "# @see https://www.tensorflow.org/text/tutorials/transformer\n",
    "@saving.register_keras_serializable()\n",
    "def masked_acc(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=2)\n",
    "    y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "    match = y_true == y_pred\n",
    "    mask = y_true != 0\n",
    "    match = match & mask\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets():\n",
    "    if is_running_on_apple_sillicon():\n",
    "        args = {\n",
    "            'trust_remote_code': False,\n",
    "        }\n",
    "    else:\n",
    "        \"\"\"\n",
    "        When 'trust_remote_code' is False, it does not work on AWS SageMaker.\n",
    "        \"\"\"\n",
    "        args = {\n",
    "        }\n",
    "    train_ds, validation_ds, test_ds = tfds.load(\n",
    "        'huggingface:ccdv__cnn_dailymail/3.0.0',\n",
    "        split=['train', 'validation', 'test'],\n",
    "        builder_kwargs=args,\n",
    "    )\n",
    "    # for development with 1/10 entries\n",
    "    if DEVELOPMENT:\n",
    "        train_size = len(train_ds) // 10 * 9\n",
    "        validation_size = len(validation_ds) // 10 * 9\n",
    "        test_size = len(test_ds) // 10 * 9\n",
    "        train_ds = train_ds.skip(train_size)\n",
    "        validation_ds = validation_ds.skip(validation_size)\n",
    "        test_ds = test_ds.skip(test_size)\n",
    "    return train_ds, validation_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tokenizer(\n",
    "        train_ds,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length,\n",
    "        max_tokens=15000):\n",
    "    \"\"\"\n",
    "    Display the plot that indicates the loss and accuracy.\n",
    "    :param train_ds: training dataset to obtain vocabulary.\n",
    "    :param max_tokens: In other words, this is the vocabulary size.\n",
    "    :param encoder_sequence_length: The sequence length for input.\n",
    "    :param input_output_sequence_length: The sequence length for target.\n",
    "    \"\"\"\n",
    "    vectorization_layer = keras.layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_tokens,\n",
    "        output_mode='int',\n",
    "        ragged=True,\n",
    "    )\n",
    "    # Warning: adapt, which clear the already held data inside, must be called only once.\n",
    "    vectorization_layer.adapt(train_ds.map(lambda row: '[start] ' + row['article'] + ' ' + row['highlights'] + ' [end]'))\n",
    "    vocabulary = vectorization_layer.get_vocabulary()\n",
    "\n",
    "    input_vectorization_layer = keras.layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_tokens,\n",
    "        output_mode='int',\n",
    "        # @TODO This should be programmatically obtained\n",
    "        output_sequence_length=encoder_sequence_length,\n",
    "    )\n",
    "    target_vectorization_layer = keras.layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_tokens,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=decoder_sequence_length,\n",
    "    )\n",
    "    input_vectorization_layer.set_vocabulary(vocabulary)\n",
    "    target_vectorization_layer.set_vocabulary(vocabulary)\n",
    "    return vectorization_layer, input_vectorization_layer, target_vectorization_layer\n",
    "\n",
    "def build_datasets(\n",
    "        train_ds, validation_ds, test_ds,\n",
    "        input_vectorization_layer,\n",
    "        vectorization_layer,\n",
    "        batch_size,\n",
    "        decoder_sequence_length):\n",
    "    \"\"\"\n",
    "    vectorization_layer(['This is a pen', 'I am a software engineer'])\n",
    "    #vectorization_layer(['This is a pen', 'I am a software engineer']).row_lengths().shape[0]\n",
    "    # 2\n",
    "    rows = vectorization_layer(['This is a pen', 'I am a software engineer']).row_lengths().shape[0]\n",
    "    vectorization_layer(['This is a pen', 'I am a software engineer']).to_tensor(shape=(rows, 10))\n",
    "    # .to_tensor()\n",
    "\n",
    "    RaggedTensor.to_tensor can make 0-filled Tensor\n",
    "    \"\"\"\n",
    "    def format_dataset(x):\n",
    "        # decoder_sequence_length: either the following 2.\n",
    "        # - decoder input: [start] + sentence\n",
    "        # - decoder output: sentence + [end]\n",
    "        # That is, decoder_sequence_length = sentence length + 1\n",
    "        summarized_text_length = decoder_sequence_length - 1\n",
    "        article = input_vectorization_layer(x['article'])\n",
    "        highlights = tf.strings.join(['[start] ', x['highlights'], ' [end]'])\n",
    "        h = vectorization_layer(highlights)\n",
    "        rows = h.row_lengths().shape[0]\n",
    "        sequences = h.to_tensor(shape=(rows, summarized_text_length + 1 + 1)) # start + sentence + end\n",
    "        highlights_decoder_input = sequences[:, :-1] # start + sentence\n",
    "        highlights_decoder_output = sequences[:, 1:] # sentence + end\n",
    "        return (\n",
    "            (\n",
    "                article, # encoder input\n",
    "                highlights_decoder_input, # decoder input\n",
    "            ),\n",
    "            highlights_decoder_output, # decoder output\n",
    "        )\n",
    "    train_ds = train_ds.batch(batch_size).map(format_dataset)\n",
    "    validation_ds = validation_ds.batch(batch_size).map(format_dataset)\n",
    "    test_ds = test_ds.batch(batch_size).map(format_dataset)\n",
    "    return train_ds, validation_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@saving.register_keras_serializable()\n",
    "class TransformerEncoderDecoderModel(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_tokenizer,\n",
    "        decoder_tokenizer,\n",
    "        num_encoders,\n",
    "        num_decoders,\n",
    "        num_heads,\n",
    "        transformer_intermediate_dim,\n",
    "        encoder_vocabulary_size,\n",
    "        decoder_vocabulary_size,\n",
    "        embedding_dim,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length,\n",
    "        **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoders = []\n",
    "        self.decoders = []\n",
    "        for _ in range(num_encoders):\n",
    "            self.encoders.append(\n",
    "                keras_nlp.layers.TransformerEncoder(\n",
    "                    num_heads=num_heads,\n",
    "                    intermediate_dim=transformer_intermediate_dim,\n",
    "                )\n",
    "            )\n",
    "        for _ in range(num_decoders):\n",
    "            self.decoders.append(\n",
    "                keras_nlp.layers.TransformerDecoder(\n",
    "                    num_heads=num_heads,\n",
    "                    intermediate_dim=transformer_intermediate_dim,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.encoder_tokenizer = encoder_tokenizer\n",
    "        self.decoder_tokenizer = decoder_tokenizer\n",
    "\n",
    "        self.encoder_embedding = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "            vocabulary_size=encoder_vocabulary_size,\n",
    "            sequence_length=encoder_sequence_length,\n",
    "            embedding_dim=embedding_dim,\n",
    "            mask_zero=True,\n",
    "        )\n",
    "\n",
    "        self.decoder_embedding = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "            vocabulary_size=decoder_vocabulary_size,\n",
    "            sequence_length=decoder_sequence_length,\n",
    "            embedding_dim=embedding_dim,\n",
    "            mask_zero=True,\n",
    "        )\n",
    "\n",
    "        self.dense = keras.layers.Dense(\n",
    "            decoder_vocabulary_size,\n",
    "            activation=\"softmax\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_input, decoder_input = (\n",
    "            inputs[0],\n",
    "            inputs[1],\n",
    "        )\n",
    "        encoded = self.encoder_embedding(encoder_input)\n",
    "        for encoder in self.encoders:\n",
    "            encoded = encoder(inputs=encoded)\n",
    "\n",
    "        decoded = self.decoder_embedding(decoder_input)\n",
    "        for decoder in self.decoders:\n",
    "            decoded = decoder(\n",
    "                decoder_sequence=decoded,\n",
    "                encoder_sequence=encoded,\n",
    "                use_causal_mask=True,\n",
    "            )\n",
    "\n",
    "        output = self.dense(decoded)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \"encoder_tokenizer\": self.encoder_tokenizer.get_config(),\n",
    "            \"decoder_tokenizer\": self.decoder_tokenizer.get_config(),\n",
    "            \"num_encoders\": len(self.encoders),\n",
    "            \"num_decoders\": len(self.decoders),\n",
    "            \"num_heads\": self.encoders[0].num_heads,\n",
    "            \"transformer_intermediate_dim\": self.encoders[0].intermediate_dim,\n",
    "            \"encoder_vocabulary_size\": self.encoder_embedding.vocabulary_size,\n",
    "            \"decoder_vocabulary_size\": self.decoder_embedding.vocabulary_size,\n",
    "            \"embedding_dim\": self.encoder_embedding.embedding_dim,\n",
    "            \"encoder_sequence_length\": self.encoder_embedding.encoder_sequence_length,\n",
    "            \"decoder_sequence_length\": self.encoder_embedding.decoder_sequence_length,\n",
    "        })\n",
    "        return config\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        encoder_tokenizer_config = config.pop(\"encoder_tokenizer\")\n",
    "        decoder_tokenizer_config = config.pop(\"decoder_tokenizer\")\n",
    "        encoder_tokenizer = keras.layers.TextVectorization.from_config(encoder_tokenizer_config)\n",
    "        decoder_tokenizer = keras.layers.TextVectorization.from_config(decoder_tokenizer_config)\n",
    "        return cls(encoder_tokenizer=encoder_tokenizer, decoder_tokenizer=decoder_tokenizer, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "        model,\n",
    "        train_ds,\n",
    "        validation_ds,\n",
    "        initial_learning_rate,\n",
    "        decay_steps,\n",
    "        decay_rate,\n",
    "        epochs,\n",
    "        steps_per_epoch):\n",
    "    if decay_rate < 1.0:\n",
    "        learning_rate = keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=initial_learning_rate,\n",
    "            decay_steps=decay_steps,\n",
    "            decay_rate=decay_rate,\n",
    "        )\n",
    "    else:\n",
    "        learning_rate = initial_learning_rate\n",
    "    if f\"{keras.__version__}\".startswith(\"2.\") and is_running_on_apple_sillicon():\n",
    "        optimizer = keras.optimizers.legacy.Adam(\n",
    "            learning_rate=learning_rate,\n",
    "        )\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate,\n",
    "        )\n",
    "    if f\"{keras.__version__}\".startswith(\"2.\"):\n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "            reduction=keras.losses.Reduction.NONE\n",
    "        )\n",
    "    else:\n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "            reduction=None\n",
    "        )\n",
    "    metrics = [\n",
    "        masked_acc,\n",
    "        #keras.metrics.SparseCategoricalAccuracy(),\n",
    "        #keras_nlp.metrics.Bleu(), #  This cannot be used here\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "        loss=masked_loss,\n",
    "        weighted_metrics=[],\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_ds,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "    )\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "        train_ds, validation_ds, test_ds,\n",
    "        num_encoders,\n",
    "        num_decoders,\n",
    "        num_heads,\n",
    "        transformer_intermediate_dim,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length,\n",
    "        vocab_size,\n",
    "        batch_size,\n",
    "        embedding_dim,\n",
    "        initial_learning_rate,\n",
    "        decay_steps,\n",
    "        decay_rate,\n",
    "        epochs,\n",
    "        steps_per_epoch):\n",
    "    vectorization_layer, input_vectorization_layer, target_vectorization_layer = prepare_tokenizer(\n",
    "        train_ds=train_ds,\n",
    "        encoder_sequence_length=encoder_sequence_length,\n",
    "        decoder_sequence_length=decoder_sequence_length,\n",
    "        max_tokens=vocab_size,\n",
    "    )\n",
    "    train_ds, validation_ds, test_ds = build_datasets(\n",
    "        train_ds=train_ds,\n",
    "        validation_ds=validation_ds,\n",
    "        test_ds=test_ds,\n",
    "        input_vectorization_layer=input_vectorization_layer,\n",
    "        vectorization_layer=vectorization_layer,\n",
    "        batch_size=batch_size,\n",
    "        decoder_sequence_length=decoder_sequence_length,\n",
    "    )\n",
    "\n",
    "    input_vocab_size = input_vectorization_layer.vocabulary_size()\n",
    "    target_vocab_size = target_vectorization_layer.vocabulary_size()\n",
    "    model = TransformerEncoderDecoderModel(\n",
    "        encoder_tokenizer=input_vectorization_layer,\n",
    "        decoder_tokenizer=target_vectorization_layer,\n",
    "        num_encoders=num_encoders,\n",
    "        num_decoders=num_decoders,\n",
    "        num_heads=num_heads,\n",
    "        transformer_intermediate_dim=transformer_intermediate_dim,\n",
    "        encoder_vocabulary_size=input_vocab_size,\n",
    "        decoder_vocabulary_size=target_vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        encoder_sequence_length=encoder_sequence_length,\n",
    "        decoder_sequence_length=decoder_sequence_length,\n",
    "    )\n",
    "\n",
    "    history = run_training(\n",
    "        model,\n",
    "        train_ds=train_ds,\n",
    "        validation_ds=validation_ds,\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "    )\n",
    "\n",
    "    if is_running_on_apple_sillicon():\n",
    "        filepath = 'summarization_model.keras/summarization_model.keras'\n",
    "    else:\n",
    "        filepath = 'summarization_model.keras'\n",
    "    print(f\"Saving to {filepath}\")\n",
    "    model.save(filepath=filepath)\n",
    "\n",
    "    print(f\"Successfully saved model to {filepath}\")\n",
    "    return model, filepath, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = [\n",
    "    \"\"\"(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men\\'s 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles. The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital. \"I\\'m proud of myself and I\\'ll continue to work to dominate for as long as possible,\" Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics. Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems. Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt. Earlier, Jamaica\\'s women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds. Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover. The British quartet, who were initially fourth, were promoted to the bronze which eluded their men\\'s team. Fraser-Pryce, like Bolt aged 26, became the first woman to achieve three golds in the 100-200 and the relay. In other final action on the last day of the championships, France\\'s Teddy Tamgho became the third man to leap over 18m in the triple jump, exceeding the mark by four centimeters to take gold. Germany\\'s Christina Obergfoll finally took gold at global level in the women\\'s javelin after five previous silvers, while Kenya\\'s Asbel Kiprop easily won a tactical men\\'s 1500m final. Kiprop\\'s compatriot Eunice Jepkoech Sum was a surprise winner of the women\\'s 800m. Bolt\\'s final dash for golden glory brought the eight-day championship to a rousing finale, but while the hosts topped the medal table from the United States there was criticism of the poor attendances in the Luzhniki Stadium. There was further concern when their pole vault gold medalist Yelena Isinbayeva made controversial remarks in support of Russia\\'s new laws, which make \"the propagandizing of non-traditional sexual relations among minors\" a criminal offense. She later attempted to clarify her comments, but there were renewed calls by gay rights groups for a boycott of the 2014 Winter Games in Sochi, the next major sports event in Russia.\"\"\",\n",
    "    \"\"\"Vice President Dick Cheney will serve as acting president briefly Saturday while President Bush is anesthetized for a routine colonoscopy, White House spokesman Tony Snow said Friday. Bush is scheduled to have the medical procedure, expected to take about 2 1/2 hours, at the presidential retreat at Camp David, Maryland, Snow said. Bush's last colonoscopy was in June 2002, and no abnormalities were found, Snow said. The president's doctor had recommended a repeat procedure in about five years. The procedure will be supervised by Dr. Richard Tubb and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, Snow said. A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic. Small polyps may be removed during the procedure. Snow said that was the case when Bush had colonoscopies before becoming president. Snow himself is undergoing chemotherapy for cancer that began in his colon and spread to his liver. Snow told reporters he had a chemo session scheduled later Friday. Watch Snow talk about Bush's procedure and his own colon cancer » . \"The president wants to encourage everybody to use surveillance,\" Snow said. The American Cancer Society recommends that people without high-risk factors or symptoms begin getting screened for signs of colorectal cancer at age 50. E-mail to a friend .\"\"\",\n",
    "    \"There are two chickens in the garden.\",\n",
    "    \"Two chickens fell into the swimming pool in the garden.\",\n",
    "]\n",
    "\n",
    "def decode_sequence(input_sentence, model, max_sequence_length, lookup_table):\n",
    "    encoder_tokenizer = model.encoder_tokenizer\n",
    "    decoder_tokenizer = model.decoder_tokenizer\n",
    "    tokenized_input = encoder_tokenizer([input_sentence])\n",
    "\n",
    "    start_token = decoder_tokenizer(\"[start]\")[0].numpy()\n",
    "    end_token = decoder_tokenizer(\"[end]\")[0].numpy()\n",
    "\n",
    "    decoded_sentence = [start_token]\n",
    "    for i in range(max_sequence_length):\n",
    "        decoder_inputs = tf.convert_to_tensor(\n",
    "            [decoded_sentence],\n",
    "            dtype=\"int64\",\n",
    "        )\n",
    "        decoder_inputs = tf.concat(\n",
    "            [\n",
    "                decoder_inputs,\n",
    "                tf.zeros(\n",
    "                    [1, max_sequence_length - i - 1],\n",
    "                    dtype=\"int64\",\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        input = {\n",
    "            \"encoder_inputs\": tokenized_input,\n",
    "            \"decoder_inputs\": decoder_inputs,\n",
    "        }\n",
    "        predictions = model(input)\n",
    "        predicted_token = np.argmax(predictions[0, i, :])\n",
    "        decoded_sentence.append(predicted_token)\n",
    "        if predicted_token == end_token:\n",
    "            break\n",
    "\n",
    "    detokenized_output = []\n",
    "    for token in decoded_sentence:\n",
    "        detokenized_output.append(lookup_table[token])\n",
    "    return \" \".join(detokenized_output)\n",
    "\n",
    "\n",
    "def predict_main(filepath, examples, decoder_sequence_length):\n",
    "    loaded_model = keras.models.load_model(filepath)\n",
    "\n",
    "    decoder_tokenizer = loaded_model.decoder_tokenizer\n",
    "    vocab = decoder_tokenizer.get_vocabulary()\n",
    "    index_lookup_table = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "    summarized = []\n",
    "    for example in examples:\n",
    "        summarized.append(\n",
    "            decode_sequence(\n",
    "                example,\n",
    "                loaded_model,\n",
    "                decoder_sequence_length,\n",
    "                index_lookup_table,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        print(\"ORIGINAL SENTENCE: \", examples[i])\n",
    "        print(\"SUMMARIZED RESULT: \", summarized[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builders/huggingface_dataset_builder.py:160: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
      "  hf_names = hf_datasets.list_datasets()\n",
      "2024-07-03 00:17:04.687845: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-07-03 00:17:04.687868: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-07-03 00:17:04.687872: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-07-03 00:17:04.687890: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-03 00:17:04.687903: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_ds, validation_ds, test_ds = prepare_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# development params\n",
    "# Epoch 24/50 - loss: 0.1224 - sparse_categorical_accuracy: 0.8007 - val_loss: 0.8010 - val_sparse_categorical_accuracy: 0.5755\n",
    "LEARNING_RATE = 0.001\n",
    "# It has been found out that the validation accuracy of this model turns to increasing within 20 epochs.\n",
    "NUM_EPOCHS = 1\n",
    "STEPS_PER_EPOCH = None\n",
    "ENCODER_SEQUENCE_LENGTH = 2137 # @TODO The followings should programmatically be derived.\n",
    "DECODER_SEQUENCE_LENGTH = 256 #  1437 is the longest summarized text in dataset\n",
    "VOCABULARY_SIZE = 15000\n",
    "BATCH_SIZE = 16\n",
    "NUM_ENCODERS = 1\n",
    "NUM_DECODERS = 1\n",
    "NUM_HEADS = 6\n",
    "INTERMIDIATE_DIM = 512\n",
    "EMBEDDING_DIM = 64\n",
    "DECAY_STEPS = 100\n",
    "DECAY_RATE = 1.0\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    train_ds, validation_ds, test_ds,\n",
    "    num_encoders=NUM_ENCODERS,\n",
    "    num_decoders=NUM_DECODERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    transformer_intermediate_dim=INTERMIDIATE_DIM,\n",
    "    encoder_sequence_length=ENCODER_SEQUENCE_LENGTH,\n",
    "    decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCABULARY_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=DECAY_STEPS,\n",
    "    decay_rate=DECAY_RATE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    ")\n",
    "plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum viable params\n",
    "# Epoch 24/50 - loss: 0.1224 - sparse_categorical_accuracy: 0.8007 - val_loss: 0.8010 - val_sparse_categorical_accuracy: 0.5755\n",
    "LEARNING_RATE = 0.001\n",
    "# It has been found out that the validation accuracy of this model turns to increasing within 20 epochs.\n",
    "NUM_EPOCHS = 20\n",
    "STEPS_PER_EPOCH = None\n",
    "ENCODER_SEQUENCE_LENGTH = 2137 # @TODO The followings should programmatically be derived.\n",
    "DECODER_SEQUENCE_LENGTH = 256 #  1437 is the longest summarized text in dataset\n",
    "VOCABULARY_SIZE = 15000\n",
    "BATCH_SIZE = 64\n",
    "NUM_ENCODERS = 1\n",
    "NUM_DECODERS = 1\n",
    "NUM_HEADS = 6\n",
    "INTERMIDIATE_DIM = 512\n",
    "EMBEDDING_DIM = 64\n",
    "DECAY_STEPS = 100\n",
    "DECAY_RATE = 1.0\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    train_ds, validation_ds, test_ds,\n",
    "    num_encoders=NUM_ENCODERS,\n",
    "    num_decoders=NUM_DECODERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    transformer_intermediate_dim=INTERMIDIATE_DIM,\n",
    "    encoder_sequence_length=ENCODER_SEQUENCE_LENGTH,\n",
    "    decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCABULARY_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=DECAY_STEPS,\n",
    "    decay_rate=DECAY_RATE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    ")\n",
    "plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default params\n",
    "FLAGS_learning_rate = 0.001\n",
    "FLAGS_num_epochs = 50 # default=1, but too small\n",
    "FLAGS_steps_per_epoch = None\n",
    "FLAGS_sequence_length = 20 # Input and output sequence length.\n",
    "FLAGS_vocab_size = 15000 # Vocabulary size, required by tokenizer.\n",
    "FLAGS_batch_size = 64\n",
    "FLAGS_num_encoders = 2\n",
    "FLAGS_num_decoders = 2\n",
    "FLAGS_num_heads = 8 # Number of head of the multihead attention.\n",
    "FLAGS_intermediate_dim = 128 # Intermediate dimension (feedforward network) of transformer.\n",
    "FLAGS_model_dim = 64\n",
    "FLAGS_decay_steps = 20\n",
    "FLAGS_decay_rate = 0.98\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    train_ds, validation_ds, test_ds,\n",
    "    num_encoders=NUM_ENCODERS,\n",
    "    num_decoders=NUM_DECODERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    transformer_intermediate_dim=INTERMIDIATE_DIM,\n",
    "    encoder_sequence_length=ENCODER_SEQUENCE_LENGTH,\n",
    "    decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCABULARY_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=DECAY_STEPS,\n",
    "    decay_rate=DECAY_RATE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    ")\n",
    "plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
