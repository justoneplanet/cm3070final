{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras-nlp/example/machine_translation\n",
    "\n",
    "- https://github.com/keras-team/keras-nlp/tree/master/examples/machine_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Copyright 2023 The KerasNLP Authors\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.15.1\n",
      "  Using cached tensorflow-2.15.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting tensorflow-macos==2.15.1\n",
      "  Using cached tensorflow_macos-2.15.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.4 kB)\n",
      "Collecting keras==2.15.0\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (16.0.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.3.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.26.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (4.11.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.56.0)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n",
      "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.19.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.30.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\n",
      "Using cached tensorflow-2.15.1-cp310-cp310-macosx_12_0_arm64.whl (205.7 MB)\n",
      "Using cached tensorflow_macos-2.15.1-cp310-cp310-macosx_12_0_arm64.whl (2.2 kB)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: keras, tensorboard, tensorflow, tensorflow-macos\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.4.1\n",
      "    Uninstalling keras-3.4.1:\n",
      "      Successfully uninstalled keras-3.4.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.2\n",
      "    Uninstalling tensorflow-2.16.2:\n",
      "      Successfully uninstalled tensorflow-2.16.2\n",
      "  Attempting uninstall: tensorflow-macos\n",
      "    Found existing installation: tensorflow-macos 2.16.2\n",
      "    Uninstalling tensorflow-macos-2.16.2:\n",
      "      Successfully uninstalled tensorflow-macos-2.16.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.15.0 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-macos-2.15.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# The hyperparameters, especially of the optimizer, seem picky.\n",
    "# Currently, only the following versions go well only on mac with RMSprop.\n",
    "%pip install -U tensorflow==2.15.1 tensorflow-macos==2.15.1 keras==2.15.0\n",
    "#%pip install keras-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version can not use keras.optimizers.legacy.RMSprop.\n",
    "# And the model does not converge.\n",
    "%pip install -U tensorflow==2.16.2 tensorflow-macos==2.16.2 keras==3.4.1\n",
    "#%pip install keras-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "2.15.1\n",
      "2.15.0\n",
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_nlp\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "def is_running_on_apple_sillicon():\n",
    "    return platform.system() == \"Darwin\" and platform.processor() == \"arm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker cannot use @keras.saving\n",
    "from keras import saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(history, title=None):\n",
    "    \"\"\"\n",
    "    Display the plot that indicates the loss and accuracy.\n",
    "    :param history: history object from the tensorflow fit function.\n",
    "    :param title: title text.\n",
    "    \"\"\"\n",
    "    flg, axes = plt.subplots(1, 2, tight_layout=True)\n",
    "    if title is not None:\n",
    "        flg.suptitle(t=title, fontsize=14)\n",
    "    for i, key in enumerate([\"loss\", \"accuracy\"]):\n",
    "        value = history.history[key]\n",
    "        val_loss = history.history[f\"val_{key}\"]\n",
    "        epochs = range(1, len(value) + 1)\n",
    "        axes[i].plot(epochs, value, label=f\"Training {key}\")\n",
    "        axes[i].plot(epochs, val_loss, label=f\"Validation {key}\")\n",
    "        axes[i].set_title(f\"Training and validation {key}\")\n",
    "        axes[i].set_xlabel(\"epochs\")\n",
    "        axes[i].set_ylabel(key)\n",
    "        axes[i].legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(\n",
    "        np.min(history.history[\"val_loss\"]),\n",
    "        \"The best number of epocs for the validation loss is\",\n",
    "        np.argmin(history.history[\"val_loss\"]) + 1,\n",
    "    )\n",
    "    print(\n",
    "        np.max(history.history[\"val_accuracy\"]),\n",
    "        \"The best number of epocs for the validation accuracy is\",\n",
    "        np.argmax(history.history[\"val_accuracy\"]) + 1,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True,\n",
    "        reduction='none'\n",
    "    )\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "# def masked_acc(y_true, y_pred):\n",
    "#     # Calculate the loss for each item in the batch.\n",
    "#     y_pred = tf.argmax(y_pred, axis=-1)\n",
    "#     y_pred = tf.cast(y_pred, dtype=y_true.dtype)\n",
    "#     match = tf.cast(y_true == y_pred, dtype=tf.float32)\n",
    "#     mask = tf.cast(y_true != 0, dtype=tf.float32)\n",
    "#     return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "# @see https://www.tensorflow.org/text/tutorials/transformer\n",
    "def masked_acc(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=2)\n",
    "    y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "    match = y_true == y_pred\n",
    "    mask = y_true != 0\n",
    "    match = match & mask\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    text_file = keras.utils.get_file(\n",
    "        fname=\"spa-eng.zip\",\n",
    "        origin=(\n",
    "            \"http://storage.googleapis.com/download.tensorflow.org/data/\"\n",
    "            + \"spa-eng.zip\"\n",
    "        ),\n",
    "        extract=True,\n",
    "    )\n",
    "    return pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\"\n",
    "\n",
    "\n",
    "def read_data(filepath):\n",
    "    with open(filepath) as f:\n",
    "        lines = f.read().split(\"\\n\")[:-1]\n",
    "        text_pairs = []\n",
    "        for line in lines:\n",
    "            eng, spa = line.split(\"\\t\")\n",
    "            spa = \"[start] \" + spa + \" [end]\"\n",
    "            text_pairs.append((eng, spa))\n",
    "    return text_pairs\n",
    "\n",
    "\n",
    "def split_train_val_test(text_pairs):\n",
    "    random.shuffle(text_pairs)\n",
    "    num_val_samples = int(0.15 * len(text_pairs))\n",
    "    num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "    train_pairs = text_pairs[:num_train_samples]\n",
    "    val_end_index = num_train_samples + num_val_samples\n",
    "    val_pairs = text_pairs[num_train_samples:val_end_index]\n",
    "    test_pairs = text_pairs[val_end_index:]\n",
    "    return train_pairs, val_pairs, test_pairs\n",
    "\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase,\n",
    "        \"[%s]\" % re.escape(strip_chars),\n",
    "        \"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_tokenizer(train_pairs, sequence_length, vocab_size):\n",
    "    \"\"\"Preapare English and Spanish tokenizer.\"\"\"\n",
    "    eng_tokenizer = keras.layers.TextVectorization(\n",
    "        max_tokens=vocab_size,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "    )\n",
    "    spa_tokenizer = keras.layers.TextVectorization(\n",
    "        max_tokens=vocab_size,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length + 1,\n",
    "        standardize=custom_standardization,\n",
    "    )\n",
    "    eng_texts, spa_texts = zip(*train_pairs)\n",
    "    eng_tokenizer.adapt(eng_texts)\n",
    "    spa_tokenizer.adapt(spa_texts)\n",
    "    return eng_tokenizer, spa_tokenizer\n",
    "\n",
    "\n",
    "def prepare_datasets(text_pairs, batch_size, eng_tokenizer, spa_tokenizer):\n",
    "    \"\"\"Transform raw text pairs to tf datasets.\"\"\"\n",
    "    eng_texts, spa_texts = zip(*text_pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "\n",
    "    def format_dataset(eng, spa):\n",
    "        \"\"\"Format the dataset given input English and Spanish text.\n",
    "\n",
    "        The output format is:\n",
    "            x: a pair of English and Spanish sentence.\n",
    "            y: The Spanish sentence in x shifts 1 token towards right, because\n",
    "                we are predicting the next token.\n",
    "        \"\"\"\n",
    "        eng = eng_tokenizer(eng)\n",
    "        spa = spa_tokenizer(spa)\n",
    "        return (\n",
    "            {\n",
    "                \"encoder_inputs\": eng,\n",
    "                \"decoder_inputs\": spa[:, :-1],\n",
    "            },\n",
    "            spa[:, 1:],\n",
    "            tf.cast((spa[:, 1:] != 0), \"float32\"),  # mask as sample weights\n",
    "        )\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "\n",
    "def get_dataset_and_tokenizer(sequence_length, vocab_size, batch_size):\n",
    "    \"\"\"Main method to get the formatted machine translation dataset.\"\"\"\n",
    "    filepath = download_data()\n",
    "    text_pairs = read_data(filepath)\n",
    "    train_pairs, val_pairs, test_pairs = split_train_val_test(text_pairs)\n",
    "    eng_tokenizer, spa_tokenizer = prepare_tokenizer(\n",
    "        train_pairs, sequence_length, vocab_size\n",
    "    )\n",
    "    train_ds = prepare_datasets(\n",
    "        train_pairs,\n",
    "        batch_size,\n",
    "        eng_tokenizer,\n",
    "        spa_tokenizer,\n",
    "    )\n",
    "    val_ds = prepare_datasets(\n",
    "        val_pairs,\n",
    "        batch_size,\n",
    "        eng_tokenizer,\n",
    "        spa_tokenizer,\n",
    "    )\n",
    "    test_ds = prepare_datasets(\n",
    "        test_pairs,\n",
    "        batch_size,\n",
    "        eng_tokenizer,\n",
    "        spa_tokenizer,\n",
    "    )\n",
    "    return (train_ds, val_ds, test_ds), (eng_tokenizer, spa_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "class TranslationModel(keras.Model):\n",
    "    \"\"\"The machine translation model.\n",
    "\n",
    "    The model is an encoder-decoder structure model. The encoder is a stack of\n",
    "    `keras_nlp.TransformerEncoder`, and the decoder is a stack of\n",
    "    `keras_nlp.TransformerDecoder`. We also pass in the tokenizer for encoder\n",
    "    and decoder so that during save/load, the tokenizer is also kept.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_tokenizer,\n",
    "        decoder_tokenizer,\n",
    "        num_encoders,\n",
    "        num_decoders,\n",
    "        num_heads,\n",
    "        transformer_intermediate_dim,\n",
    "        encoder_vocabulary_size,\n",
    "        decoder_vocabulary_size,\n",
    "        embedding_dim,\n",
    "        sequence_length,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoders = []\n",
    "        self.decoders = []\n",
    "        for _ in range(num_encoders):\n",
    "            self.encoders.append(\n",
    "                keras_nlp.layers.TransformerEncoder(\n",
    "                    num_heads=num_heads,\n",
    "                    intermediate_dim=transformer_intermediate_dim,\n",
    "                )\n",
    "            )\n",
    "        for _ in range(num_decoders):\n",
    "            self.decoders.append(\n",
    "                keras_nlp.layers.TransformerDecoder(\n",
    "                    num_heads=num_heads,\n",
    "                    intermediate_dim=transformer_intermediate_dim,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.encoder_tokenizer = encoder_tokenizer\n",
    "        self.decoder_tokenizer = decoder_tokenizer\n",
    "\n",
    "        self.encoder_embedding = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "            vocabulary_size=encoder_vocabulary_size,\n",
    "            sequence_length=sequence_length,\n",
    "            embedding_dim=embedding_dim,\n",
    "            mask_zero=True,\n",
    "        )\n",
    "\n",
    "        self.decoder_embedding = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "            vocabulary_size=decoder_vocabulary_size,\n",
    "            sequence_length=sequence_length,\n",
    "            embedding_dim=embedding_dim,\n",
    "            mask_zero=True,\n",
    "        )\n",
    "\n",
    "        self.dense = keras.layers.Dense(\n",
    "            decoder_vocabulary_size,\n",
    "            activation=\"softmax\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_input, decoder_input = (\n",
    "            inputs[\"encoder_inputs\"],\n",
    "            inputs[\"decoder_inputs\"],\n",
    "        )\n",
    "        encoded = self.encoder_embedding(encoder_input)\n",
    "        for encoder in self.encoders:\n",
    "            encoded = encoder(inputs=encoded)\n",
    "\n",
    "        decoded = self.decoder_embedding(decoder_input)\n",
    "        for decoder in self.decoders:\n",
    "            decoded = decoder(\n",
    "                decoder_sequence=decoded,\n",
    "                encoder_sequence=encoded,\n",
    "                use_causal_mask=True,\n",
    "            )\n",
    "\n",
    "        output = self.dense(decoded)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \"encoder_tokenizer\": self.encoder_tokenizer.get_config(),\n",
    "            \"decoder_tokenizer\": self.decoder_tokenizer.get_config(),\n",
    "            \"num_encoders\": len(self.encoders),\n",
    "            \"num_decoders\": len(self.decoders),\n",
    "            \"num_heads\": self.encoders[0].num_heads,\n",
    "            \"transformer_intermediate_dim\": self.encoders[0].intermediate_dim,\n",
    "            \"encoder_vocabulary_size\": self.encoder_embedding.vocabulary_size,\n",
    "            \"decoder_vocabulary_size\": self.decoder_embedding.vocabulary_size,\n",
    "            \"embedding_dim\": self.encoder_embedding.embedding_dim,\n",
    "            \"sequence_length\": self.encoder_embedding.sequence_length,\n",
    "        })\n",
    "        return config\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        encoder_tokenizer_config = config.pop(\"encoder_tokenizer\")\n",
    "        decoder_tokenizer_config = config.pop(\"decoder_tokenizer\")\n",
    "        encoder_tokenizer = keras.layers.TextVectorization.from_config(encoder_tokenizer_config)\n",
    "        decoder_tokenizer = keras.layers.TextVectorization.from_config(decoder_tokenizer_config)\n",
    "        return cls(encoder_tokenizer=encoder_tokenizer, decoder_tokenizer=decoder_tokenizer, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "        model,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        initial_learning_rate,\n",
    "        decay_steps,\n",
    "        decay_rate,\n",
    "        epochs,\n",
    "        steps_per_epoch):\n",
    "    if decay_rate < 1.0:\n",
    "        learning_rate = keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=initial_learning_rate,\n",
    "            decay_steps=decay_steps,\n",
    "            decay_rate=decay_rate,\n",
    "        )\n",
    "    else:\n",
    "        learning_rate = initial_learning_rate\n",
    "    if f\"{keras.__version__}\".startswith(\"2.\") and is_running_on_apple_sillicon():\n",
    "        optimizer = keras.optimizers.legacy.Adam(\n",
    "            learning_rate=learning_rate,\n",
    "        )\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate,\n",
    "        )\n",
    "    if f\"{keras.__version__}\".startswith(\"2.\"):\n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "            reduction=keras.losses.Reduction.NONE\n",
    "        )\n",
    "    else:\n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "            reduction=None\n",
    "        )\n",
    "    metrics = [\n",
    "        keras.metrics.SparseCategoricalAccuracy(),\n",
    "        #keras.metrics.SparseCategoricalCrossentropy(),\n",
    "        #keras_nlp.metrics.Bleu(), #  This cannot be used here\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "        loss=loss_fn,\n",
    "        weighted_metrics=[],\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_ds,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "        num_encoders,\n",
    "        num_decoders,\n",
    "        num_heads,\n",
    "        transformer_intermediate_dim,\n",
    "        sequence_length,\n",
    "        vocab_size,\n",
    "        batch_size,\n",
    "        embedding_dim,\n",
    "        initial_learning_rate,\n",
    "        decay_steps,\n",
    "        decay_rate,\n",
    "        epochs,\n",
    "        steps_per_epoch):\n",
    "    (\n",
    "        (train_ds, val_ds, test_ds),\n",
    "        (\n",
    "            eng_tokenizer,\n",
    "            spa_tokenizer,\n",
    "        ),\n",
    "    ) = get_dataset_and_tokenizer(\n",
    "        sequence_length, vocab_size, batch_size\n",
    "    )\n",
    "    english_vocab_size = eng_tokenizer.vocabulary_size()\n",
    "    spanish_vocab_size = spa_tokenizer.vocabulary_size()\n",
    "    model = TranslationModel(\n",
    "        encoder_tokenizer=eng_tokenizer,\n",
    "        decoder_tokenizer=spa_tokenizer,\n",
    "        num_encoders=num_encoders,\n",
    "        num_decoders=num_decoders,\n",
    "        num_heads=num_heads,\n",
    "        transformer_intermediate_dim=transformer_intermediate_dim,\n",
    "        encoder_vocabulary_size=english_vocab_size,\n",
    "        decoder_vocabulary_size=spanish_vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        sequence_length=sequence_length,\n",
    "    )\n",
    "\n",
    "    history = run_training(\n",
    "        model,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "    )\n",
    "\n",
    "    if is_running_on_apple_sillicon():\n",
    "        filepath = 'machine_translation_model.keras/machine_translation_model.keras'\n",
    "    else:\n",
    "        filepath = 'machine_translation_model.keras'\n",
    "    print(f\"Saving to {filepath}\")\n",
    "    model.save(filepath=filepath)\n",
    "\n",
    "    print(f\"Successfully saved model to {filepath}\")\n",
    "    return model, filepath, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "EXAMPLES = [\n",
    "    (\n",
    "        \"Tom doesn't listen to anyone.\",\n",
    "        \"[start] Tomás no escucha a nadie. [end]\",\n",
    "    ),\n",
    "    (\"I got soaked to the skin.\", \"[start] Estoy chorreando. [end]\"),\n",
    "    (\"I imagined that.\", \"[start] Me imaginé eso. [end]\"),\n",
    "    (\"The baby is crying.\", \"[start] El bebé está llorando. [end]\"),\n",
    "    (\n",
    "        \"I've never felt so exhilarated.\",\n",
    "        \"[start] Nunca me he sentido tan animado. [end]\",\n",
    "    ),\n",
    "    (\n",
    "        \"Please forgive me for not having written sooner.\",\n",
    "        \"[start] Perdóname por no haberte escrito antes, por favor. [end]\",\n",
    "    ),\n",
    "    (\"I expected more from you.\", \"[start] Esperaba más de vos. [end]\"),\n",
    "    (\"I have a computer.\", \"[start] Tengo un computador. [end]\"),\n",
    "    (\"Dinner's ready!\", \"[start] ¡La cena está lista! [end]\"),\n",
    "    (\"Let me finish.\", \"[start] Déjame terminar. [end]\"),\n",
    "    (\"I trust her.\", \"[start] Yo confío en ella. [end]\"),\n",
    "    (\"I trust him.\", \"[start] Yo confío en él. [end]\"),\n",
    "]\n",
    "\n",
    "def decode_sequence(input_sentence, model, max_sequence_length, lookup_table):\n",
    "    encoder_tokenizer = model.encoder_tokenizer\n",
    "    decoder_tokenizer = model.decoder_tokenizer\n",
    "    tokenized_input = encoder_tokenizer([input_sentence])\n",
    "\n",
    "    start_token = decoder_tokenizer(\"[start]\")[0].numpy()\n",
    "    end_token = decoder_tokenizer(\"[end]\")[0].numpy()\n",
    "\n",
    "    decoded_sentence = [start_token]\n",
    "    for i in range(max_sequence_length):\n",
    "        decoder_inputs = tf.convert_to_tensor(\n",
    "            [decoded_sentence],\n",
    "            dtype=\"int64\",\n",
    "        )\n",
    "        decoder_inputs = tf.concat(\n",
    "            [\n",
    "                decoder_inputs,\n",
    "                tf.zeros(\n",
    "                    [1, max_sequence_length - i - 1],\n",
    "                    dtype=\"int64\",\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        input = {\n",
    "            \"encoder_inputs\": tokenized_input,\n",
    "            \"decoder_inputs\": decoder_inputs,\n",
    "        }\n",
    "        predictions = model(input)\n",
    "        predicted_token = np.argmax(predictions[0, i, :])\n",
    "        decoded_sentence.append(predicted_token)\n",
    "        if predicted_token == end_token:\n",
    "            break\n",
    "\n",
    "    detokenized_output = []\n",
    "    for token in decoded_sentence:\n",
    "        detokenized_output.append(lookup_table[token])\n",
    "    return \" \".join(detokenized_output)\n",
    "\n",
    "\n",
    "def predict_main(filepath, examples, sequence_length):\n",
    "    loaded_model = keras.models.load_model(filepath)\n",
    "\n",
    "    decoder_tokenizer = loaded_model.decoder_tokenizer\n",
    "    vocab = decoder_tokenizer.get_vocabulary()\n",
    "    index_lookup_table = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "    translated = []\n",
    "    for example in examples:\n",
    "        translated.append(\n",
    "            decode_sequence(\n",
    "                example[0],\n",
    "                loaded_model,\n",
    "                sequence_length,\n",
    "                index_lookup_table,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        print(\"ENGLISH SENTENCE: \", examples[i][0])\n",
    "        print(\"MACHINE TRANSLATED RESULT: \", translated[i])\n",
    "        print(\"GOLDEN: \", examples[i][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 13:12:11.132331: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-07-01 13:12:11.132385: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-07-01 13:12:11.132393: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-07-01 13:12:11.133577: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-01 13:12:11.133603: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-07-01 13:12:11.506375: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1302/1302 [==============================] - 1081s 826ms/step - loss: 1.5817 - sparse_categorical_accuracy: 0.2928 - val_loss: 1.1885 - val_sparse_categorical_accuracy: 0.4031\n",
      "Epoch 2/50\n",
      "1302/1302 [==============================] - 1250s 961ms/step - loss: 1.0730 - sparse_categorical_accuracy: 0.4433 - val_loss: 1.0412 - val_sparse_categorical_accuracy: 0.4549\n",
      "Epoch 3/50\n",
      "1302/1302 [==============================] - 134s 103ms/step - loss: 0.9662 - sparse_categorical_accuracy: 0.4819 - val_loss: 1.0103 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 4/50\n",
      "1302/1302 [==============================] - 137s 105ms/step - loss: 0.9383 - sparse_categorical_accuracy: 0.4922 - val_loss: 1.0028 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 5/50\n",
      "1302/1302 [==============================] - 138s 106ms/step - loss: 0.9309 - sparse_categorical_accuracy: 0.4950 - val_loss: 1.0006 - val_sparse_categorical_accuracy: 0.4705\n",
      "Epoch 6/50\n",
      "1302/1302 [==============================] - 135s 104ms/step - loss: 0.9289 - sparse_categorical_accuracy: 0.4957 - val_loss: 0.9999 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 7/50\n",
      "1302/1302 [==============================] - 139s 107ms/step - loss: 0.9283 - sparse_categorical_accuracy: 0.4959 - val_loss: 0.9997 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 8/50\n",
      "1302/1302 [==============================] - 135s 104ms/step - loss: 0.9282 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9997 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 9/50\n",
      "1302/1302 [==============================] - 134s 103ms/step - loss: 0.9282 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 10/50\n",
      "1302/1302 [==============================] - 136s 104ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 11/50\n",
      "1302/1302 [==============================] - 142s 109ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 12/50\n",
      "1302/1302 [==============================] - 134s 103ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 13/50\n",
      "1302/1302 [==============================] - 134s 103ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 14/50\n",
      "1302/1302 [==============================] - 132s 102ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 15/50\n",
      "1302/1302 [==============================] - 137s 105ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 16/50\n",
      "1302/1302 [==============================] - 152s 117ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 17/50\n",
      "1302/1302 [==============================] - 144s 111ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 18/50\n",
      "1302/1302 [==============================] - 136s 104ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 19/50\n",
      "1302/1302 [==============================] - 137s 105ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 20/50\n",
      "1302/1302 [==============================] - 138s 106ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 21/50\n",
      "1302/1302 [==============================] - 142s 109ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 22/50\n",
      "1302/1302 [==============================] - 136s 105ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 23/50\n",
      "1302/1302 [==============================] - 142s 109ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 24/50\n",
      "1302/1302 [==============================] - 138s 106ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 25/50\n",
      "1302/1302 [==============================] - 140s 108ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 26/50\n",
      "1302/1302 [==============================] - 139s 107ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 27/50\n",
      "1302/1302 [==============================] - 141s 109ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 28/50\n",
      "1302/1302 [==============================] - 140s 108ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 29/50\n",
      "1302/1302 [==============================] - 145s 111ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 30/50\n",
      "1302/1302 [==============================] - 142s 109ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 31/50\n",
      "1302/1302 [==============================] - 143s 110ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 32/50\n",
      "1302/1302 [==============================] - 137s 105ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 33/50\n",
      "1302/1302 [==============================] - 149s 115ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 34/50\n",
      "1302/1302 [==============================] - 148s 113ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 35/50\n",
      "1302/1302 [==============================] - 149s 115ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 36/50\n",
      "1302/1302 [==============================] - 147s 113ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 37/50\n",
      "1302/1302 [==============================] - 153s 117ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 38/50\n",
      "1302/1302 [==============================] - 150s 115ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 39/50\n",
      "1302/1302 [==============================] - 149s 115ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 40/50\n",
      "1302/1302 [==============================] - 148s 113ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 41/50\n",
      "1302/1302 [==============================] - 151s 116ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 42/50\n",
      "1302/1302 [==============================] - 147s 113ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 43/50\n",
      "1302/1302 [==============================] - 144s 111ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 44/50\n",
      "1302/1302 [==============================] - 139s 107ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 45/50\n",
      "1302/1302 [==============================] - 142s 109ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 46/50\n",
      "1302/1302 [==============================] - 138s 106ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 47/50\n",
      "1302/1302 [==============================] - 139s 107ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 48/50\n",
      "1302/1302 [==============================] - 138s 106ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 49/50\n",
      "1302/1302 [==============================] - 137s 106ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 50/50\n",
      "1302/1302 [==============================] - 135s 104ms/step - loss: 0.9281 - sparse_categorical_accuracy: 0.4960 - val_loss: 0.9996 - val_sparse_categorical_accuracy: 0.4707\n",
      "Saving to machine_translation_model.keras/machine_translation_model\n",
      "INFO:tensorflow:Assets written to: machine_translation_model.keras/machine_translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: machine_translation_model.keras/machine_translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model to machine_translation_model.keras/machine_translation_model\n"
     ]
    }
   ],
   "source": [
    "# default params\n",
    "FLAGS_learning_rate = 0.001\n",
    "FLAGS_num_epochs = 50 # default=1, but too small\n",
    "FLAGS_steps_per_epoch = None\n",
    "FLAGS_sequence_length = 20 # Input and output sequence length.\n",
    "FLAGS_vocab_size = 15000 # Vocabulary size, required by tokenizer.\n",
    "FLAGS_batch_size = 64\n",
    "FLAGS_num_encoders = 2\n",
    "FLAGS_num_decoders = 2\n",
    "FLAGS_num_heads = 8 # Number of head of the multihead attention.\n",
    "FLAGS_intermediate_dim = 128 # Intermediate dimension (feedforward network) of transformer.\n",
    "FLAGS_model_dim = 64\n",
    "FLAGS_decay_steps = 20\n",
    "FLAGS_decay_rate = 0.98\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    num_encoders=FLAGS_num_encoders,\n",
    "    num_decoders=FLAGS_num_decoders,\n",
    "    num_heads=FLAGS_num_heads,\n",
    "    transformer_intermediate_dim=FLAGS_intermediate_dim,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    "    vocab_size=FLAGS_vocab_size,\n",
    "    batch_size=FLAGS_batch_size,\n",
    "    embedding_dim=FLAGS_model_dim,\n",
    "    initial_learning_rate=FLAGS_learning_rate,\n",
    "    decay_steps=FLAGS_decay_steps,\n",
    "    decay_rate=FLAGS_decay_rate,\n",
    "    epochs=FLAGS_num_epochs,\n",
    "    steps_per_epoch=FLAGS_steps_per_epoch,\n",
    ")\n",
    "plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH SENTENCE:  Tom doesn't listen to anyone.\n",
      "MACHINE TRANSLATED RESULT:  [start] tom no se [UNK] a ver a los [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] que [UNK]\n",
      "GOLDEN:  [start] Tomás no escucha a nadie. [end]\n",
      "ENGLISH SENTENCE:  I got soaked to the skin.\n",
      "MACHINE TRANSLATED RESULT:  [start] me pregunto que la [UNK] de [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] que [UNK]\n",
      "GOLDEN:  [start] Estoy chorreando. [end]\n",
      "ENGLISH SENTENCE:  I imagined that.\n",
      "MACHINE TRANSLATED RESULT:  [start] me pregunto que los [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] que [UNK]\n",
      "GOLDEN:  [start] Me imaginé eso. [end]\n",
      "ENGLISH SENTENCE:  The baby is crying.\n",
      "MACHINE TRANSLATED RESULT:  [start] el bebé es capaz de comer [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] que [UNK]\n",
      "GOLDEN:  [start] El bebé está llorando. [end]\n",
      "ENGLISH SENTENCE:  I've never felt so exhilarated.\n",
      "MACHINE TRANSLATED RESULT:  [start] nunca he visto tan [UNK] que los [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] que [UNK]\n",
      "GOLDEN:  [start] Nunca me he sentido tan animado. [end]\n",
      "ENGLISH SENTENCE:  Please forgive me for not having written sooner.\n",
      "MACHINE TRANSLATED RESULT:  [start] por favor [UNK] con no [UNK] para que no [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que los\n",
      "GOLDEN:  [start] Perdóname por no haberte escrito antes, por favor. [end]\n",
      "ENGLISH SENTENCE:  I expected more from you.\n",
      "MACHINE TRANSLATED RESULT:  [start] se me ha más más de más que [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] que [UNK]\n",
      "GOLDEN:  [start] Esperaba más de vos. [end]\n",
      "ENGLISH SENTENCE:  I have a computer.\n",
      "MACHINE TRANSLATED RESULT:  [start] tengo una [UNK] de que [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] que [UNK]\n",
      "GOLDEN:  [start] Tengo un computador. [end]\n",
      "ENGLISH SENTENCE:  Dinner's ready!\n",
      "MACHINE TRANSLATED RESULT:  [start] el [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] [UNK] que [UNK]\n",
      "GOLDEN:  [start] ¡La cena está lista! [end]\n",
      "ENGLISH SENTENCE:  Let me finish.\n",
      "MACHINE TRANSLATED RESULT:  [start] déjame aprender de [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] que [UNK]\n",
      "GOLDEN:  [start] Déjame terminar. [end]\n",
      "ENGLISH SENTENCE:  I trust her.\n",
      "MACHINE TRANSLATED RESULT:  [start] me [UNK] los años que los [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] [UNK] [UNK]\n",
      "GOLDEN:  [start] Yo confío en ella. [end]\n",
      "ENGLISH SENTENCE:  I trust him.\n",
      "MACHINE TRANSLATED RESULT:  [start] me [UNK] que los [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] que [UNK] que [UNK]\n",
      "GOLDEN:  [start] Yo confío en él. [end]\n"
     ]
    }
   ],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1302/1302 [==============================] - 88s 65ms/step - loss: 1.4859 - sparse_categorical_accuracy: 0.3218 - val_loss: 0.9899 - val_sparse_categorical_accuracy: 0.4612\n",
      "Epoch 2/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.8249 - sparse_categorical_accuracy: 0.5196 - val_loss: 0.7564 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 3/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.6001 - sparse_categorical_accuracy: 0.5883 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.5614\n",
      "Epoch 4/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.4764 - sparse_categorical_accuracy: 0.6295 - val_loss: 0.6518 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "1302/1302 [==============================] - 81s 62ms/step - loss: 0.3970 - sparse_categorical_accuracy: 0.6599 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.5756\n",
      "Epoch 6/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.3418 - sparse_categorical_accuracy: 0.6833 - val_loss: 0.6435 - val_sparse_categorical_accuracy: 0.5807\n",
      "Epoch 7/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.3021 - sparse_categorical_accuracy: 0.7015 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.5829\n",
      "Epoch 8/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.2716 - sparse_categorical_accuracy: 0.7166 - val_loss: 0.6541 - val_sparse_categorical_accuracy: 0.5827\n",
      "Epoch 9/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.2467 - sparse_categorical_accuracy: 0.7296 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.5808\n",
      "Epoch 10/50\n",
      "1302/1302 [==============================] - 80s 62ms/step - loss: 0.2261 - sparse_categorical_accuracy: 0.7407 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.5816\n",
      "Epoch 11/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.2091 - sparse_categorical_accuracy: 0.7502 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.5808\n",
      "Epoch 12/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.1949 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.5799\n",
      "Epoch 13/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.1829 - sparse_categorical_accuracy: 0.7654 - val_loss: 0.7132 - val_sparse_categorical_accuracy: 0.5792\n",
      "Epoch 14/50\n",
      "1302/1302 [==============================] - 80s 62ms/step - loss: 0.1726 - sparse_categorical_accuracy: 0.7715 - val_loss: 0.7236 - val_sparse_categorical_accuracy: 0.5795\n",
      "Epoch 15/50\n",
      "1302/1302 [==============================] - 81s 62ms/step - loss: 0.1637 - sparse_categorical_accuracy: 0.7766 - val_loss: 0.7348 - val_sparse_categorical_accuracy: 0.5780\n",
      "Epoch 16/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.1561 - sparse_categorical_accuracy: 0.7811 - val_loss: 0.7452 - val_sparse_categorical_accuracy: 0.5768\n",
      "Epoch 17/50\n",
      "1302/1302 [==============================] - 80s 62ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.7850 - val_loss: 0.7520 - val_sparse_categorical_accuracy: 0.5782\n",
      "Epoch 18/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.1438 - sparse_categorical_accuracy: 0.7884 - val_loss: 0.7610 - val_sparse_categorical_accuracy: 0.5783\n",
      "Epoch 19/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.1389 - sparse_categorical_accuracy: 0.7912 - val_loss: 0.7697 - val_sparse_categorical_accuracy: 0.5775\n",
      "Epoch 20/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.1346 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.7779 - val_sparse_categorical_accuracy: 0.5770\n",
      "Epoch 21/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.1309 - sparse_categorical_accuracy: 0.7959 - val_loss: 0.7843 - val_sparse_categorical_accuracy: 0.5766\n",
      "Epoch 22/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.1276 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.7895 - val_sparse_categorical_accuracy: 0.5765\n",
      "Epoch 23/50\n",
      "1302/1302 [==============================] - 81s 62ms/step - loss: 0.1248 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.7938 - val_sparse_categorical_accuracy: 0.5760\n",
      "Epoch 24/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.1223 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.7977 - val_sparse_categorical_accuracy: 0.5758\n",
      "Epoch 25/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.1201 - sparse_categorical_accuracy: 0.8023 - val_loss: 0.8014 - val_sparse_categorical_accuracy: 0.5755\n",
      "Epoch 26/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.1182 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.8049 - val_sparse_categorical_accuracy: 0.5753\n",
      "Epoch 27/50\n",
      "1302/1302 [==============================] - 77s 59ms/step - loss: 0.1165 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.8081 - val_sparse_categorical_accuracy: 0.5750\n",
      "Epoch 28/50\n",
      "1302/1302 [==============================] - 73s 56ms/step - loss: 0.1150 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.8110 - val_sparse_categorical_accuracy: 0.5748\n",
      "Epoch 29/50\n",
      "1302/1302 [==============================] - 74s 57ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.8135 - val_sparse_categorical_accuracy: 0.5747\n",
      "Epoch 30/50\n",
      "1302/1302 [==============================] - 72s 55ms/step - loss: 0.1125 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.8159 - val_sparse_categorical_accuracy: 0.5747\n",
      "Epoch 31/50\n",
      "1302/1302 [==============================] - 70s 54ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.8180 - val_sparse_categorical_accuracy: 0.5746\n",
      "Epoch 32/50\n",
      "1302/1302 [==============================] - 71s 55ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.8200 - val_sparse_categorical_accuracy: 0.5746\n",
      "Epoch 33/50\n",
      "1302/1302 [==============================] - 71s 55ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.8217 - val_sparse_categorical_accuracy: 0.5743\n",
      "Epoch 34/50\n",
      "1302/1302 [==============================] - 73s 56ms/step - loss: 0.1091 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.8233 - val_sparse_categorical_accuracy: 0.5742\n",
      "Epoch 35/50\n",
      "1302/1302 [==============================] - 71s 54ms/step - loss: 0.1085 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.8247 - val_sparse_categorical_accuracy: 0.5743\n",
      "Epoch 36/50\n",
      "1302/1302 [==============================] - 73s 56ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.8260 - val_sparse_categorical_accuracy: 0.5741\n",
      "Epoch 37/50\n",
      "1302/1302 [==============================] - 70s 54ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.8098 - val_loss: 0.8271 - val_sparse_categorical_accuracy: 0.5740\n",
      "Epoch 38/50\n",
      "1302/1302 [==============================] - 70s 54ms/step - loss: 0.1071 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.8282 - val_sparse_categorical_accuracy: 0.5739\n",
      "Epoch 39/50\n",
      "1302/1302 [==============================] - 71s 55ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.8291 - val_sparse_categorical_accuracy: 0.5739\n",
      "Epoch 40/50\n",
      "1302/1302 [==============================] - 71s 54ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.8299 - val_sparse_categorical_accuracy: 0.5739\n",
      "Epoch 41/50\n",
      "1302/1302 [==============================] - 70s 54ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.8306 - val_sparse_categorical_accuracy: 0.5738\n",
      "Epoch 42/50\n",
      "1302/1302 [==============================] - 71s 54ms/step - loss: 0.1058 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.8313 - val_sparse_categorical_accuracy: 0.5737\n",
      "Epoch 43/50\n",
      "1302/1302 [==============================] - 71s 54ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.8318 - val_sparse_categorical_accuracy: 0.5736\n",
      "Epoch 44/50\n",
      "1302/1302 [==============================] - 70s 54ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.8112 - val_loss: 0.8323 - val_sparse_categorical_accuracy: 0.5736\n",
      "Epoch 45/50\n",
      "1302/1302 [==============================] - 70s 54ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.8327 - val_sparse_categorical_accuracy: 0.5734\n",
      "Epoch 46/50\n",
      "1302/1302 [==============================] - 71s 54ms/step - loss: 0.1051 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.8331 - val_sparse_categorical_accuracy: 0.5734\n",
      "Epoch 47/50\n",
      "1302/1302 [==============================] - 70s 54ms/step - loss: 0.1049 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.8334 - val_sparse_categorical_accuracy: 0.5735\n",
      "Epoch 48/50\n",
      "1302/1302 [==============================] - 71s 54ms/step - loss: 0.1048 - sparse_categorical_accuracy: 0.8116 - val_loss: 0.8336 - val_sparse_categorical_accuracy: 0.5735\n",
      "Epoch 49/50\n",
      "1302/1302 [==============================] - 71s 55ms/step - loss: 0.1047 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.8339 - val_sparse_categorical_accuracy: 0.5735\n",
      "Epoch 50/50\n",
      "1302/1302 [==============================] - 72s 55ms/step - loss: 0.1046 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.8341 - val_sparse_categorical_accuracy: 0.5734\n",
      "Saving to machine_translation_model.keras/machine_translation_model\n",
      "INFO:tensorflow:Assets written to: machine_translation_model.keras/machine_translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: machine_translation_model.keras/machine_translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model to machine_translation_model.keras/machine_translation_model\n"
     ]
    }
   ],
   "source": [
    "# minimum viable params\n",
    "# Epoch 24/50 - loss: 0.1224 - sparse_categorical_accuracy: 0.8007 - val_loss: 0.8010 - val_sparse_categorical_accuracy: 0.5755\n",
    "FLAGS_learning_rate = 0.001\n",
    "FLAGS_num_epochs = 50\n",
    "FLAGS_steps_per_epoch = None\n",
    "FLAGS_sequence_length = 20\n",
    "FLAGS_vocab_size = 15000\n",
    "FLAGS_batch_size = 64\n",
    "FLAGS_num_encoders = 1\n",
    "FLAGS_num_decoders = 1\n",
    "FLAGS_num_heads = 6\n",
    "FLAGS_intermediate_dim = 512\n",
    "FLAGS_model_dim = 64\n",
    "FLAGS_decay_steps = 100\n",
    "FLAGS_decay_rate = 0.99\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    num_encoders=FLAGS_num_encoders,\n",
    "    num_decoders=FLAGS_num_decoders,\n",
    "    num_heads=FLAGS_num_heads,\n",
    "    transformer_intermediate_dim=FLAGS_intermediate_dim,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    "    vocab_size=FLAGS_vocab_size,\n",
    "    batch_size=FLAGS_batch_size,\n",
    "    embedding_dim=FLAGS_model_dim,\n",
    "    initial_learning_rate=FLAGS_learning_rate,\n",
    "    decay_steps=FLAGS_decay_steps,\n",
    "    decay_rate=FLAGS_decay_rate,\n",
    "    epochs=FLAGS_num_epochs,\n",
    "    steps_per_epoch=FLAGS_steps_per_epoch,\n",
    ")\n",
    "# plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1302/1302 [==============================] - 85s 62ms/step - loss: 1.5949 - sparse_categorical_accuracy: 0.2873 - val_loss: 1.1859 - val_sparse_categorical_accuracy: 0.3964\n",
      "Epoch 2/50\n",
      "1302/1302 [==============================] - 76s 58ms/step - loss: 1.0881 - sparse_categorical_accuracy: 0.4368 - val_loss: 1.0414 - val_sparse_categorical_accuracy: 0.4515\n",
      "Epoch 3/50\n",
      "1302/1302 [==============================] - 79s 60ms/step - loss: 0.9831 - sparse_categorical_accuracy: 0.4744 - val_loss: 1.0101 - val_sparse_categorical_accuracy: 0.4636\n",
      "Epoch 4/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.9559 - sparse_categorical_accuracy: 0.4848 - val_loss: 1.0021 - val_sparse_categorical_accuracy: 0.4661\n",
      "Epoch 5/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9487 - sparse_categorical_accuracy: 0.4875 - val_loss: 0.9999 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 6/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.9467 - sparse_categorical_accuracy: 0.4881 - val_loss: 0.9993 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 7/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.9462 - sparse_categorical_accuracy: 0.4883 - val_loss: 0.9991 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 8/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.9461 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 9/50\n",
      "1302/1302 [==============================] - 77s 59ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 10/50\n",
      "1302/1302 [==============================] - 79s 60ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 11/50\n",
      "1302/1302 [==============================] - 88s 68ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 12/50\n",
      "1302/1302 [==============================] - 86s 66ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 13/50\n",
      "1302/1302 [==============================] - 83s 64ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 14/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 15/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 16/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 17/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 18/50\n",
      "1302/1302 [==============================] - 83s 64ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 19/50\n",
      "1302/1302 [==============================] - 77s 59ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 20/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 21/50\n",
      "1302/1302 [==============================] - 81s 62ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 22/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 23/50\n",
      "1302/1302 [==============================] - 84s 65ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 24/50\n",
      "1302/1302 [==============================] - 90s 69ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 25/50\n",
      "1302/1302 [==============================] - 84s 64ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 26/50\n",
      "1302/1302 [==============================] - 85s 65ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 27/50\n",
      "1302/1302 [==============================] - 86s 66ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 28/50\n",
      "1302/1302 [==============================] - 88s 67ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 29/50\n",
      "1302/1302 [==============================] - 84s 65ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 30/50\n",
      "1302/1302 [==============================] - 84s 64ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 31/50\n",
      "1302/1302 [==============================] - 85s 66ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 32/50\n",
      "1302/1302 [==============================] - 84s 65ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 33/50\n",
      "1302/1302 [==============================] - 89s 68ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 34/50\n",
      "1302/1302 [==============================] - 88s 67ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 35/50\n",
      "1302/1302 [==============================] - 86s 66ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 36/50\n",
      "1302/1302 [==============================] - 81s 62ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 37/50\n",
      "1302/1302 [==============================] - 86s 66ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 38/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 39/50\n",
      "1302/1302 [==============================] - 86s 66ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 40/50\n",
      "1302/1302 [==============================] - 88s 68ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 41/50\n",
      "1302/1302 [==============================] - 84s 64ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 42/50\n",
      "1302/1302 [==============================] - 79s 60ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 43/50\n",
      "1302/1302 [==============================] - 81s 62ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 44/50\n",
      "1302/1302 [==============================] - 83s 63ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 45/50\n",
      "1302/1302 [==============================] - 77s 59ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 46/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 47/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 48/50\n",
      "1302/1302 [==============================] - 83s 64ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 49/50\n",
      "1302/1302 [==============================] - 85s 65ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Epoch 50/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.4884 - val_loss: 0.9990 - val_sparse_categorical_accuracy: 0.4669\n",
      "Saving to machine_translation_model.keras/machine_translation_model\n",
      "INFO:tensorflow:Assets written to: machine_translation_model.keras/machine_translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: machine_translation_model.keras/machine_translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model to machine_translation_model.keras/machine_translation_model\n"
     ]
    }
   ],
   "source": [
    "# FLAGS_learning_rate = 0.001 # pegasus: 0.0005 > text generation: 2e-6\n",
    "# minimum viable params\n",
    "FLAGS_learning_rate = 0.001\n",
    "FLAGS_num_epochs = 50\n",
    "FLAGS_steps_per_epoch = None\n",
    "FLAGS_sequence_length = 20\n",
    "FLAGS_vocab_size = 15000\n",
    "FLAGS_batch_size = 64\n",
    "FLAGS_num_encoders = 1\n",
    "FLAGS_num_decoders = 1\n",
    "FLAGS_num_heads = 6\n",
    "FLAGS_intermediate_dim = 512\n",
    "FLAGS_model_dim = 64\n",
    "FLAGS_decay_steps = 20\n",
    "FLAGS_decay_rate = 0.98\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    num_encoders=FLAGS_num_encoders,\n",
    "    num_decoders=FLAGS_num_decoders,\n",
    "    num_heads=FLAGS_num_heads,\n",
    "    transformer_intermediate_dim=FLAGS_intermediate_dim,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    "    vocab_size=FLAGS_vocab_size,\n",
    "    batch_size=FLAGS_batch_size,\n",
    "    embedding_dim=FLAGS_model_dim,\n",
    "    initial_learning_rate=FLAGS_learning_rate,\n",
    "    decay_steps=FLAGS_decay_steps,\n",
    "    decay_rate=FLAGS_decay_rate,\n",
    "    epochs=FLAGS_num_epochs,\n",
    "    steps_per_epoch=FLAGS_steps_per_epoch,\n",
    ")\n",
    "plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1302/1302 [==============================] - 100s 74ms/step - loss: 1.4887 - sparse_categorical_accuracy: 0.3220 - val_loss: 0.9714 - val_sparse_categorical_accuracy: 0.4700\n",
      "Epoch 2/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.8124 - sparse_categorical_accuracy: 0.5234 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.5424\n",
      "Epoch 3/50\n",
      "1302/1302 [==============================] - 84s 64ms/step - loss: 0.5844 - sparse_categorical_accuracy: 0.5905 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.5644\n",
      "Epoch 4/50\n",
      "1302/1302 [==============================] - 84s 64ms/step - loss: 0.4640 - sparse_categorical_accuracy: 0.6282 - val_loss: 0.6395 - val_sparse_categorical_accuracy: 0.5723\n",
      "Epoch 5/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.3908 - sparse_categorical_accuracy: 0.6553 - val_loss: 0.6443 - val_sparse_categorical_accuracy: 0.5717\n",
      "Epoch 6/50\n",
      "1302/1302 [==============================] - 85s 65ms/step - loss: 0.3427 - sparse_categorical_accuracy: 0.6759 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.5666\n",
      "Epoch 7/50\n",
      "1302/1302 [==============================] - 83s 64ms/step - loss: 0.3076 - sparse_categorical_accuracy: 0.6923 - val_loss: 0.6663 - val_sparse_categorical_accuracy: 0.5766\n",
      "Epoch 8/50\n",
      "1302/1302 [==============================] - 83s 64ms/step - loss: 0.2807 - sparse_categorical_accuracy: 0.7055 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.5741\n",
      "Epoch 9/50\n",
      "1302/1302 [==============================] - 86s 66ms/step - loss: 0.2584 - sparse_categorical_accuracy: 0.7170 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.5738\n",
      "Epoch 10/50\n",
      "1302/1302 [==============================] - 83s 64ms/step - loss: 0.2398 - sparse_categorical_accuracy: 0.7273 - val_loss: 0.7212 - val_sparse_categorical_accuracy: 0.5683\n",
      "Epoch 11/50\n",
      "1302/1302 [==============================] - 87s 67ms/step - loss: 0.2251 - sparse_categorical_accuracy: 0.7346 - val_loss: 0.7402 - val_sparse_categorical_accuracy: 0.5664\n",
      "Epoch 12/50\n",
      "1302/1302 [==============================] - 81s 62ms/step - loss: 0.2134 - sparse_categorical_accuracy: 0.7408 - val_loss: 0.7664 - val_sparse_categorical_accuracy: 0.5671\n",
      "Epoch 13/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.2027 - sparse_categorical_accuracy: 0.7460 - val_loss: 0.7835 - val_sparse_categorical_accuracy: 0.5692\n",
      "Epoch 14/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.1917 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.7998 - val_sparse_categorical_accuracy: 0.5662\n",
      "Epoch 15/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.1819 - sparse_categorical_accuracy: 0.7581 - val_loss: 0.8243 - val_sparse_categorical_accuracy: 0.5606\n",
      "Epoch 16/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.1743 - sparse_categorical_accuracy: 0.7621 - val_loss: 0.8399 - val_sparse_categorical_accuracy: 0.5613\n",
      "Epoch 17/50\n",
      "1302/1302 [==============================] - 85s 65ms/step - loss: 0.1667 - sparse_categorical_accuracy: 0.7661 - val_loss: 0.8687 - val_sparse_categorical_accuracy: 0.5573\n",
      "Epoch 18/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.1617 - sparse_categorical_accuracy: 0.7688 - val_loss: 0.8807 - val_sparse_categorical_accuracy: 0.5596\n",
      "Epoch 19/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.1558 - sparse_categorical_accuracy: 0.7719 - val_loss: 0.9070 - val_sparse_categorical_accuracy: 0.5577\n",
      "Epoch 20/50\n",
      "1302/1302 [==============================] - 76s 58ms/step - loss: 0.1505 - sparse_categorical_accuracy: 0.7750 - val_loss: 0.9264 - val_sparse_categorical_accuracy: 0.5566\n",
      "Epoch 21/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.1444 - sparse_categorical_accuracy: 0.7786 - val_loss: 0.9430 - val_sparse_categorical_accuracy: 0.5573\n",
      "Epoch 22/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.1395 - sparse_categorical_accuracy: 0.7812 - val_loss: 0.9565 - val_sparse_categorical_accuracy: 0.5562\n",
      "Epoch 23/50\n",
      "1302/1302 [==============================] - 77s 59ms/step - loss: 0.1341 - sparse_categorical_accuracy: 0.7846 - val_loss: 0.9781 - val_sparse_categorical_accuracy: 0.5526\n",
      "Epoch 24/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.9944 - val_sparse_categorical_accuracy: 0.5486\n",
      "Epoch 25/50\n",
      "1302/1302 [==============================] - 81s 62ms/step - loss: 0.1276 - sparse_categorical_accuracy: 0.7882 - val_loss: 1.0132 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 26/50\n",
      "1302/1302 [==============================] - 80s 62ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.7903 - val_loss: 1.0189 - val_sparse_categorical_accuracy: 0.5462\n",
      "Epoch 27/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.7914 - val_loss: 1.0333 - val_sparse_categorical_accuracy: 0.5506\n",
      "Epoch 28/50\n",
      "1302/1302 [==============================] - 79s 61ms/step - loss: 0.1185 - sparse_categorical_accuracy: 0.7934 - val_loss: 1.0484 - val_sparse_categorical_accuracy: 0.5503\n",
      "Epoch 29/50\n",
      "1302/1302 [==============================] - 79s 60ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.7948 - val_loss: 1.0605 - val_sparse_categorical_accuracy: 0.5480\n",
      "Epoch 30/50\n",
      "1302/1302 [==============================] - 81s 62ms/step - loss: 0.1126 - sparse_categorical_accuracy: 0.7967 - val_loss: 1.0759 - val_sparse_categorical_accuracy: 0.5471\n",
      "Epoch 31/50\n",
      "1302/1302 [==============================] - 78s 60ms/step - loss: 0.1102 - sparse_categorical_accuracy: 0.7981 - val_loss: 1.0862 - val_sparse_categorical_accuracy: 0.5460\n",
      "Epoch 32/50\n",
      "1302/1302 [==============================] - 83s 64ms/step - loss: 0.1077 - sparse_categorical_accuracy: 0.8000 - val_loss: 1.0944 - val_sparse_categorical_accuracy: 0.5460\n",
      "Epoch 33/50\n",
      "1302/1302 [==============================] - 85s 65ms/step - loss: 0.1049 - sparse_categorical_accuracy: 0.8015 - val_loss: 1.1172 - val_sparse_categorical_accuracy: 0.5455\n",
      "Epoch 34/50\n",
      "1302/1302 [==============================] - 86s 66ms/step - loss: 0.1023 - sparse_categorical_accuracy: 0.8029 - val_loss: 1.1310 - val_sparse_categorical_accuracy: 0.5456\n",
      "Epoch 35/50\n",
      "1302/1302 [==============================] - 73s 56ms/step - loss: 0.1007 - sparse_categorical_accuracy: 0.8039 - val_loss: 1.1418 - val_sparse_categorical_accuracy: 0.5455\n",
      "Epoch 36/50\n",
      "1302/1302 [==============================] - 74s 57ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.8051 - val_loss: 1.1552 - val_sparse_categorical_accuracy: 0.5442\n",
      "Epoch 37/50\n",
      "1302/1302 [==============================] - 76s 58ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.8059 - val_loss: 1.1737 - val_sparse_categorical_accuracy: 0.5447\n",
      "Epoch 38/50\n",
      "1302/1302 [==============================] - 76s 59ms/step - loss: 0.0957 - sparse_categorical_accuracy: 0.8069 - val_loss: 1.1819 - val_sparse_categorical_accuracy: 0.5452\n",
      "Epoch 39/50\n",
      "1302/1302 [==============================] - 776s 596ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.8083 - val_loss: 1.1920 - val_sparse_categorical_accuracy: 0.5402\n",
      "Epoch 40/50\n",
      "1302/1302 [==============================] - 6495s 5s/step - loss: 0.0927 - sparse_categorical_accuracy: 0.8086 - val_loss: 1.2023 - val_sparse_categorical_accuracy: 0.5413\n",
      "Epoch 41/50\n",
      "1302/1302 [==============================] - 72s 56ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.8093 - val_loss: 1.2130 - val_sparse_categorical_accuracy: 0.5418\n",
      "Epoch 42/50\n",
      "1302/1302 [==============================] - 73s 56ms/step - loss: 0.0891 - sparse_categorical_accuracy: 0.8106 - val_loss: 1.2286 - val_sparse_categorical_accuracy: 0.5420\n",
      "Epoch 43/50\n",
      "1302/1302 [==============================] - 75s 58ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.8114 - val_loss: 1.2482 - val_sparse_categorical_accuracy: 0.5433\n",
      "Epoch 44/50\n",
      "1302/1302 [==============================] - 76s 59ms/step - loss: 0.0869 - sparse_categorical_accuracy: 0.8121 - val_loss: 1.2506 - val_sparse_categorical_accuracy: 0.5429\n",
      "Epoch 45/50\n",
      "1302/1302 [==============================] - 75s 58ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.8132 - val_loss: 1.2562 - val_sparse_categorical_accuracy: 0.5428\n",
      "Epoch 46/50\n",
      "1302/1302 [==============================] - 76s 58ms/step - loss: 0.0840 - sparse_categorical_accuracy: 0.8140 - val_loss: 1.2682 - val_sparse_categorical_accuracy: 0.5398\n",
      "Epoch 47/50\n",
      "1302/1302 [==============================] - 74s 57ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.8150 - val_loss: 1.2777 - val_sparse_categorical_accuracy: 0.5421\n",
      "Epoch 48/50\n",
      "1302/1302 [==============================] - 74s 57ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.8153 - val_loss: 1.2905 - val_sparse_categorical_accuracy: 0.5402\n",
      "Epoch 49/50\n",
      "1302/1302 [==============================] - 74s 57ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.8154 - val_loss: 1.2943 - val_sparse_categorical_accuracy: 0.5378\n",
      "Epoch 50/50\n",
      "1302/1302 [==============================] - 73s 56ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.8167 - val_loss: 1.3083 - val_sparse_categorical_accuracy: 0.5380\n",
      "Saving to machine_translation_model.keras/machine_translation_model\n",
      "INFO:tensorflow:Assets written to: machine_translation_model.keras/machine_translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: machine_translation_model.keras/machine_translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model to machine_translation_model.keras/machine_translation_model\n"
     ]
    }
   ],
   "source": [
    "# minimum viable params with no decay\n",
    "# Epoch 24/50 - loss: 0.1224 - sparse_categorical_accuracy: 0.8007 - val_loss: 0.8010 - val_sparse_categorical_accuracy: 0.5755\n",
    "FLAGS_learning_rate = 0.001\n",
    "FLAGS_num_epochs = 50\n",
    "FLAGS_steps_per_epoch = None\n",
    "FLAGS_sequence_length = 20\n",
    "FLAGS_vocab_size = 15000\n",
    "FLAGS_batch_size = 64\n",
    "FLAGS_num_encoders = 1\n",
    "FLAGS_num_decoders = 1\n",
    "FLAGS_num_heads = 6\n",
    "FLAGS_intermediate_dim = 512\n",
    "FLAGS_model_dim = 64\n",
    "FLAGS_decay_steps = 100\n",
    "FLAGS_decay_rate = 1.0\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    num_encoders=FLAGS_num_encoders,\n",
    "    num_decoders=FLAGS_num_decoders,\n",
    "    num_heads=FLAGS_num_heads,\n",
    "    transformer_intermediate_dim=FLAGS_intermediate_dim,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    "    vocab_size=FLAGS_vocab_size,\n",
    "    batch_size=FLAGS_batch_size,\n",
    "    embedding_dim=FLAGS_model_dim,\n",
    "    initial_learning_rate=FLAGS_learning_rate,\n",
    "    decay_steps=FLAGS_decay_steps,\n",
    "    decay_rate=FLAGS_decay_rate,\n",
    "    epochs=FLAGS_num_epochs,\n",
    "    steps_per_epoch=FLAGS_steps_per_epoch,\n",
    ")\n",
    "plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
