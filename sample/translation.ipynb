{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras-nlp/example/machine_translation\n",
    "\n",
    "- https://github.com/keras-team/keras-nlp/tree/master/examples/machine_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Copyright 2023 The KerasNLP Authors\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.15.1\n",
      "  Using cached tensorflow-2.15.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting tensorflow-macos==2.15.1\n",
      "  Using cached tensorflow_macos-2.15.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.4 kB)\n",
      "Collecting keras==2.15.0\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (16.0.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.3.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.26.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (4.11.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.56.0)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n",
      "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow==2.15.1) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.19.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.30.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\n",
      "Using cached tensorflow-2.15.1-cp310-cp310-macosx_12_0_arm64.whl (205.7 MB)\n",
      "Using cached tensorflow_macos-2.15.1-cp310-cp310-macosx_12_0_arm64.whl (2.2 kB)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: keras, tensorboard, tensorflow, tensorflow-macos\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.4.1\n",
      "    Uninstalling keras-3.4.1:\n",
      "      Successfully uninstalled keras-3.4.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.2\n",
      "    Uninstalling tensorflow-2.16.2:\n",
      "      Successfully uninstalled tensorflow-2.16.2\n",
      "  Attempting uninstall: tensorflow-macos\n",
      "    Found existing installation: tensorflow-macos 2.16.2\n",
      "    Uninstalling tensorflow-macos-2.16.2:\n",
      "      Successfully uninstalled tensorflow-macos-2.16.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.15.0 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-macos-2.15.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# The hyperparameters, especially of the optimizer, seem picky.\n",
    "# Currently, only the following versions go well only on mac with RMSprop.\n",
    "%pip install -U tensorflow==2.15.1 tensorflow-macos==2.15.1 keras==2.15.0\n",
    "#%pip install keras-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version can not use keras.optimizers.legacy.RMSprop.\n",
    "# And the model does not converge.\n",
    "%pip install -U tensorflow==2.16.2 tensorflow-macos==2.16.2 keras==3.4.1\n",
    "#%pip install keras-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "2.15.1\n",
      "2.15.0\n",
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_nlp\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "def is_running_on_apple_sillicon():\n",
    "    return platform.system() == \"Darwin\" and platform.processor() == \"arm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker cannot use @keras.saving\n",
    "from keras import saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(history, title=None):\n",
    "    \"\"\"\n",
    "    Display the plot that indicates the loss and accuracy.\n",
    "    :param history: history object from the tensorflow fit function.\n",
    "    :param title: title text.\n",
    "    \"\"\"\n",
    "    flg, axes = plt.subplots(1, 2, tight_layout=True)\n",
    "    if title is not None:\n",
    "        flg.suptitle(t=title, fontsize=14)\n",
    "    for i, key in enumerate([\"loss\", \"accuracy\"]):\n",
    "        value = history.history[key]\n",
    "        val_loss = history.history[f\"val_{key}\"]\n",
    "        epochs = range(1, len(value) + 1)\n",
    "        axes[i].plot(epochs, value, label=f\"Training {key}\")\n",
    "        axes[i].plot(epochs, val_loss, label=f\"Validation {key}\")\n",
    "        axes[i].set_title(f\"Training and validation {key}\")\n",
    "        axes[i].set_xlabel(\"epochs\")\n",
    "        axes[i].set_ylabel(key)\n",
    "        axes[i].legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(\n",
    "        np.min(history.history[\"val_loss\"]),\n",
    "        \"The best number of epocs for the validation loss is\",\n",
    "        np.argmin(history.history[\"val_loss\"]) + 1,\n",
    "    )\n",
    "    print(\n",
    "        np.max(history.history[\"val_accuracy\"]),\n",
    "        \"The best number of epocs for the validation accuracy is\",\n",
    "        np.argmax(history.history[\"val_accuracy\"]) + 1,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True,\n",
    "        reduction='none'\n",
    "    )\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "# def masked_acc(y_true, y_pred):\n",
    "#     # Calculate the loss for each item in the batch.\n",
    "#     y_pred = tf.argmax(y_pred, axis=-1)\n",
    "#     y_pred = tf.cast(y_pred, dtype=y_true.dtype)\n",
    "#     match = tf.cast(y_true == y_pred, dtype=tf.float32)\n",
    "#     mask = tf.cast(y_true != 0, dtype=tf.float32)\n",
    "#     return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "# @see https://www.tensorflow.org/text/tutorials/transformer\n",
    "def masked_acc(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=2)\n",
    "    y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "    match = y_true == y_pred\n",
    "    mask = y_true != 0\n",
    "    match = match & mask\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    text_file = keras.utils.get_file(\n",
    "        fname=\"spa-eng.zip\",\n",
    "        origin=(\n",
    "            \"http://storage.googleapis.com/download.tensorflow.org/data/\"\n",
    "            + \"spa-eng.zip\"\n",
    "        ),\n",
    "        extract=True,\n",
    "    )\n",
    "    return pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\"\n",
    "\n",
    "\n",
    "def read_data(filepath):\n",
    "    with open(filepath) as f:\n",
    "        lines = f.read().split(\"\\n\")[:-1]\n",
    "        text_pairs = []\n",
    "        for line in lines:\n",
    "            eng, spa = line.split(\"\\t\")\n",
    "            spa = \"[start] \" + spa + \" [end]\"\n",
    "            text_pairs.append((eng, spa))\n",
    "    return text_pairs\n",
    "\n",
    "\n",
    "def split_train_val_test(text_pairs):\n",
    "    random.shuffle(text_pairs)\n",
    "    num_val_samples = int(0.15 * len(text_pairs))\n",
    "    num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "    train_pairs = text_pairs[:num_train_samples]\n",
    "    val_end_index = num_train_samples + num_val_samples\n",
    "    val_pairs = text_pairs[num_train_samples:val_end_index]\n",
    "    test_pairs = text_pairs[val_end_index:]\n",
    "    return train_pairs, val_pairs, test_pairs\n",
    "\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase,\n",
    "        \"[%s]\" % re.escape(strip_chars),\n",
    "        \"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_tokenizer(train_pairs, sequence_length, vocab_size):\n",
    "    \"\"\"Preapare English and Spanish tokenizer.\"\"\"\n",
    "    eng_tokenizer = keras.layers.TextVectorization(\n",
    "        max_tokens=vocab_size,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "    )\n",
    "    spa_tokenizer = keras.layers.TextVectorization(\n",
    "        max_tokens=vocab_size,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length + 1,\n",
    "        standardize=custom_standardization,\n",
    "    )\n",
    "    eng_texts, spa_texts = zip(*train_pairs)\n",
    "    eng_tokenizer.adapt(eng_texts)\n",
    "    spa_tokenizer.adapt(spa_texts)\n",
    "    return eng_tokenizer, spa_tokenizer\n",
    "\n",
    "\n",
    "def prepare_datasets(text_pairs, batch_size, eng_tokenizer, spa_tokenizer):\n",
    "    \"\"\"Transform raw text pairs to tf datasets.\"\"\"\n",
    "    eng_texts, spa_texts = zip(*text_pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "\n",
    "    def format_dataset(eng, spa):\n",
    "        \"\"\"Format the dataset given input English and Spanish text.\n",
    "\n",
    "        The output format is:\n",
    "            x: a pair of English and Spanish sentence.\n",
    "            y: The Spanish sentence in x shifts 1 token towards right, because\n",
    "                we are predicting the next token.\n",
    "        \"\"\"\n",
    "        eng = eng_tokenizer(eng)\n",
    "        spa = spa_tokenizer(spa)\n",
    "        return (\n",
    "            {\n",
    "                \"encoder_inputs\": eng,\n",
    "                \"decoder_inputs\": spa[:, :-1],\n",
    "            },\n",
    "            spa[:, 1:],\n",
    "            tf.cast((spa[:, 1:] != 0), \"float32\"),  # mask as sample weights\n",
    "        )\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "\n",
    "def get_dataset_and_tokenizer(sequence_length, vocab_size, batch_size):\n",
    "    \"\"\"Main method to get the formatted machine translation dataset.\"\"\"\n",
    "    filepath = download_data()\n",
    "    text_pairs = read_data(filepath)\n",
    "    train_pairs, val_pairs, test_pairs = split_train_val_test(text_pairs)\n",
    "    eng_tokenizer, spa_tokenizer = prepare_tokenizer(\n",
    "        train_pairs, sequence_length, vocab_size\n",
    "    )\n",
    "    train_ds = prepare_datasets(\n",
    "        train_pairs,\n",
    "        batch_size,\n",
    "        eng_tokenizer,\n",
    "        spa_tokenizer,\n",
    "    )\n",
    "    val_ds = prepare_datasets(\n",
    "        val_pairs,\n",
    "        batch_size,\n",
    "        eng_tokenizer,\n",
    "        spa_tokenizer,\n",
    "    )\n",
    "    test_ds = prepare_datasets(\n",
    "        test_pairs,\n",
    "        batch_size,\n",
    "        eng_tokenizer,\n",
    "        spa_tokenizer,\n",
    "    )\n",
    "    return (train_ds, val_ds, test_ds), (eng_tokenizer, spa_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "class TranslationModel(keras.Model):\n",
    "    \"\"\"The machine translation model.\n",
    "\n",
    "    The model is an encoder-decoder structure model. The encoder is a stack of\n",
    "    `keras_nlp.TransformerEncoder`, and the decoder is a stack of\n",
    "    `keras_nlp.TransformerDecoder`. We also pass in the tokenizer for encoder\n",
    "    and decoder so that during save/load, the tokenizer is also kept.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_tokenizer,\n",
    "        decoder_tokenizer,\n",
    "        num_encoders,\n",
    "        num_decoders,\n",
    "        num_heads,\n",
    "        transformer_intermediate_dim,\n",
    "        encoder_vocabulary_size,\n",
    "        decoder_vocabulary_size,\n",
    "        embedding_dim,\n",
    "        sequence_length,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoders = []\n",
    "        self.decoders = []\n",
    "        for _ in range(num_encoders):\n",
    "            self.encoders.append(\n",
    "                keras_nlp.layers.TransformerEncoder(\n",
    "                    num_heads=num_heads,\n",
    "                    intermediate_dim=transformer_intermediate_dim,\n",
    "                )\n",
    "            )\n",
    "        for _ in range(num_decoders):\n",
    "            self.decoders.append(\n",
    "                keras_nlp.layers.TransformerDecoder(\n",
    "                    num_heads=num_heads,\n",
    "                    intermediate_dim=transformer_intermediate_dim,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.encoder_tokenizer = encoder_tokenizer\n",
    "        self.decoder_tokenizer = decoder_tokenizer\n",
    "\n",
    "        self.encoder_embedding = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "            vocabulary_size=encoder_vocabulary_size,\n",
    "            sequence_length=sequence_length,\n",
    "            embedding_dim=embedding_dim,\n",
    "            mask_zero=True,\n",
    "        )\n",
    "\n",
    "        self.decoder_embedding = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "            vocabulary_size=decoder_vocabulary_size,\n",
    "            sequence_length=sequence_length,\n",
    "            embedding_dim=embedding_dim,\n",
    "            mask_zero=True,\n",
    "        )\n",
    "\n",
    "        self.dense = keras.layers.Dense(\n",
    "            decoder_vocabulary_size,\n",
    "            activation=\"softmax\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_input, decoder_input = (\n",
    "            inputs[\"encoder_inputs\"],\n",
    "            inputs[\"decoder_inputs\"],\n",
    "        )\n",
    "        encoded = self.encoder_embedding(encoder_input)\n",
    "        for encoder in self.encoders:\n",
    "            encoded = encoder(inputs=encoded)\n",
    "\n",
    "        decoded = self.decoder_embedding(decoder_input)\n",
    "        for decoder in self.decoders:\n",
    "            decoded = decoder(\n",
    "                decoder_sequence=decoded,\n",
    "                encoder_sequence=encoded,\n",
    "                use_causal_mask=True,\n",
    "            )\n",
    "\n",
    "        output = self.dense(decoded)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \"encoder_tokenizer\": self.encoder_tokenizer.get_config(),\n",
    "            \"decoder_tokenizer\": self.decoder_tokenizer.get_config(),\n",
    "            \"num_encoders\": len(self.encoders),\n",
    "            \"num_decoders\": len(self.decoders),\n",
    "            \"num_heads\": self.encoders[0].num_heads,\n",
    "            \"transformer_intermediate_dim\": self.encoders[0].intermediate_dim,\n",
    "            \"encoder_vocabulary_size\": self.encoder_embedding.vocabulary_size,\n",
    "            \"decoder_vocabulary_size\": self.decoder_embedding.vocabulary_size,\n",
    "            \"embedding_dim\": self.encoder_embedding.embedding_dim,\n",
    "            \"sequence_length\": self.encoder_embedding.sequence_length,\n",
    "        })\n",
    "        return config\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        encoder_tokenizer_config = config.pop(\"encoder_tokenizer\")\n",
    "        decoder_tokenizer_config = config.pop(\"decoder_tokenizer\")\n",
    "        encoder_tokenizer = keras.layers.TextVectorization.from_config(encoder_tokenizer_config)\n",
    "        decoder_tokenizer = keras.layers.TextVectorization.from_config(decoder_tokenizer_config)\n",
    "        return cls(encoder_tokenizer=encoder_tokenizer, decoder_tokenizer=decoder_tokenizer, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "        model,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        initial_learning_rate,\n",
    "        decay_steps,\n",
    "        decay_rate,\n",
    "        epochs,\n",
    "        steps_per_epoch):\n",
    "    if decay_rate < 1.0:\n",
    "        learning_rate = keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=initial_learning_rate,\n",
    "            decay_steps=decay_steps,\n",
    "            decay_rate=decay_rate,\n",
    "        )\n",
    "    else:\n",
    "        learning_rate = initial_learning_rate\n",
    "    if f\"{keras.__version__}\".startswith(\"2.\") and is_running_on_apple_sillicon():\n",
    "        optimizer = keras.optimizers.legacy.Adam(\n",
    "            learning_rate=learning_rate,\n",
    "        )\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate,\n",
    "        )\n",
    "    if f\"{keras.__version__}\".startswith(\"2.\"):\n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "            reduction=keras.losses.Reduction.NONE\n",
    "        )\n",
    "    else:\n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "            reduction=None\n",
    "        )\n",
    "    metrics = [\n",
    "        keras.metrics.SparseCategoricalAccuracy(),\n",
    "        #keras.metrics.SparseCategoricalCrossentropy(),\n",
    "        #keras_nlp.metrics.Bleu(), #  This cannot be used here\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "        loss=loss_fn,\n",
    "        weighted_metrics=[],\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_ds,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "    )\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "        num_encoders,\n",
    "        num_decoders,\n",
    "        num_heads,\n",
    "        transformer_intermediate_dim,\n",
    "        sequence_length,\n",
    "        vocab_size,\n",
    "        batch_size,\n",
    "        embedding_dim,\n",
    "        initial_learning_rate,\n",
    "        decay_steps,\n",
    "        decay_rate,\n",
    "        epochs,\n",
    "        steps_per_epoch):\n",
    "    (\n",
    "        (train_ds, val_ds, test_ds),\n",
    "        (\n",
    "            eng_tokenizer,\n",
    "            spa_tokenizer,\n",
    "        ),\n",
    "    ) = get_dataset_and_tokenizer(\n",
    "        sequence_length, vocab_size, batch_size\n",
    "    )\n",
    "    english_vocab_size = eng_tokenizer.vocabulary_size()\n",
    "    spanish_vocab_size = spa_tokenizer.vocabulary_size()\n",
    "    model = TranslationModel(\n",
    "        encoder_tokenizer=eng_tokenizer,\n",
    "        decoder_tokenizer=spa_tokenizer,\n",
    "        num_encoders=num_encoders,\n",
    "        num_decoders=num_decoders,\n",
    "        num_heads=num_heads,\n",
    "        transformer_intermediate_dim=transformer_intermediate_dim,\n",
    "        encoder_vocabulary_size=english_vocab_size,\n",
    "        decoder_vocabulary_size=spanish_vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        sequence_length=sequence_length,\n",
    "    )\n",
    "\n",
    "    history = run_training(\n",
    "        model,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "    )\n",
    "\n",
    "    if is_running_on_apple_sillicon():\n",
    "        filepath = 'machine_translation_model.keras/machine_translation_model.keras'\n",
    "    else:\n",
    "        filepath = 'machine_translation_model.keras'\n",
    "    print(f\"Saving to {filepath}\")\n",
    "    model.save(filepath=filepath)\n",
    "\n",
    "    print(f\"Successfully saved model to {filepath}\")\n",
    "    return model, filepath, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "EXAMPLES = [\n",
    "    (\n",
    "        \"Tom doesn't listen to anyone.\",\n",
    "        \"[start] Tomás no escucha a nadie. [end]\",\n",
    "    ),\n",
    "    (\"I got soaked to the skin.\", \"[start] Estoy chorreando. [end]\"),\n",
    "    (\"I imagined that.\", \"[start] Me imaginé eso. [end]\"),\n",
    "    (\"The baby is crying.\", \"[start] El bebé está llorando. [end]\"),\n",
    "    (\n",
    "        \"I've never felt so exhilarated.\",\n",
    "        \"[start] Nunca me he sentido tan animado. [end]\",\n",
    "    ),\n",
    "    (\n",
    "        \"Please forgive me for not having written sooner.\",\n",
    "        \"[start] Perdóname por no haberte escrito antes, por favor. [end]\",\n",
    "    ),\n",
    "    (\"I expected more from you.\", \"[start] Esperaba más de vos. [end]\"),\n",
    "    (\"I have a computer.\", \"[start] Tengo un computador. [end]\"),\n",
    "    (\"Dinner's ready!\", \"[start] ¡La cena está lista! [end]\"),\n",
    "    (\"Let me finish.\", \"[start] Déjame terminar. [end]\"),\n",
    "    (\"I trust her.\", \"[start] Yo confío en ella. [end]\"),\n",
    "    (\"I trust him.\", \"[start] Yo confío en él. [end]\"),\n",
    "]\n",
    "\n",
    "def decode_sequence(input_sentence, model, max_sequence_length, lookup_table):\n",
    "    encoder_tokenizer = model.encoder_tokenizer\n",
    "    decoder_tokenizer = model.decoder_tokenizer\n",
    "    tokenized_input = encoder_tokenizer([input_sentence])\n",
    "\n",
    "    start_token = decoder_tokenizer(\"[start]\")[0].numpy()\n",
    "    end_token = decoder_tokenizer(\"[end]\")[0].numpy()\n",
    "\n",
    "    decoded_sentence = [start_token]\n",
    "    for i in range(max_sequence_length):\n",
    "        decoder_inputs = tf.convert_to_tensor(\n",
    "            [decoded_sentence],\n",
    "            dtype=\"int64\",\n",
    "        )\n",
    "        decoder_inputs = tf.concat(\n",
    "            [\n",
    "                decoder_inputs,\n",
    "                tf.zeros(\n",
    "                    [1, max_sequence_length - i - 1],\n",
    "                    dtype=\"int64\",\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        input = {\n",
    "            \"encoder_inputs\": tokenized_input,\n",
    "            \"decoder_inputs\": decoder_inputs,\n",
    "        }\n",
    "        predictions = model(input)\n",
    "        predicted_token = np.argmax(predictions[0, i, :])\n",
    "        decoded_sentence.append(predicted_token)\n",
    "        if predicted_token == end_token:\n",
    "            break\n",
    "\n",
    "    detokenized_output = []\n",
    "    for token in decoded_sentence:\n",
    "        detokenized_output.append(lookup_table[token])\n",
    "    return \" \".join(detokenized_output)\n",
    "\n",
    "\n",
    "def predict_main(filepath, examples, sequence_length):\n",
    "    loaded_model = keras.models.load_model(filepath)\n",
    "\n",
    "    decoder_tokenizer = loaded_model.decoder_tokenizer\n",
    "    vocab = decoder_tokenizer.get_vocabulary()\n",
    "    index_lookup_table = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "    translated = []\n",
    "    for example in examples:\n",
    "        translated.append(\n",
    "            decode_sequence(\n",
    "                example[0],\n",
    "                loaded_model,\n",
    "                sequence_length,\n",
    "                index_lookup_table,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        print(\"ENGLISH SENTENCE: \", examples[i][0])\n",
    "        print(\"MACHINE TRANSLATED RESULT: \", translated[i])\n",
    "        print(\"GOLDEN: \", examples[i][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default params\n",
    "FLAGS_learning_rate = 0.001\n",
    "FLAGS_num_epochs = 50 # default=1, but too small\n",
    "FLAGS_steps_per_epoch = None\n",
    "FLAGS_sequence_length = 20 # Input and output sequence length.\n",
    "FLAGS_vocab_size = 15000 # Vocabulary size, required by tokenizer.\n",
    "FLAGS_batch_size = 64\n",
    "FLAGS_num_encoders = 2\n",
    "FLAGS_num_decoders = 2\n",
    "FLAGS_num_heads = 8 # Number of head of the multihead attention.\n",
    "FLAGS_intermediate_dim = 128 # Intermediate dimension (feedforward network) of transformer.\n",
    "FLAGS_model_dim = 64\n",
    "FLAGS_decay_steps = 20\n",
    "FLAGS_decay_rate = 0.98\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    num_encoders=FLAGS_num_encoders,\n",
    "    num_decoders=FLAGS_num_decoders,\n",
    "    num_heads=FLAGS_num_heads,\n",
    "    transformer_intermediate_dim=FLAGS_intermediate_dim,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    "    vocab_size=FLAGS_vocab_size,\n",
    "    batch_size=FLAGS_batch_size,\n",
    "    embedding_dim=FLAGS_model_dim,\n",
    "    initial_learning_rate=FLAGS_learning_rate,\n",
    "    decay_steps=FLAGS_decay_steps,\n",
    "    decay_rate=FLAGS_decay_rate,\n",
    "    epochs=FLAGS_num_epochs,\n",
    "    steps_per_epoch=FLAGS_steps_per_epoch,\n",
    ")\n",
    "plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 90ms/step - loss: 1.9148 - sparse_categorical_accuracy: 0.0887 - val_loss: 1.0073 - val_sparse_categorical_accuracy: 0.1860\n",
      "Epoch 2/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 88ms/step - loss: 0.9248 - sparse_categorical_accuracy: 0.1973 - val_loss: 0.7509 - val_sparse_categorical_accuracy: 0.2194\n",
      "Epoch 3/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 83ms/step - loss: 0.6444 - sparse_categorical_accuracy: 0.2320 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.2291\n",
      "Epoch 4/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 83ms/step - loss: 0.5014 - sparse_categorical_accuracy: 0.2501 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.2332\n",
      "Epoch 5/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 84ms/step - loss: 0.4127 - sparse_categorical_accuracy: 0.2630 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.2354\n",
      "Epoch 6/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 87ms/step - loss: 0.3516 - sparse_categorical_accuracy: 0.2733 - val_loss: 0.6398 - val_sparse_categorical_accuracy: 0.2362\n",
      "Epoch 7/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 86ms/step - loss: 0.3083 - sparse_categorical_accuracy: 0.2812 - val_loss: 0.6444 - val_sparse_categorical_accuracy: 0.2364\n",
      "Epoch 8/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 87ms/step - loss: 0.2753 - sparse_categorical_accuracy: 0.2880 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.2338\n",
      "Epoch 9/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 88ms/step - loss: 0.2499 - sparse_categorical_accuracy: 0.2934 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.2345\n",
      "Epoch 10/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 89ms/step - loss: 0.2295 - sparse_categorical_accuracy: 0.2978 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.2359\n",
      "Epoch 11/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 86ms/step - loss: 0.2124 - sparse_categorical_accuracy: 0.3017 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.2359\n",
      "Epoch 12/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 87ms/step - loss: 0.1980 - sparse_categorical_accuracy: 0.3049 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.2357\n",
      "Epoch 13/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 91ms/step - loss: 0.1856 - sparse_categorical_accuracy: 0.3078 - val_loss: 0.7115 - val_sparse_categorical_accuracy: 0.2355\n",
      "Epoch 14/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 91ms/step - loss: 0.1753 - sparse_categorical_accuracy: 0.3102 - val_loss: 0.7210 - val_sparse_categorical_accuracy: 0.2352\n",
      "Epoch 15/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 92ms/step - loss: 0.1663 - sparse_categorical_accuracy: 0.3123 - val_loss: 0.7308 - val_sparse_categorical_accuracy: 0.2350\n",
      "Epoch 16/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 86ms/step - loss: 0.1586 - sparse_categorical_accuracy: 0.3141 - val_loss: 0.7404 - val_sparse_categorical_accuracy: 0.2347\n",
      "Epoch 17/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 88ms/step - loss: 0.1520 - sparse_categorical_accuracy: 0.3156 - val_loss: 0.7493 - val_sparse_categorical_accuracy: 0.2344\n",
      "Epoch 18/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 85ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.3169 - val_loss: 0.7577 - val_sparse_categorical_accuracy: 0.2341\n",
      "Epoch 19/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 84ms/step - loss: 0.1413 - sparse_categorical_accuracy: 0.3181 - val_loss: 0.7651 - val_sparse_categorical_accuracy: 0.2338\n",
      "Epoch 20/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 88ms/step - loss: 0.1370 - sparse_categorical_accuracy: 0.3192 - val_loss: 0.7720 - val_sparse_categorical_accuracy: 0.2336\n",
      "Epoch 21/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 87ms/step - loss: 0.1332 - sparse_categorical_accuracy: 0.3202 - val_loss: 0.7783 - val_sparse_categorical_accuracy: 0.2334\n",
      "Epoch 22/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 88ms/step - loss: 0.1299 - sparse_categorical_accuracy: 0.3210 - val_loss: 0.7843 - val_sparse_categorical_accuracy: 0.2332\n",
      "Epoch 23/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 89ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.3216 - val_loss: 0.7897 - val_sparse_categorical_accuracy: 0.2330\n",
      "Epoch 24/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 91ms/step - loss: 0.1246 - sparse_categorical_accuracy: 0.3222 - val_loss: 0.7947 - val_sparse_categorical_accuracy: 0.2329\n",
      "Epoch 25/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 113ms/step - loss: 0.1223 - sparse_categorical_accuracy: 0.3227 - val_loss: 0.7990 - val_sparse_categorical_accuracy: 0.2327\n",
      "Epoch 26/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1178s\u001b[0m 905ms/step - loss: 0.1204 - sparse_categorical_accuracy: 0.3232 - val_loss: 0.8030 - val_sparse_categorical_accuracy: 0.2326\n",
      "Epoch 27/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 96ms/step - loss: 0.1187 - sparse_categorical_accuracy: 0.3236 - val_loss: 0.8064 - val_sparse_categorical_accuracy: 0.2324\n",
      "Epoch 28/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 91ms/step - loss: 0.1172 - sparse_categorical_accuracy: 0.3240 - val_loss: 0.8094 - val_sparse_categorical_accuracy: 0.2324\n",
      "Epoch 29/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 98ms/step - loss: 0.1159 - sparse_categorical_accuracy: 0.3243 - val_loss: 0.8120 - val_sparse_categorical_accuracy: 0.2324\n",
      "Epoch 30/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 94ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.3246 - val_loss: 0.8142 - val_sparse_categorical_accuracy: 0.2324\n",
      "Epoch 31/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 88ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.3248 - val_loss: 0.8162 - val_sparse_categorical_accuracy: 0.2323\n",
      "Epoch 32/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 87ms/step - loss: 0.1128 - sparse_categorical_accuracy: 0.3250 - val_loss: 0.8179 - val_sparse_categorical_accuracy: 0.2323\n",
      "Epoch 33/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 89ms/step - loss: 0.1120 - sparse_categorical_accuracy: 0.3253 - val_loss: 0.8194 - val_sparse_categorical_accuracy: 0.2323\n",
      "Epoch 34/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 87ms/step - loss: 0.1113 - sparse_categorical_accuracy: 0.3254 - val_loss: 0.8207 - val_sparse_categorical_accuracy: 0.2323\n",
      "Epoch 35/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 87ms/step - loss: 0.1107 - sparse_categorical_accuracy: 0.3256 - val_loss: 0.8219 - val_sparse_categorical_accuracy: 0.2323\n",
      "Epoch 36/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 86ms/step - loss: 0.1101 - sparse_categorical_accuracy: 0.3257 - val_loss: 0.8229 - val_sparse_categorical_accuracy: 0.2322\n",
      "Epoch 37/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 86ms/step - loss: 0.1097 - sparse_categorical_accuracy: 0.3258 - val_loss: 0.8238 - val_sparse_categorical_accuracy: 0.2322\n",
      "Epoch 38/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 86ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.3259 - val_loss: 0.8246 - val_sparse_categorical_accuracy: 0.2322\n",
      "Epoch 39/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 87ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.3260 - val_loss: 0.8253 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 40/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 87ms/step - loss: 0.1085 - sparse_categorical_accuracy: 0.3261 - val_loss: 0.8259 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 41/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 85ms/step - loss: 0.1082 - sparse_categorical_accuracy: 0.3262 - val_loss: 0.8264 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 42/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 85ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.3262 - val_loss: 0.8269 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 43/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 86ms/step - loss: 0.1077 - sparse_categorical_accuracy: 0.3263 - val_loss: 0.8273 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 44/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 87ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.3264 - val_loss: 0.8276 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 45/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 88ms/step - loss: 0.1073 - sparse_categorical_accuracy: 0.3264 - val_loss: 0.8279 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 46/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 86ms/step - loss: 0.1072 - sparse_categorical_accuracy: 0.3265 - val_loss: 0.8282 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 47/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 86ms/step - loss: 0.1070 - sparse_categorical_accuracy: 0.3265 - val_loss: 0.8285 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 48/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 90ms/step - loss: 0.1069 - sparse_categorical_accuracy: 0.3265 - val_loss: 0.8287 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 49/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 95ms/step - loss: 0.1068 - sparse_categorical_accuracy: 0.3266 - val_loss: 0.8289 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 50/50\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 94ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.3266 - val_loss: 0.8290 - val_sparse_categorical_accuracy: 0.2322\n",
      "Saving to machine_translation_model.keras/machine_translation_model.keras\n",
      "Successfully saved model to machine_translation_model.keras/machine_translation_model.keras\n"
     ]
    }
   ],
   "source": [
    "# minimum viable params\n",
    "# Epoch 24/50 - loss: 0.1224 - sparse_categorical_accuracy: 0.8007 - val_loss: 0.8010 - val_sparse_categorical_accuracy: 0.5755\n",
    "FLAGS_learning_rate = 0.001\n",
    "FLAGS_num_epochs = 50\n",
    "FLAGS_steps_per_epoch = None\n",
    "FLAGS_sequence_length = 20\n",
    "FLAGS_vocab_size = 15000\n",
    "FLAGS_batch_size = 64\n",
    "FLAGS_num_encoders = 1\n",
    "FLAGS_num_decoders = 1\n",
    "FLAGS_num_heads = 6\n",
    "FLAGS_intermediate_dim = 512\n",
    "FLAGS_model_dim = 64\n",
    "FLAGS_decay_steps = 100\n",
    "FLAGS_decay_rate = 0.99\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    num_encoders=FLAGS_num_encoders,\n",
    "    num_decoders=FLAGS_num_decoders,\n",
    "    num_heads=FLAGS_num_heads,\n",
    "    transformer_intermediate_dim=FLAGS_intermediate_dim,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    "    vocab_size=FLAGS_vocab_size,\n",
    "    batch_size=FLAGS_batch_size,\n",
    "    embedding_dim=FLAGS_model_dim,\n",
    "    initial_learning_rate=FLAGS_learning_rate,\n",
    "    decay_steps=FLAGS_decay_steps,\n",
    "    decay_rate=FLAGS_decay_rate,\n",
    "    epochs=FLAGS_num_epochs,\n",
    "    steps_per_epoch=FLAGS_steps_per_epoch,\n",
    ")\n",
    "# plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH SENTENCE:  Tom doesn't listen to anyone.\n",
      "MACHINE TRANSLATED RESULT:  [start] tom no escucha a nadie [end]\n",
      "GOLDEN:  [start] Tomás no escucha a nadie. [end]\n",
      "ENGLISH SENTENCE:  I got soaked to the skin.\n",
      "MACHINE TRANSLATED RESULT:  [start] estoy [UNK] [end]\n",
      "GOLDEN:  [start] Estoy chorreando. [end]\n",
      "ENGLISH SENTENCE:  I imagined that.\n",
      "MACHINE TRANSLATED RESULT:  [start] me imaginé eso [end]\n",
      "GOLDEN:  [start] Me imaginé eso. [end]\n",
      "ENGLISH SENTENCE:  The baby is crying.\n",
      "MACHINE TRANSLATED RESULT:  [start] el bebé está llorando [end]\n",
      "GOLDEN:  [start] El bebé está llorando. [end]\n",
      "ENGLISH SENTENCE:  I've never felt so exhilarated.\n",
      "MACHINE TRANSLATED RESULT:  [start] nunca he quedado tan [UNK] en vías de cansancio [end]\n",
      "GOLDEN:  [start] Nunca me he sentido tan animado. [end]\n",
      "ENGLISH SENTENCE:  Please forgive me for not having written sooner.\n",
      "MACHINE TRANSLATED RESULT:  [start] perdóname por no haber escrito antes de que esté escrito [end]\n",
      "GOLDEN:  [start] Perdóname por no haberte escrito antes, por favor. [end]\n",
      "ENGLISH SENTENCE:  I expected more from you.\n",
      "MACHINE TRANSLATED RESULT:  [start] esperaba más de ti [end]\n",
      "GOLDEN:  [start] Esperaba más de vos. [end]\n",
      "ENGLISH SENTENCE:  I have a computer.\n",
      "MACHINE TRANSLATED RESULT:  [start] tengo un ordenador [end]\n",
      "GOLDEN:  [start] Tengo un computador. [end]\n",
      "ENGLISH SENTENCE:  Dinner's ready!\n",
      "MACHINE TRANSLATED RESULT:  [start] la cena está preparada [end]\n",
      "GOLDEN:  [start] ¡La cena está lista! [end]\n",
      "ENGLISH SENTENCE:  Let me finish.\n",
      "MACHINE TRANSLATED RESULT:  [start] déjame terminar [end]\n",
      "GOLDEN:  [start] Déjame terminar. [end]\n",
      "ENGLISH SENTENCE:  I trust her.\n",
      "MACHINE TRANSLATED RESULT:  [start] yo confío en ella [end]\n",
      "GOLDEN:  [start] Yo confío en ella. [end]\n",
      "ENGLISH SENTENCE:  I trust him.\n",
      "MACHINE TRANSLATED RESULT:  [start] yo confío en él [end]\n",
      "GOLDEN:  [start] Yo confío en él. [end]\n"
     ]
    }
   ],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGS_learning_rate = 0.001 # pegasus: 0.0005 > text generation: 2e-6\n",
    "# minimum viable params\n",
    "FLAGS_learning_rate = 0.001\n",
    "FLAGS_num_epochs = 50\n",
    "FLAGS_steps_per_epoch = None\n",
    "FLAGS_sequence_length = 20\n",
    "FLAGS_vocab_size = 15000\n",
    "FLAGS_batch_size = 64\n",
    "FLAGS_num_encoders = 1\n",
    "FLAGS_num_decoders = 1\n",
    "FLAGS_num_heads = 6\n",
    "FLAGS_intermediate_dim = 512\n",
    "FLAGS_model_dim = 64\n",
    "FLAGS_decay_steps = 20\n",
    "FLAGS_decay_rate = 0.98\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    num_encoders=FLAGS_num_encoders,\n",
    "    num_decoders=FLAGS_num_decoders,\n",
    "    num_heads=FLAGS_num_heads,\n",
    "    transformer_intermediate_dim=FLAGS_intermediate_dim,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    "    vocab_size=FLAGS_vocab_size,\n",
    "    batch_size=FLAGS_batch_size,\n",
    "    embedding_dim=FLAGS_model_dim,\n",
    "    initial_learning_rate=FLAGS_learning_rate,\n",
    "    decay_steps=FLAGS_decay_steps,\n",
    "    decay_rate=FLAGS_decay_rate,\n",
    "    epochs=FLAGS_num_epochs,\n",
    "    steps_per_epoch=FLAGS_steps_per_epoch,\n",
    ")\n",
    "plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum viable params with no decay\n",
    "# Epoch 24/50 - loss: 0.1224 - sparse_categorical_accuracy: 0.8007 - val_loss: 0.8010 - val_sparse_categorical_accuracy: 0.5755\n",
    "FLAGS_learning_rate = 0.001\n",
    "FLAGS_num_epochs = 50\n",
    "FLAGS_steps_per_epoch = None\n",
    "FLAGS_sequence_length = 20\n",
    "FLAGS_vocab_size = 15000\n",
    "FLAGS_batch_size = 64\n",
    "FLAGS_num_encoders = 1\n",
    "FLAGS_num_decoders = 1\n",
    "FLAGS_num_heads = 6\n",
    "FLAGS_intermediate_dim = 512\n",
    "FLAGS_model_dim = 64\n",
    "FLAGS_decay_steps = 100\n",
    "FLAGS_decay_rate = 1.0\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    num_encoders=FLAGS_num_encoders,\n",
    "    num_decoders=FLAGS_num_decoders,\n",
    "    num_heads=FLAGS_num_heads,\n",
    "    transformer_intermediate_dim=FLAGS_intermediate_dim,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    "    vocab_size=FLAGS_vocab_size,\n",
    "    batch_size=FLAGS_batch_size,\n",
    "    embedding_dim=FLAGS_model_dim,\n",
    "    initial_learning_rate=FLAGS_learning_rate,\n",
    "    decay_steps=FLAGS_decay_steps,\n",
    "    decay_rate=FLAGS_decay_rate,\n",
    "    epochs=FLAGS_num_epochs,\n",
    "    steps_per_epoch=FLAGS_steps_per_epoch,\n",
    ")\n",
    "plot(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_main(\n",
    "    filepath=filepath,\n",
    "    examples=EXAMPLES,\n",
    "    sequence_length=FLAGS_sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
