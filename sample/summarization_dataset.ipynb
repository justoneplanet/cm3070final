{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summarization task of CNN dailymail dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-nlp in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: rouge-score in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: tensorflow-datasets in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (4.9.4)\n",
      "Requirement already satisfied: datasets in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (2.19.1)\n",
      "Requirement already satisfied: keras-core in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-nlp) (0.1.7)\n",
      "Requirement already satisfied: absl-py in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-nlp) (1.4.0)\n",
      "Requirement already satisfied: numpy in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-nlp) (1.26.1)\n",
      "Requirement already satisfied: packaging in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-nlp) (23.1)\n",
      "Requirement already satisfied: regex in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-nlp) (2023.5.5)\n",
      "Requirement already satisfied: rich in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-nlp) (13.7.1)\n",
      "Requirement already satisfied: dm-tree in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-nlp) (0.1.8)\n",
      "Requirement already satisfied: kagglehub in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-nlp) (0.2.5)\n",
      "Requirement already satisfied: nltk in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from rouge-score) (1.15.0)\n",
      "Requirement already satisfied: click in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (8.1.3)\n",
      "Requirement already satisfied: etils>=0.9.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (1.6.0)\n",
      "Requirement already satisfied: promise in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (5.9.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (2.30.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: termcolor in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (2.3.0)\n",
      "Requirement already satisfied: toml in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (4.65.0)\n",
      "Requirement already satisfied: wrapt in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-datasets) (1.14.1)\n",
      "Requirement already satisfied: filelock in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (3.12.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: xxhash in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (0.23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: importlib_resources in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.1.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.17.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (2023.5.7)\n",
      "Requirement already satisfied: namex in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-core->keras-nlp) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from keras-core->keras-nlp) (3.11.0)\n",
      "Requirement already satisfied: joblib in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from nltk->rouge-score) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from rich->keras-nlp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from rich->keras-nlp) (2.15.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.62.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install KerasNLP, and so on\n",
    "%pip install keras-nlp rouge-score tensorflow-datasets datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "# SageMaker cannot use @keras.saving\n",
    "from keras import saving\n",
    "\n",
    "# Hyperparameters\n",
    "# BATCH_SIZE = 32 # p3.2xlarge ResourceExhaustedError\n",
    "EMBEDDING_DIM = 64\n",
    "NUM_HEADS = 8\n",
    "INTERMIDIATE_DIM = 1024\n",
    "VOCAB_SIZE = 15000\n",
    "NUM_ENCODERS = 1\n",
    "NUM_DECODERS = 1\n",
    "BATCH_SIZE = 16 # 1 does not work\n",
    "NUM_EPOCHS = 10 # 1 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builders/huggingface_dataset_builder.py:160: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
      "  hf_names = hf_datasets.list_datasets()\n",
      "2024-06-18 14:54:22.299409: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-06-18 14:54:22.299430: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-06-18 14:54:22.299434: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-06-18 14:54:22.299464: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-18 14:54:22.299479: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "if platform.system() == \"Darwin\" and platform.processor() == \"arm\":\n",
    "    args = {\n",
    "        'trust_remote_code': False,\n",
    "    }\n",
    "else:\n",
    "    \"\"\"\n",
    "    When 'trust_remote_code' is False, it does not work on AWS SageMaker.\n",
    "    \"\"\"\n",
    "    args = {\n",
    "    }\n",
    "train_dataset, validation_dataset, test_dataset = tfds.load(\n",
    "    'huggingface:ccdv__cnn_dailymail/3.0.0',\n",
    "    split=['train', 'validation', 'test'],\n",
    "    builder_kwargs=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_input_length = max(len(row[0][0]) for ds in [preprocessed_train_dataset, preprocessed_validation_dataset, preprocessed_test_dataset] for row in ds)\n",
    "# max_target_length = max(len(row[0][1]) for ds in [preprocessed_train_dataset, preprocessed_validation_dataset, preprocessed_test_dataset] for row in ds)\n",
    "# max_decoder_target_length = max(len(row[1]) for ds in [preprocessed_train_dataset, preprocessed_validation_dataset, preprocessed_test_dataset] for row in ds)\n",
    "# max_input_length, max_target_length, max_decoder_target_length\n",
    "\n",
    "summarized_text_size = 256 #  1437 is the longest summarized text in dataset\n",
    "min_summarized_text_size = 32\n",
    "\n",
    "# @TODO The followings should programmatically be derived.\n",
    "max_input_length = 2137\n",
    "max_target_length = summarized_text_size + 1\n",
    "max_decoder_target_length = summarized_text_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for development with 1/10 entries\n",
    "DEVELOPMENT = True\n",
    "if DEVELOPMENT:\n",
    "    if platform.system() == \"Darwin\" and platform.processor() == \"arm\":\n",
    "        NUM_TAKE = 128 # 500\n",
    "        train_dataset = train_dataset.take(NUM_TAKE)\n",
    "        validation_dataset = validation_dataset.take(NUM_TAKE)\n",
    "        test_dataset = test_dataset.take(NUM_TAKE)\n",
    "    else:\n",
    "        # Use 10% dataset.\n",
    "        train_size = len(train_dataset) // 10 * 9\n",
    "        validation_size = len(validation_dataset) // 10 * 9\n",
    "        test_size = len(test_dataset) // 10 * 9\n",
    "        train_dataset = train_dataset.skip(train_size)\n",
    "        validation_dataset = validation_dataset.skip(validation_size)\n",
    "        test_dataset = test_dataset.skip(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 14:54:22.513814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# @see https://github.com/keras-team/keras-nlp/blob/50e041487b1d8b30b34c5fb738db3ed3406363bc/examples/machine_translation/data.py\n",
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase,\n",
    "        \"[%s]\" % re.escape(strip_chars),\n",
    "        \"\",\n",
    "    )\n",
    "\n",
    "vectorization_layer = keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    ragged=True,\n",
    ")\n",
    "# Warning: adapt, which clear the already held data inside, must be called only once.\n",
    "vectorization_layer.adapt(train_dataset.concatenate(validation_dataset).concatenate(test_dataset).batch(BATCH_SIZE).map(lambda row: '[start] ' + row['article'] + ' ' + row['highlights'] + ' [end]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectorization_layer = keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    # @TODO This should be programmatically obtained\n",
    "    output_sequence_length=2137,\n",
    ")\n",
    "target_vectorization_layer = keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=summarized_text_size + 1,\n",
    ")\n",
    "input_vectorization_layer.set_vocabulary(vectorization_layer.get_vocabulary())\n",
    "target_vectorization_layer.set_vocabulary(vectorization_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, ['', '[UNK]', 'the', 'to', 'of', 'a', 'and', 'in'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorization_layer.vocabulary_size(), vectorization_layer.get_vocabulary(include_special_tokens=True)[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be False\n",
    "assert not vectorization_layer(['[start]'])[0] == vectorization_layer(['start'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "vectorization_layer(['This is a pen', 'I am a software engineer'])\n",
    "#vectorization_layer(['This is a pen', 'I am a software engineer']).row_lengths().shape[0]\n",
    "# 2\n",
    "rows = vectorization_layer(['This is a pen', 'I am a software engineer']).row_lengths().shape[0]\n",
    "vectorization_layer(['This is a pen', 'I am a software engineer']).to_tensor(shape=(rows, 10))\n",
    "# .to_tensor()\n",
    "\n",
    "RaggedTensor.to_tensor can make 0-filled Tensor\n",
    "\"\"\"\n",
    "def prepare_dataset(x):\n",
    "    article = input_vectorization_layer(x['article'])\n",
    "    highlights = tf.strings.join(['[start] ', x['highlights'], ' [end]'])\n",
    "    h = vectorization_layer(highlights)\n",
    "    rows = h.row_lengths().shape[0]\n",
    "    sequences = h.to_tensor(shape=(rows, summarized_text_size + 1 + 1))\n",
    "    highlights_decoder_input = sequences[:, :-1] # summarized_text_size - 1\n",
    "    highlights_decoder_output = sequences[:, 1:] # summarized_text_size - 1\n",
    "    return (\n",
    "        (\n",
    "            article, # encoder input\n",
    "            highlights_decoder_input, # decoder input\n",
    "        ),\n",
    "        highlights_decoder_output, # decoder output\n",
    "    )\n",
    "\n",
    "def filter_by_length(row):\n",
    "    highlights = vectorization_layer(row['highlights'])\n",
    "    return min_summarized_text_size <= tf.size(highlights) and tf.size(highlights) <= summarized_text_size\n",
    "\n",
    "preprocessed_train_dataset = train_dataset.filter(filter_by_length).batch(BATCH_SIZE).map(prepare_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "preprocessed_validation_dataset = validation_dataset.filter(filter_by_length).batch(BATCH_SIZE).map(prepare_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "preprocessed_test_dataset = test_dataset.filter(filter_by_length).batch(BATCH_SIZE).map(prepare_dataset, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article:  b'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It\\'s a step that is set to turn an international crisis into a fierce domestic political battle. There are key questions looming over the debate: What did U.N. weapons inspectors find in Syria? What happens if Congress votes no? And how will the Syrian government react? In a televised address from the White House Rose Garden earlier Saturday, the president said he would take his case to Congress, not because he has to -- but because he wants to. \"While I believe I have the authority to carry out this military action without specific congressional authorization, I know that the country will be stronger if we take this course, and our actions will be even more effective,\" he said. \"We should have this debate, because the issues are too big for business as usual.\" Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9. The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday, Sen. Robert Menendez said. Transcript: Read Obama\\'s full remarks . Syrian crisis: Latest developments . U.N. inspectors leave Syria . Obama\\'s remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis. Top U.S. officials have said there\\'s no doubt that the Syrian government was behind it, while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels. British and U.S. intelligence reports say the attack involved chemical weapons, but U.N. officials have stressed the importance of waiting for an official report from inspectors. The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban, who has said he wants to wait until the U.N. team\\'s final report is completed before presenting it to the U.N. Security Council. The Organization for the Prohibition of Chemical Weapons, which nine of the inspectors belong to, said Saturday that it could take up to three weeks to analyze the evidence they collected. \"It needs time to be able to analyze the information and the samples,\" Nesirky said. He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\" Bergen:  Syria is a problem from hell for the U.S. Obama: \\'This menace must be confronted\\' Obama\\'s senior advisers have debated the next steps to take, and the president\\'s comments Saturday came amid mounting political pressure over the situation in Syria. Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire. Some global leaders have expressed support, but the British Parliament\\'s vote against military action earlier this week was a blow to Obama\\'s hopes of getting strong backing from key NATO allies. On Saturday, Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad. Any military attack would not be open-ended or include U.S. ground forces, he said. Syria\\'s alleged use of chemical weapons earlier this month \"is an assault on human dignity,\" the president said. A failure to respond with force, Obama argued,  \"could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm. In a world with many dangers, this menace must be confronted.\" Syria missile strike: What would happen next? Map: U.S. and allied assets around Syria . Obama decision came Friday night . On Friday night, the president made a last-minute decision to consult lawmakers. What will happen if they vote no? It\\'s unclear. A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force. Obama on Saturday continued to shore up support for a strike on the al-Assad government. He spoke by phone with French President Francois Hollande before his Rose Garden speech. \"The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world,\" the White House said. Meanwhile, as uncertainty loomed over how Congress would weigh in, U.S. military officials said they remained at the ready. 5 key assertions: U.S. intelligence report on Syria . Syria: Who wants what after chemical weapons horror . Reactions mixed to Obama\\'s speech . A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama\\'s announcement. \"Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite concerned.\" Some members of Congress applauded Obama\\'s decision. House Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president. \"Under the Constitution, the responsibility to declare war lies with Congress,\" the Republican lawmakers said. \"We are glad the president is seeking authorization for any military action in Syria in response to serious, substantive questions being raised.\" More than 160 legislators, including 63 of Obama\\'s fellow Democrats, had signed letters calling for either a vote or at least a \"full debate\" before any U.S. action. British Prime Minister David Cameron, whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week, responded to Obama\\'s speech in a Twitter post Saturday. \"I understand and support Barack Obama\\'s position on Syria,\" Cameron said. An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory. \"The main reason Obama is turning to the Congress:  the military operation did not get enough support either in the world, among allies of the US or in the United States itself,\" Alexei Pushkov, chairman of the international-affairs committee of the Russian State Duma, said in a Twitter post. In the United States, scattered groups of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans...we\\'re just tired of the United States getting involved and invading and bombing other countries,\" said Robin Rosecrans, who was among hundreds at a Los Angeles demonstration. What do Syria\\'s neighbors think? Why Russia, China, Iran stand by Assad . Syria\\'s government unfazed . After Obama\\'s speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels. Syria\\'s prime minister appeared unfazed by the saber-rattling. \"The Syrian Army\\'s status is on maximum readiness and fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy, according to a banner on Syria State TV that was broadcast prior to Obama\\'s address. An anchor on Syrian state television said Obama \"appeared to be preparing for an aggression on Syria based on repeated lies.\" A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel, Turkey, some Arabs and right-wing extremists in the United States. \"I think he has done well by doing what Cameron did in terms of taking the issue to Parliament,\" said Bashar Jaafari, Syria\\'s ambassador to the United Nations. Both Obama and Cameron, he said, \"climbed to the top of the tree and don\\'t know how to get down.\" The Syrian government has denied that it used chemical weapons in the August 21 attack, saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it. British intelligence had put the number of people killed in the attack at more than 350. On Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429, more than 400 of them children. No explanation was offered for the discrepancy. Iran: U.S. military action in Syria would spark \\'disaster\\' Opinion: Why strikes in Syria are a bad idea .'\n",
      "highlights:  b'Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .'\n",
      "encoder input:  (16, 2137) tf.Tensor(\n",
      "[[  34  187   52 ...    0    0    0]\n",
      " [  64 8762 3140 ...    0    0    0]\n",
      " [2028  125 3032 ...    0    0    0]\n",
      " ...\n",
      " [ 105 1908  124 ...    0    0    0]\n",
      " [1336  125   64 ...    0    0    0]\n",
      " [  64 4539 1637 ...    0    0    0]], shape=(10, 2137), dtype=int64)\n",
      "decoder input:  (16, 257) tf.Tensor(\n",
      "[[  65  541  187 ...    0    0    0]\n",
      " [  65 8762 3140 ...    0    0    0]\n",
      " [  65    2 1465 ...    0    0    0]\n",
      " ...\n",
      " [  65 1908  124 ...    0    0    0]\n",
      " [  65   59 3469 ...    0    0    0]\n",
      " [  65    2 1637 ...    0    0    0]], shape=(10, 257), dtype=int64)\n",
      "decoder output:  (16, 257) tf.Tensor(\n",
      "[[ 541  187  216 ...    0    0    0]\n",
      " [8762 3140 2103 ...    0    0    0]\n",
      " [   2 1465    7 ...    0    0    0]\n",
      " ...\n",
      " [1908  124    9 ...    0    0    0]\n",
      " [  59 3469 6347 ...    0    0    0]\n",
      " [   2 1637 3283 ...    0    0    0]], shape=(10, 257), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for entry in train_dataset.take(1):\n",
    "    print('article: ', entry['article'].numpy())\n",
    "    print('highlights: ', entry['highlights'].numpy())\n",
    "for entry in preprocessed_train_dataset.take(1):\n",
    "    print('encoder input: ', entry[0][0].shape, entry[0][0][:10])\n",
    "    print('decoder input: ', entry[0][1].shape, entry[0][1][:10])\n",
    "    print('decoder output: ', entry[1].shape, entry[1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@saving.register_keras_serializable()\n",
    "class TransformerEncoderDecoderModel(keras.Model):\n",
    "    \"\"\"\n",
    "    Build Transformer Encoder Decoder model\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_tokenizer,\n",
    "        decoder_tokenizer,\n",
    "        max_input_length,\n",
    "        max_target_length,\n",
    "        embedding_dim,\n",
    "        encoder_vocabulary_size,\n",
    "        decoder_vocabulary_size,\n",
    "        num_encoders,\n",
    "        num_decoders,\n",
    "        encoder_num_heads,\n",
    "        encoder_transformer_intermediate_dim,\n",
    "        decoder_num_heads,\n",
    "        decoder_transformer_intermediate_dim,\n",
    "        **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.encoder_tokenizer = encoder_tokenizer\n",
    "        self.decoder_tokenizer = decoder_tokenizer\n",
    "        self.encoders = []\n",
    "        self.decoders = []\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_embedding = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "            vocabulary_size=encoder_vocabulary_size,\n",
    "            sequence_length=max_input_length,\n",
    "            embedding_dim=embedding_dim,\n",
    "            mask_zero=True,\n",
    "            name=\"encoder_embedding\",\n",
    "        )\n",
    "        for i in range(num_encoders):\n",
    "            self.encoders.append(\n",
    "                keras_nlp.layers.TransformerEncoder(\n",
    "                    num_heads=encoder_num_heads,\n",
    "                    intermediate_dim=encoder_transformer_intermediate_dim,\n",
    "                    name=f\"transformer_encoder_{i}\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_embedding = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "            vocabulary_size=decoder_vocabulary_size,\n",
    "            sequence_length=max_target_length,\n",
    "            embedding_dim=embedding_dim,\n",
    "            mask_zero=True,\n",
    "            name=\"decoder_embedding\",\n",
    "        )\n",
    "        for i in range(num_decoders):\n",
    "            self.decoders.append(\n",
    "                keras_nlp.layers.TransformerDecoder(\n",
    "                    num_heads=decoder_num_heads,\n",
    "                    intermediate_dim=decoder_transformer_intermediate_dim,\n",
    "                    name=f\"transformer_decoder_{i}\",\n",
    "                )\n",
    "            )\n",
    "        self.dense = keras.layers.Dense(\n",
    "            decoder_vocabulary_size,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder_embedding(inputs[0])\n",
    "        for encoder in self.encoders:\n",
    "            encoded = encoder(inputs=encoded)\n",
    "\n",
    "        decoded = self.decoder_embedding(inputs[1])\n",
    "        for decoder in self.decoders:\n",
    "            decoded = decoder(\n",
    "                decoder_sequence=decoded,\n",
    "                encoder_sequence=encoded,\n",
    "                use_causal_mask=True,\n",
    "            )\n",
    "\n",
    "        output = self.dense(decoded)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        #config = super(TransformerEncoderDecoderModel, self).get_config()\n",
    "        config.update({\n",
    "            \"encoder_tokenizer\": self.encoder_tokenizer.get_config(),\n",
    "            \"decoder_tokenizer\": self.decoder_tokenizer.get_config(),\n",
    "            \"max_input_length\": self.encoder_embedding.sequence_length,\n",
    "            \"max_target_length\": self.decoder_embedding.sequence_length,\n",
    "            \"embedding_dim\": self.encoder_embedding.embedding_dim,\n",
    "            \"encoder_vocabulary_size\": self.encoder_embedding.vocabulary_size,\n",
    "            \"decoder_vocabulary_size\": self.decoder_embedding.vocabulary_size,\n",
    "            \"num_encoders\": len(self.encoders),\n",
    "            \"num_decoders\": len(self.decoders),\n",
    "            \"encoder_num_heads\": self.encoders[0].num_heads,\n",
    "            \"encoder_transformer_intermediate_dim\": self.encoders[0].intermediate_dim,\n",
    "            \"decoder_num_heads\": self.decoders[0].num_heads,\n",
    "            \"decoder_transformer_intermediate_dim\": self.decoders[0].intermediate_dim,\n",
    "        })\n",
    "        return config\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        encoder_tokenizer_config = config.pop(\"encoder_tokenizer\")\n",
    "        decoder_tokenizer_config = config.pop(\"decoder_tokenizer\")\n",
    "        encoder_tokenizer = keras.layers.TextVectorization.from_config(encoder_tokenizer_config)\n",
    "        decoder_tokenizer = keras.layers.TextVectorization.from_config(decoder_tokenizer_config)\n",
    "        return cls(\n",
    "            encoder_tokenizer=encoder_tokenizer,\n",
    "            decoder_tokenizer=decoder_tokenizer,\n",
    "            **config\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=20,\n",
    "    decay_rate=0.99,\n",
    ")\n",
    "if platform.system() == \"Darwin\" and platform.processor() == \"arm\":\n",
    "    \"\"\"\n",
    "    Apple Silicon mac shows tht following warning.\n",
    "    WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs,\n",
    "    please use the legacy Keras optimizer instead,\n",
    "    located at `tf.keras.optimizers.legacy.Adam`\n",
    "    Therefore, keras.optimizers.legacy.Adam is used.\n",
    "    \"\"\"\n",
    "    optimizer = keras.optimizers.legacy.RMSprop()\n",
    "else:\n",
    "    optimizer = keras.optimizers.RMSprop()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "    reduction=keras.losses.Reduction.NONE\n",
    ")\n",
    "model = TransformerEncoderDecoderModel(\n",
    "    encoder_tokenizer=input_vectorization_layer,\n",
    "    decoder_tokenizer=target_vectorization_layer,\n",
    "    max_input_length=max_input_length,\n",
    "    max_target_length=max_target_length,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    encoder_vocabulary_size=VOCAB_SIZE,\n",
    "    decoder_vocabulary_size=VOCAB_SIZE,\n",
    "    num_encoders=NUM_ENCODERS,\n",
    "    num_decoders=NUM_DECODERS,\n",
    "    encoder_num_heads=NUM_HEADS,\n",
    "    encoder_transformer_intermediate_dim=INTERMIDIATE_DIM,\n",
    "    decoder_num_heads=NUM_HEADS,\n",
    "    decoder_transformer_intermediate_dim=INTERMIDIATE_DIM,\n",
    "    name=\"transformer_text_summarization_model\",\n",
    ")\n",
    "# Note\n",
    "# In the case that the dataset is large and the dimension is small,\n",
    "# the learning rate of Adam needed to be smaller.\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy()\n",
    "        # 'accuracy', #  This should not be used.\n",
    "        # \"loss\", # This is not necessarily specified.\n",
    "        # keras_nlp.metrics.RougeL()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 47s 5s/step - loss: 1.5873 - sparse_categorical_accuracy: 0.0267 - val_loss: 1.1739 - val_sparse_categorical_accuracy: 0.0381\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 38s 5s/step - loss: 1.4268 - sparse_categorical_accuracy: 0.0399 - val_loss: 1.1148 - val_sparse_categorical_accuracy: 0.0395\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 35s 5s/step - loss: 1.3270 - sparse_categorical_accuracy: 0.0452 - val_loss: 1.0801 - val_sparse_categorical_accuracy: 0.0432\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 37s 5s/step - loss: 1.2606 - sparse_categorical_accuracy: 0.0595 - val_loss: 1.0606 - val_sparse_categorical_accuracy: 0.0471\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 37s 5s/step - loss: 1.2156 - sparse_categorical_accuracy: 0.0698 - val_loss: 1.0513 - val_sparse_categorical_accuracy: 0.0673\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 38s 5s/step - loss: 1.1828 - sparse_categorical_accuracy: 0.0764 - val_loss: 1.0480 - val_sparse_categorical_accuracy: 0.0701\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 40s 5s/step - loss: 1.1556 - sparse_categorical_accuracy: 0.0785 - val_loss: 1.0442 - val_sparse_categorical_accuracy: 0.0721\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 38s 5s/step - loss: 1.1297 - sparse_categorical_accuracy: 0.0862 - val_loss: 1.0507 - val_sparse_categorical_accuracy: 0.0703\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 43s 6s/step - loss: 1.1042 - sparse_categorical_accuracy: 0.0881 - val_loss: 1.0450 - val_sparse_categorical_accuracy: 0.0710\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 53s 7s/step - loss: 1.0759 - sparse_categorical_accuracy: 0.1045 - val_loss: 1.0416 - val_sparse_categorical_accuracy: 0.0698\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = model.fit(\n",
    "    preprocessed_train_dataset,\n",
    "    validation_data=preprocessed_validation_dataset,\n",
    "    # Generally, 100 to 200 is used as the epoch number for generative models\n",
    "    # However, because this is a prototype, the number is intentionally small.\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # steps_per_epoch=2,\n",
    ")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('text_classification.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 17s 2s/step - loss: 1.0447 - sparse_categorical_accuracy: 0.0784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.044676423072815, 0.07844474911689758]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss = model.evaluate(\n",
    "    preprocessed_test_dataset,\n",
    ")\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: \n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles. The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital. \"I'm proud of myself and I'll continue to work to dominate for as long as possible,\" Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics. Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems. Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt. Earlier, Jamaica's women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds. Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover. The British quartet, who were initially fourth, were promoted to the bronze which eluded their men's team. Fraser-Pryce, like Bolt aged 26, became the first woman to achieve three golds in the 100-200 and the relay. In other final action on the last day of the championships, France's Teddy Tamgho became the third man to leap over 18m in the triple jump, exceeding the mark by four centimeters to take gold. Germany's Christina Obergfoll finally took gold at global level in the women's javelin after five previous silvers, while Kenya's Asbel Kiprop easily won a tactical men's 1500m final. Kiprop's compatriot Eunice Jepkoech Sum was a surprise winner of the women's 800m. Bolt's final dash for golden glory brought the eight-day championship to a rousing finale, but while the hosts topped the medal table from the United States there was criticism of the poor attendances in the Luzhniki Stadium. There was further concern when their pole vault gold medalist Yelena Isinbayeva made controversial remarks in support of Russia's new laws, which make \"the propagandizing of non-traditional sexual relations among minors\" a criminal offense. She later attempted to clarify her comments, but there were renewed calls by gay rights groups for a boycott of the 2014 Winter Games in Sochi, the next major sports event in Russia.\n",
      "\n",
      "Summary: [start] the  the  the of the of the  the of the  the  the of the  in the  [end]\n",
      "Original: \n",
      "Vice President Dick Cheney will serve as acting president briefly Saturday while President Bush is anesthetized for a routine colonoscopy, White House spokesman Tony Snow said Friday. Bush is scheduled to have the medical procedure, expected to take about 2 1/2 hours, at the presidential retreat at Camp David, Maryland, Snow said. Bush's last colonoscopy was in June 2002, and no abnormalities were found, Snow said. The president's doctor had recommended a repeat procedure in about five years. The procedure will be supervised by Dr. Richard Tubb and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, Snow said. A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic. Small polyps may be removed during the procedure. Snow said that was the case when Bush had colonoscopies before becoming president. Snow himself is undergoing chemotherapy for cancer that began in his colon and spread to his liver. Snow told reporters he had a chemo session scheduled later Friday. Watch Snow talk about Bush's procedure and his own colon cancer Â» . \"The president wants to encourage everybody to use surveillance,\" Snow said. The American Cancer Society recommends that people without high-risk factors or symptoms begin getting screened for signs of colorectal cancer at age 50. E-mail to a friend .\n",
      "\n",
      "Summary: [start] the  the  the of the of the  the of the  the  the of the  in the  [end]\n",
      "Original: There are two chickens in the garden.\n",
      "Summary: [start] the  the  the of the of the  the of the  the  the of the  in the  [end]\n",
      "Original: Two chickens fell into the swimming pool in the garden.\n",
      "Summary: [start] the  the  the of the of the  the of the  the  the of the  in the  [end]\n"
     ]
    }
   ],
   "source": [
    "def summarize(model, encoder_tokenizer, decoder_tokenizer, text):\n",
    "    \"\"\"\n",
    "    Summarize text\n",
    "    :param text: original text\n",
    "    :return: summarized text\n",
    "    \"\"\"\n",
    "    table = decoder_tokenizer.get_vocabulary()\n",
    "    input_sequence = encoder_tokenizer([text])\n",
    "\n",
    "\n",
    "    start_token = decoder_tokenizer('[start]')[0].numpy()\n",
    "    end_token = decoder_tokenizer('[end]')[0].numpy()\n",
    "    decoded_sentence = [start_token]\n",
    "    for i in range(max_target_length):\n",
    "        decoder_inputs = tf.convert_to_tensor(\n",
    "            [decoded_sentence],\n",
    "            dtype=\"int64\",\n",
    "        )\n",
    "        decoder_inputs = tf.concat(\n",
    "            [\n",
    "                decoder_inputs,\n",
    "                tf.zeros(\n",
    "                    [1, max_target_length - i - 1],\n",
    "                    dtype=\"int64\",\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        predictions = model.predict(\n",
    "            [input_sequence, decoder_inputs],\n",
    "            verbose=0\n",
    "        )\n",
    "        predicted_token = np.argmax(predictions[0, i, :])\n",
    "        decoded_sentence.append(predicted_token)\n",
    "        if predicted_token == end_token:\n",
    "            break\n",
    "\n",
    "    detokenized_output = []\n",
    "    for token in decoded_sentence:\n",
    "        detokenized_output.append(table[token])\n",
    "    return \" \".join(detokenized_output)\n",
    "\n",
    "\n",
    "loaded_model = keras.models.load_model('text_classification.keras')\n",
    "encoder_tokenizer = loaded_model.encoder_tokenizer\n",
    "decoder_tokenizer = loaded_model.decoder_tokenizer\n",
    "\n",
    "# Sample\n",
    "# sample_text = \"Giant pig fell into the swimming pool at his home in Ringwood, Hampshire. It took the efforts of a team of firefighters to winch him out of the water. A wayward horse also had to be rescued from a swimming pool in Sussex.\"\n",
    "# print(\"Original:\", sample_text)\n",
    "# print(\"Summary:\", summarize(sample_text))\n",
    "sample_text = \"\"\"\n",
    "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men\\'s 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles. The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital. \"I\\'m proud of myself and I\\'ll continue to work to dominate for as long as possible,\" Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics. Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems. Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt. Earlier, Jamaica\\'s women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds. Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover. The British quartet, who were initially fourth, were promoted to the bronze which eluded their men\\'s team. Fraser-Pryce, like Bolt aged 26, became the first woman to achieve three golds in the 100-200 and the relay. In other final action on the last day of the championships, France\\'s Teddy Tamgho became the third man to leap over 18m in the triple jump, exceeding the mark by four centimeters to take gold. Germany\\'s Christina Obergfoll finally took gold at global level in the women\\'s javelin after five previous silvers, while Kenya\\'s Asbel Kiprop easily won a tactical men\\'s 1500m final. Kiprop\\'s compatriot Eunice Jepkoech Sum was a surprise winner of the women\\'s 800m. Bolt\\'s final dash for golden glory brought the eight-day championship to a rousing finale, but while the hosts topped the medal table from the United States there was criticism of the poor attendances in the Luzhniki Stadium. There was further concern when their pole vault gold medalist Yelena Isinbayeva made controversial remarks in support of Russia\\'s new laws, which make \"the propagandizing of non-traditional sexual relations among minors\" a criminal offense. She later attempted to clarify her comments, but there were renewed calls by gay rights groups for a boycott of the 2014 Winter Games in Sochi, the next major sports event in Russia.\n",
    "\"\"\"\n",
    "print(\"Original:\", sample_text)\n",
    "print(\"Summary:\", summarize(model, encoder_tokenizer, decoder_tokenizer, sample_text))\n",
    "\n",
    "sample_text = \"\"\"\n",
    "Vice President Dick Cheney will serve as acting president briefly Saturday while President Bush is anesthetized for a routine colonoscopy, White House spokesman Tony Snow said Friday. Bush is scheduled to have the medical procedure, expected to take about 2 1/2 hours, at the presidential retreat at Camp David, Maryland, Snow said. Bush's last colonoscopy was in June 2002, and no abnormalities were found, Snow said. The president's doctor had recommended a repeat procedure in about five years. The procedure will be supervised by Dr. Richard Tubb and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, Snow said. A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic. Small polyps may be removed during the procedure. Snow said that was the case when Bush had colonoscopies before becoming president. Snow himself is undergoing chemotherapy for cancer that began in his colon and spread to his liver. Snow told reporters he had a chemo session scheduled later Friday. Watch Snow talk about Bush's procedure and his own colon cancer Â» . \"The president wants to encourage everybody to use surveillance,\" Snow said. The American Cancer Society recommends that people without high-risk factors or symptoms begin getting screened for signs of colorectal cancer at age 50. E-mail to a friend .\n",
    "\"\"\"\n",
    "print(\"Original:\", sample_text)\n",
    "print(\"Summary:\", summarize(model, encoder_tokenizer, decoder_tokenizer, sample_text))\n",
    "\n",
    "sample_text = \"There are two chickens in the garden.\"\n",
    "print(\"Original:\", sample_text)\n",
    "print(\"Summary:\", summarize(model, encoder_tokenizer, decoder_tokenizer, sample_text))\n",
    "\n",
    "sample_text = \"Two chickens fell into the swimming pool in the garden.\"\n",
    "print(\"Original:\", sample_text)\n",
    "print(\"Summary:\", summarize(model, encoder_tokenizer, decoder_tokenizer, sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
