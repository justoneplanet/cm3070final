{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U pip datasets ipywidgets\n",
    "# For mac OS\n",
    "# %pip install -U tensorflow==2.16.2 tensorflow-macos==2.16.2 keras==3.4.1 keras-nlp\n",
    "# 20240803, tensorflow-text can be installed on Apple Silicon mac now!\n",
    "# %pip install tensorflow-text\n",
    "# For Intel mac\n",
    "# %pip install -U tensorflow==2.16.2 tensorflow-text keras==3.4.1 keras-nlp\n",
    "# For AWS SageMaker\n",
    "# %pip install -U tensorflow==2.16.2 tensorflow-datasets tensorflow-text keras==3.4.1 keras-nlp datasets rouge-score py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to determine where this note is running\n",
    "import platform\n",
    "\n",
    "def is_running_on_apple_silicon():\n",
    "    \"\"\"\n",
    "    Determine if this is running on Apple Silicon Mac.\n",
    "    \"\"\"\n",
    "    return platform.system() == \"Darwin\" and platform.processor() == \"arm\"\n",
    "\n",
    "def is_running_on_intel_mac():\n",
    "    \"\"\"\n",
    "    Determine if this is running on Intel Mac.\n",
    "    \"\"\"\n",
    "    return platform.system() == \"Darwin\" and platform.processor() == \"i386\"\n",
    "\n",
    "# This flag is used for tf.debugging.experimental.enable_dump_debug_info.\n",
    "# However, this makes 10 times slower.\n",
    "DEBUGGER_V2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 2.17.0 is expected. The running version is 2.17.0\n",
      "Keras 3.4.1 is expected. The running version is 3.4.1\n",
      "KerasNLP 0.12.1 is expected. The running version is 0.12.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_nlp\n",
    "print(\"Tensorflow 2.17.0 is expected. The running version is\", tf.__version__)\n",
    "print(\"Keras 3.4.1 is expected. The running version is\", keras.__version__)\n",
    "print(\"KerasNLP 0.12.1 is expected. The running version is\", keras_nlp.__version__)\n",
    "\n",
    "if is_running_on_apple_silicon() or is_running_on_intel_mac():\n",
    "    FLOAT_TYPE = tf.float32\n",
    "else:\n",
    "    \"\"\"\n",
    "    # Mixed-precision training\n",
    "    Deep Learning with Python, Second Edition\n",
    "    François Chollet\n",
    "\n",
    "    However, this makes the processing 2.x slower on M2 Apple Silicon.\n",
    "\n",
    "    Machine | 1 step\n",
    "    --- | ---\n",
    "    Intel Mac - fp32 : fp16 | 1 : 1.714\n",
    "    Apple Silicon M2 (Mac Book Pro) - fp32 : fp16 | 1 : 2.813\n",
    "    NVIDIA V100 GPU x 1 (ml.p3.2xlarge) - fp32 : fp16 | 1 : 0.875    Intel Mac - fp32 : fp16 | 1 : 1.714\n",
    "    \"\"\"\n",
    "    keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    FLOAT_TYPE = tf.float16\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "# SageMaker cannot use @keras.saving\n",
    "from keras import saving\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(history, title=None, keys=[\"loss\", \"masked_acc\"]):\n",
    "    \"\"\"\n",
    "    Display the plot that indicates the loss and accuracy.\n",
    "    :param history: history object from the tensorflow fit function.\n",
    "    :param title: title text.\n",
    "    :param keys: keys for plotting.\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "        if 'loss' in key:\n",
    "            print(\n",
    "                np.min(history.history[f\"val_{key}\"]),\n",
    "                \"The best number of epocs for the validation loss is\",\n",
    "                np.argmin(history.history[f\"val_{key}\"]) + 1,\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                np.max(history.history[f\"val_{key}\"]),\n",
    "                \"The best number of epocs for the validation accuracy is\",\n",
    "                np.argmax(history.history[f\"val_{key}\"]) + 1,\n",
    "            )\n",
    "\n",
    "    flg, axes = plt.subplots(1, 2, tight_layout=True)\n",
    "    if title is not None:\n",
    "        flg.suptitle(t=title, fontsize=14)\n",
    "    for i, key in enumerate(keys):\n",
    "        value = history.history[key]\n",
    "        val_loss = history.history[f\"val_{key}\"]\n",
    "        epochs = range(1, len(value) + 1)\n",
    "        axes[i].plot(epochs, value, label=f\"Training {key}\")\n",
    "        axes[i].plot(epochs, val_loss, label=f\"Validation {key}\")\n",
    "        axes[i].set_title(f\"Training and validation {key}\")\n",
    "        axes[i].set_xlabel(\"epochs\")\n",
    "        axes[i].set_ylabel(key)\n",
    "        axes[i].legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir(now):\n",
    "    log_dir = \"logs/fit/\" + now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    return log_dir\n",
    "\n",
    "def get_tensorboard_callback(now):\n",
    "    \"\"\"\n",
    "    Create the TensorBoard callback\n",
    "    \"\"\"\n",
    "    # @see https://www.tensorflow.org/tensorboard/get_started\n",
    "    log_dir = get_log_dir(now=now)\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1\n",
    "    )\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://github.com/keras-team/keras-nlp/blob/50e041487b1d8b30b34c5fb738db3ed3406363bc/examples/machine_translation/data.py\n",
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "def custom_standardization(input_string):\n",
    "    \"\"\"\n",
    "    Define the custom standardization to remove useless characters.\n",
    "    \"\"\"\n",
    "    input_string = tf.strings.regex_replace(input_string, r'\\r\\n', ' ')\n",
    "    input_string = tf.strings.regex_replace(input_string, r'\\\\r\\\\n', ' ')\n",
    "    input_string = tf.strings.regex_replace(input_string, r'\\r', ' ')\n",
    "    input_string = tf.strings.regex_replace(input_string, r'\\\\r', ' ')\n",
    "    input_string = tf.strings.regex_replace(input_string, r'\\n', ' ')\n",
    "    input_string = tf.strings.regex_replace(input_string, r'\\\\n', ' ')\n",
    "    input_string = tf.strings.regex_replace(input_string, r'<br />', ' ')\n",
    "    input_string = tf.strings.regex_replace(input_string, r'&amp;', '')\n",
    "    # Exclude html tags concisely\n",
    "    input_string = tf.strings.regex_replace(input_string, r'<\\/?[^>]*>', '')\n",
    "    # Exclude html tags strictly\n",
    "    #input_string = tf.strings.regex_replace(input_string, r'''<(\"[^\"]*\"|'[^']*'|[^'\">])*>''', '')\n",
    "    input_string = tf.strings.regex_replace(input_string, r'https?:\\/\\/.*[\\r\\n]*', \" \") # URL\n",
    "    input_string = tf.strings.regex_replace(input_string, r'\\s\\s+', ' ')\n",
    "    input_string = tf.strings.regex_replace(input_string, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
    "reduce_lr_callbacks = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_delta=0.04,\n",
    "    cooldown=8,\n",
    "    min_lr=2e-5, # 5e-4: 0.0005, 2e-5: 0.00002\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### The reason why the masked loss is required for seq2seq models\n",
    "\n",
    "The prediction y values of seq2seq models contain pad(s), which are used to align the length of every output sequence.\n",
    "In the case that most sequences are much shorter than the longest sentence and pads are not considered,\n",
    "a model that predicts only pads of sentences is highly evaluated.\n",
    "Therefore, excluding pads from the loss calculation improves the model.\n",
    "\n",
    "### The reason why the classification model does not use the masked loss function\n",
    "\n",
    "The prediction y values of classification models do not contain pad(s), which are used to align the length of every output sequence.\n",
    "It just contains the probability of each class.\n",
    "\"\"\"\n",
    "\n",
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "@saving.register_keras_serializable()\n",
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "        # nn.py:609: UserWarning:\n",
    "        # \"`sparse_categorical_crossentropy` received `from_logits=True`,\n",
    "        # but the `output` argument was produced by a Softmax activation and thus does not represent logits.\n",
    "        # Was this intended?\n",
    "        # When logits is True, softmax activation function has not processed the values.\n",
    "        from_logits=True,\n",
    "        reduction='none'\n",
    "    )\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "# @saving.register_keras_serializable()\n",
    "# def masked_acc(y_true, y_pred):\n",
    "#     # Calculate the loss for each item in the batch.\n",
    "#     y_pred = tf.argmax(y_pred, axis=-1) # last index\n",
    "#     y_pred = tf.cast(y_pred, dtype=y_true.dtype)\n",
    "#     match = tf.cast(y_true == y_pred, dtype=FLOAT_TYPE)\n",
    "#     mask = tf.cast(y_true != 0, dtype=FLOAT_TYPE)\n",
    "#     return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "# @see https://www.tensorflow.org/text/tutorials/transformer\n",
    "@saving.register_keras_serializable()\n",
    "def masked_acc(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=2)\n",
    "    y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "    match = y_true == y_pred\n",
    "    mask = y_true != 0\n",
    "    match = match & mask\n",
    "    match = tf.cast(match, dtype=FLOAT_TYPE)\n",
    "    mask = tf.cast(mask, dtype=FLOAT_TYPE)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_n(y_true, y_pred, order=2):\n",
    "    rouge_n = keras_nlp.metrics.RougeN(order=order)\n",
    "    return rouge_n(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "def prepare_datasets():\n",
    "    \"\"\"\n",
    "    Get training set, validation set, and test set\n",
    "    tensorflow_datasets does not work well with the SSL error.\n",
    "    Therefore, the data is obtained with the Huggingface library and converted to Tensorflow.\n",
    "    :return: train_ds\n",
    "    :return: validation_ds\n",
    "    :return: test_ds\n",
    "    \"\"\"\n",
    "    # How to convert huggingface dataset to tensorflow dataset\n",
    "    # @see https://huggingface.co/docs/datasets/v1.3.0/torch_tensorflow.html#setting-the-format\n",
    "    def convert_hf2tf(\n",
    "            dataset: datasets.DatasetDict,\n",
    "            split: list[str],\n",
    "            columns=['article', 'highlights', 'id',]):\n",
    "        dataset.set_format(\n",
    "            type='tensorflow',\n",
    "            columns=columns\n",
    "        )\n",
    "        l = []\n",
    "        for s in split:\n",
    "            d = dataset[s]\n",
    "            features = {x: d[x] for x in columns}\n",
    "            # .batch(32) is not used to show a simple sampled data below with take(1)\n",
    "            tf_dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "            l.append(tf_dataset)\n",
    "        return tuple(l)\n",
    "    ds = datasets.load_dataset(\n",
    "        'Samsung/samsum',\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    train_ds, validation_ds, test_ds = convert_hf2tf(\n",
    "        dataset=ds,\n",
    "        split=['train', 'validation', 'test'],\n",
    "        columns=['id', 'summary', 'dialogue'],\n",
    "    )\n",
    "    return train_ds, validation_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tokenizer(\n",
    "        vectorization_layer,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length,\n",
    "        max_tokens=15000):\n",
    "    \"\"\"\n",
    "    Display the plot that indicates the loss and accuracy.\n",
    "    :param vectorization_layer: obtain vocabulary.\n",
    "    :param max_tokens: In other words, this is the vocabulary size.\n",
    "    :param encoder_sequence_length: The sequence length for input.\n",
    "    :param input_output_sequence_length: The sequence length for target.\n",
    "    \"\"\"\n",
    "    vocabulary = vectorization_layer.get_vocabulary()\n",
    "\n",
    "    input_vectorization_layer = keras.layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_tokens,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=encoder_sequence_length,\n",
    "    )\n",
    "    target_vectorization_layer = keras.layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_tokens,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=decoder_sequence_length,\n",
    "    )\n",
    "    input_vectorization_layer.set_vocabulary(vocabulary)\n",
    "    target_vectorization_layer.set_vocabulary(vocabulary)\n",
    "    return input_vectorization_layer, target_vectorization_layer\n",
    "\n",
    "def build_datasets(\n",
    "        train_ds, validation_ds, test_ds,\n",
    "        vectorization_layer,\n",
    "        batch_size,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length):\n",
    "    \"\"\"\n",
    "    vectorization_layer(['This is a pen', 'I am a software engineer'])\n",
    "    #vectorization_layer(['This is a pen', 'I am a software engineer']).row_lengths().shape[0]\n",
    "    # 2\n",
    "    rows = vectorization_layer(['This is a pen', 'I am a software engineer']).row_lengths().shape[0]\n",
    "    vectorization_layer(['This is a pen', 'I am a software engineer']).to_tensor(shape=(rows, 10))\n",
    "    # .to_tensor()\n",
    "\n",
    "    RaggedTensor.to_tensor can make 0-filled Tensor\n",
    "    \"\"\"\n",
    "    def format_dataset(x):\n",
    "        # decoder_sequence_length: either the following 2.\n",
    "        # - decoder input: [start] + sentence\n",
    "        # - decoder output: sentence + [end]\n",
    "        # That is, decoder_sequence_length = sentence length + 1\n",
    "        summarized_text_length = decoder_sequence_length - 1\n",
    "\n",
    "        d = vectorization_layer(x['dialogue'])\n",
    "        r = d.row_lengths().shape[0]\n",
    "        dialogue = d.to_tensor(shape=(r, encoder_sequence_length))\n",
    "\n",
    "        start_oov = vectorization_layer(['[start]']).to_tensor(shape=(1, 1))\n",
    "        end_oov = vectorization_layer(['[end]']).to_tensor(shape=(1, 1))\n",
    "        summary = vectorization_layer(x['summary'])\n",
    "        \"\"\"\n",
    "        print(h.row_lengths().shape[0]) None\n",
    "        print(tf.shape(h)[0]) Tensor(\"RaggedShape/Cast_3:0\", shape=(), dtype=int32)\n",
    "        At the last step, the number of rows is not equal to the batch size.\n",
    "        \"\"\"\n",
    "        rows = tf.shape(summary)[0]\n",
    "        summary = summary[:rows, :summarized_text_length]\n",
    "        start_oov = tf.repeat(start_oov, repeats=rows , axis=0)\n",
    "        end_oov = tf.repeat(end_oov, repeats=rows , axis=0)\n",
    "        summary = tf.concat([start_oov, summary, end_oov], axis=1)\n",
    "\n",
    "        sequences = summary.to_tensor(shape=(\n",
    "            rows,\n",
    "            summarized_text_length + 1 + 1 # start + sentence + end\n",
    "        ))\n",
    "\n",
    "        summary_decoder_input = sequences[:, :-1] # start + sentence\n",
    "        summary_decoder_output = sequences[:, 1:] # sentence + end\n",
    "        return (\n",
    "            (\n",
    "                dialogue, # encoder input\n",
    "                summary_decoder_input, # decoder input\n",
    "            ),\n",
    "            summary_decoder_output, # decoder output\n",
    "            tf.cast((summary_decoder_output != 0), dtype=FLOAT_TYPE)\n",
    "        )\n",
    "    train_ds = train_ds.batch(batch_size).map(\n",
    "        format_dataset,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).prefetch(tf.data.AUTOTUNE).cache()\n",
    "    if validation_ds is not None:\n",
    "        validation_ds = validation_ds.batch(batch_size).map(\n",
    "            format_dataset,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        ).prefetch(tf.data.AUTOTUNE).cache()\n",
    "    test_ds = test_ds.batch(batch_size).map(\n",
    "        format_dataset,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).prefetch(tf.data.AUTOTUNE).cache()\n",
    "    return train_ds, validation_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@saving.register_keras_serializable()\n",
    "class Seq2SeqModel(keras.Model):\n",
    "    \"\"\"\n",
    "    # This class builds the seq2seq model, which can be written by functional API as follows;\n",
    "    encoder_input = keras.Input(\n",
    "        shape=(None,),\n",
    "        dtype=\"int64\",\n",
    "        name=\"encoder_input\"\n",
    "    )\n",
    "    x = keras.layers.Embedding(\n",
    "        encoder_vocabulary_size,\n",
    "        embedding_dim,\n",
    "        mask_zero=True\n",
    "    )(encoder_input)\n",
    "    encoded_output = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(latent_dim),\n",
    "        merge_mode=\"sum\"\n",
    "    )(x)\n",
    "\n",
    "    decoder_input = keras.Input(\n",
    "        shape=(None,),\n",
    "        dtype=\"int64\",\n",
    "        name=\"decoder_input\"\n",
    "    )\n",
    "    x = keras.layers.Embedding(\n",
    "        decoder_vocabulary_size,\n",
    "        embedding_dim,\n",
    "        mask_zero=True\n",
    "    )(decoder_input)\n",
    "    x = keras.layers.GRU(\n",
    "        latent_dim,\n",
    "        return_sequences=True\n",
    "    )(x, initial_state=encoded_output)\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "    output = keras.layers.Dense(\n",
    "        decoder_vocabulary_size,\n",
    "        activation=\"softmax\"\n",
    "    )(x)\n",
    "    model = keras.Model(\n",
    "        [encoder_input, decoder_input],\n",
    "        output\n",
    "    )\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_tokenizer,\n",
    "        decoder_tokenizer,\n",
    "        dropout,\n",
    "        latent_dim,\n",
    "        encoder_vocabulary_size,\n",
    "        decoder_vocabulary_size,\n",
    "        embedding_dim,\n",
    "        mask_zero,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length,\n",
    "        **kwargs):\n",
    "        super(Seq2SeqModel, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.latent_dim = latent_dim\n",
    "        self.mask_zero = mask_zero\n",
    "        self.encoder_tokenizer = encoder_tokenizer\n",
    "        self.decoder_tokenizer = decoder_tokenizer\n",
    "\n",
    "        self.encoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=encoder_vocabulary_size,\n",
    "            output_dim=embedding_dim,\n",
    "            mask_zero=mask_zero,\n",
    "            name=\"encoder_embed\",\n",
    "        )\n",
    "        self.encoder_layer = keras.layers.Bidirectional(\n",
    "            keras.layers.GRU(latent_dim),\n",
    "            merge_mode=\"sum\",\n",
    "            name=\"encoder\",\n",
    "        )\n",
    "\n",
    "        self.decoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=decoder_vocabulary_size,\n",
    "            output_dim=embedding_dim,\n",
    "            mask_zero=mask_zero,\n",
    "            name=\"decoder_embed\",\n",
    "        )\n",
    "        self.decoder_layer = keras.layers.GRU(\n",
    "            latent_dim,\n",
    "            return_sequences=True,\n",
    "            name=\"decoder\",\n",
    "        )\n",
    "\n",
    "        self.dropout = keras.layers.Dropout(dropout)\n",
    "        self.dense = keras.layers.Dense(\n",
    "            decoder_vocabulary_size,\n",
    "            name=\"dense\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        encoder_input, decoder_input = (\n",
    "            inputs[0],\n",
    "            inputs[1],\n",
    "        )\n",
    "        # tf.print(encoder_input, decoder_input)\n",
    "        encoded = self.encoder_embedding(encoder_input)\n",
    "        encoded_source = self.encoder_layer(encoded)\n",
    "\n",
    "        decoded = self.decoder_embedding(decoder_input)\n",
    "        output = self.decoder_layer(decoded, initial_state=encoded_source)\n",
    "        output = self.dropout(output)\n",
    "        output = self.dense(output)\n",
    "        # try:\n",
    "        #     # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "        #     # b/250038731\n",
    "        #     del output._keras_mask\n",
    "        # except AttributeError:\n",
    "        #     pass\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        This method is used to save a model into a file.\n",
    "        \"\"\"\n",
    "        config = super(Seq2SeqModel, self).get_config().copy()\n",
    "        config.update({\n",
    "            \"encoder_tokenizer\": self.encoder_tokenizer.get_config(),\n",
    "            \"decoder_tokenizer\": self.decoder_tokenizer.get_config(),\n",
    "            \"dropout\" : self.dropout,\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"encoder_vocabulary_size\": self.encoder_embedding.input_dim,\n",
    "            \"decoder_vocabulary_size\": self.decoder_embedding.input_dim,\n",
    "            \"embedding_dim\": self.encoder_embedding.output_dim,\n",
    "            \"mask_zero\": self.mask_zero,\n",
    "        })\n",
    "        return config\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        \"\"\"\n",
    "        This method is used to build a model from a saved file.\n",
    "        \"\"\"\n",
    "        encoder_tokenizer_config = config.pop(\"encoder_tokenizer\")\n",
    "        decoder_tokenizer_config = config.pop(\"decoder_tokenizer\")\n",
    "        encoder_tokenizer = keras.layers.TextVectorization.from_config(encoder_tokenizer_config)\n",
    "        decoder_tokenizer = keras.layers.TextVectorization.from_config(decoder_tokenizer_config)\n",
    "        return cls(\n",
    "            encoder_tokenizer=encoder_tokenizer,\n",
    "            decoder_tokenizer=decoder_tokenizer,\n",
    "            **config\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(\n",
    "        input_sentence,\n",
    "        model,\n",
    "        max_sequence_length,\n",
    "        lookup_table):\n",
    "    \"\"\"\n",
    "    Generate summarized text from the input sentence.\n",
    "    :input_sentence: the original text that is summarized\n",
    "    :model: the Seq2SeqModel class model\n",
    "    :max_sequence_length: the maximum length of the summarized text\n",
    "    :lookup_table: the table holds token IDs and their actual words\n",
    "    \"\"\"\n",
    "    encoder_tokenizer = model.encoder_tokenizer\n",
    "    decoder_tokenizer = model.decoder_tokenizer\n",
    "    tokenized_input = encoder_tokenizer([input_sentence])\n",
    "\n",
    "    start_token = decoder_tokenizer(\"[start]\")[0].numpy()\n",
    "    end_token = decoder_tokenizer(\"[end]\")[0].numpy()\n",
    "\n",
    "    decoded_sentence = [start_token]\n",
    "    for i in range(max_sequence_length):\n",
    "        decoder_inputs = tf.convert_to_tensor(\n",
    "            [decoded_sentence],\n",
    "            dtype=\"int64\",\n",
    "        )\n",
    "        decoder_inputs = tf.concat(\n",
    "            [\n",
    "                decoder_inputs,\n",
    "                tf.zeros(\n",
    "                    [1, max_sequence_length - i - 1],\n",
    "                    dtype=\"int64\",\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        input = (\n",
    "            tokenized_input,\n",
    "            decoder_inputs,\n",
    "        )\n",
    "        predictions = model(input)\n",
    "        predicted_token = np.argmax(predictions[0, i, :])\n",
    "        decoded_sentence.append(predicted_token)\n",
    "        if predicted_token == end_token:\n",
    "            break\n",
    "\n",
    "    detokenized_output = []\n",
    "    for token in decoded_sentence:\n",
    "        detokenized_output.append(lookup_table[token])\n",
    "    return \" \".join(detokenized_output)\n",
    "\n",
    "\n",
    "def predict_main(\n",
    "        filepath,\n",
    "        examples,\n",
    "        decoder_sequence_length):\n",
    "    \"\"\"\n",
    "    Generate summarized text with the model file.\n",
    "    :filepath: the file path specifies the model\n",
    "    :examples: the list of text that is summarized.\n",
    "    :decoder_sequence_length: the maximum length of the summarized text.\n",
    "    \"\"\"\n",
    "    loaded_model = keras.models.load_model(\n",
    "        filepath,\n",
    "        # Just in case, Seq2SeqModel is specified.\n",
    "        # However, it does not seem necessary.\n",
    "        custom_objects={\n",
    "            \"Seq2SeqModel\": Seq2SeqModel,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    decoder_tokenizer = loaded_model.decoder_tokenizer\n",
    "    vocab = decoder_tokenizer.get_vocabulary()\n",
    "    index_lookup_table = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "    summarized = []\n",
    "    for example in examples:\n",
    "        summarized.append(\n",
    "            decode_sequence(\n",
    "                example,\n",
    "                loaded_model,\n",
    "                decoder_sequence_length,\n",
    "                index_lookup_table,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        print(\"ORIGINAL SENTENCE: \", examples[i])\n",
    "        print(\"SUMMARIZED RESULT: \", summarized[i])\n",
    "\n",
    "def predict_model(\n",
    "        model,\n",
    "        examples,\n",
    "        decoder_sequence_length):\n",
    "    \"\"\"\n",
    "    Generate summarized text with the model.\n",
    "    :model: the file path specifies the model\n",
    "    :examples: the list of text that is summarized.\n",
    "    :decoder_sequence_length: the maximum length of the summarized text.\n",
    "    \"\"\"\n",
    "    decoder_tokenizer = model.decoder_tokenizer\n",
    "    vocab = decoder_tokenizer.get_vocabulary()\n",
    "    index_lookup_table = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "    summarized = []\n",
    "    for example in examples:\n",
    "        summarized.append(\n",
    "            decode_sequence(\n",
    "                example,\n",
    "                model,\n",
    "                decoder_sequence_length,\n",
    "                index_lookup_table,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        print(\"ORIGINAL SENTENCE: \", examples[i])\n",
    "        print(\"SUMMARIZED RESULT: \", summarized[i])\n",
    "\n",
    "def predict_dataset(\n",
    "        model,\n",
    "        iterable_dataset,\n",
    "        decoder_sequence_length):\n",
    "    \"\"\"\n",
    "    Generate summarized text with the model.\n",
    "    :model: the file path specifies the model\n",
    "    :iterable_dataset: the dataset, which is mainly test set, used to generate summarized text.\n",
    "    :decoder_sequence_length: the maximum length of the summarized text.\n",
    "    \"\"\"\n",
    "    decoder_tokenizer = model.decoder_tokenizer\n",
    "    vocab = decoder_tokenizer.get_vocabulary()\n",
    "    index_lookup_table = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    for entry in iterable_dataset:\n",
    "        text = entry[\"dialogue\"]\n",
    "        result = decode_sequence(\n",
    "            text,\n",
    "            model,\n",
    "            decoder_sequence_length,\n",
    "            index_lookup_table,\n",
    "        )\n",
    "        y_true = entry[\"summary\"]\n",
    "        y_true = y_true.decode('utf-8').lower()\n",
    "        y_pred = result.replace('[start]', '').replace('[end]', '').strip()\n",
    "        # print(y_true, '\\n\\t' , y_pred)\n",
    "        y_trues.append(y_true)\n",
    "        y_preds.append(y_pred)\n",
    "    return y_trues, y_preds\n",
    "\n",
    "def calculate_rouge_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    # RougeN metric\n",
    "    # @see https://keras.io/api/keras_nlp/metrics/rouge_n/\n",
    "    \"\"\"\n",
    "    rouge_n = keras_nlp.metrics.RougeN(order=2)\n",
    "    rouge_2_score = rouge_n(y_true, y_pred)\n",
    "    rouge_n = keras_nlp.metrics.RougeN(order=1)\n",
    "    rouge_1_score = rouge_n(y_true, y_pred)\n",
    "    rouge_l = keras_nlp.metrics.RougeL()\n",
    "    rouge_l_score = rouge_l(y_true, y_pred)\n",
    "    return rouge_1_score, rouge_2_score, rouge_l_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "        model,\n",
    "        train_ds,\n",
    "        validation_ds,\n",
    "        optimizer,\n",
    "        epochs,\n",
    "        steps_per_epoch,\n",
    "        now,\n",
    "        verbose,\n",
    "        callbacks=[]):\n",
    "    \"\"\"\n",
    "    Run training.\n",
    "    :train_ds: training set\n",
    "    :validation_ds: validation set\n",
    "    :optimizer: optimizer.Optimizer\n",
    "    :epochs: the number of epochs\n",
    "    :steps_per_epoch: the number of weight updates in a epoch\n",
    "    :now: timestamp\n",
    "    \"\"\"\n",
    "    metrics = [\n",
    "        masked_acc,\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "        loss=masked_loss,\n",
    "        weighted_metrics=[],\n",
    "    )\n",
    "    callbacks.append(get_tensorboard_callback(now=now))\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_ds,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "        train_ds, validation_ds, test_ds,\n",
    "        vectorization_layer,\n",
    "        dropout,\n",
    "        latent_dim,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length,\n",
    "        vocab_size,\n",
    "        batch_size,\n",
    "        embedding_dim,\n",
    "        mask_zero,\n",
    "        optimizer,\n",
    "        epochs,\n",
    "        steps_per_epoch,\n",
    "        verbose=1,\n",
    "        callbacks=[]):\n",
    "    \"\"\"\n",
    "    Build the model with specified parameters.\n",
    "    :return: model: trained model\n",
    "    :return: filepath: model file path if it is saved\n",
    "    :return: history: history object to plot\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    if DEBUGGER_V2:\n",
    "        tf.debugging.experimental.enable_dump_debug_info(\n",
    "            get_log_dir(now=now),\n",
    "            tensor_debug_mode=\"FULL_HEALTH\",\n",
    "            circular_buffer_size=-1\n",
    "        )\n",
    "    input_vectorization_layer, target_vectorization_layer = prepare_tokenizer(\n",
    "        vectorization_layer=vectorization_layer,\n",
    "        encoder_sequence_length=encoder_sequence_length,\n",
    "        decoder_sequence_length=decoder_sequence_length,\n",
    "        max_tokens=vocab_size,\n",
    "    )\n",
    "    train_ds, validation_ds, test_ds = build_datasets(\n",
    "        train_ds=train_ds,\n",
    "        validation_ds=validation_ds,\n",
    "        test_ds=test_ds,\n",
    "        vectorization_layer=vectorization_layer,\n",
    "        batch_size=batch_size,\n",
    "        encoder_sequence_length=encoder_sequence_length,\n",
    "        decoder_sequence_length=decoder_sequence_length,\n",
    "    )\n",
    "\n",
    "    input_vocab_size = input_vectorization_layer.vocabulary_size()\n",
    "    target_vocab_size = target_vectorization_layer.vocabulary_size()\n",
    "\n",
    "    # encoder_input = keras.Input(\n",
    "    #     shape=(None,),\n",
    "    #     dtype=\"int64\",\n",
    "    #     name=\"encoder_input\"\n",
    "    # )\n",
    "    # x = keras.layers.Embedding(\n",
    "    #     input_vocab_size,\n",
    "    #     embedding_dim,\n",
    "    #     mask_zero=mask_zero\n",
    "    # )(encoder_input)\n",
    "    # encoded_output = keras.layers.Bidirectional(\n",
    "    #     keras.layers.GRU(latent_dim),\n",
    "    #     merge_mode=\"sum\"\n",
    "    # )(x)\n",
    "\n",
    "    # decoder_input = keras.Input(\n",
    "    #     shape=(None,),\n",
    "    #     dtype=\"int64\",\n",
    "    #     name=\"decoder_input\"\n",
    "    # )\n",
    "    # x = keras.layers.Embedding(\n",
    "    #     target_vocab_size,\n",
    "    #     embedding_dim,\n",
    "    #     mask_zero=mask_zero\n",
    "    # )(decoder_input)\n",
    "    # x = keras.layers.GRU(\n",
    "    #     latent_dim,\n",
    "    #     return_sequences=True\n",
    "    # )(x, initial_state=encoded_output)\n",
    "    # x = keras.layers.Dropout(dropout)(x)\n",
    "    # output = keras.layers.Dense(\n",
    "    #     target_vocab_size,\n",
    "    #     activation=\"softmax\"\n",
    "    # )(x)\n",
    "    # model = keras.Model(\n",
    "    #     [encoder_input, decoder_input],\n",
    "    #     output\n",
    "    # )\n",
    "\n",
    "    model = Seq2SeqModel(\n",
    "        encoder_tokenizer=input_vectorization_layer,\n",
    "        decoder_tokenizer=target_vectorization_layer,\n",
    "        dropout=dropout,\n",
    "        latent_dim=latent_dim,\n",
    "        encoder_vocabulary_size=input_vocab_size,\n",
    "        decoder_vocabulary_size=target_vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        mask_zero=mask_zero,\n",
    "        encoder_sequence_length=encoder_sequence_length,\n",
    "        decoder_sequence_length=decoder_sequence_length,\n",
    "    )\n",
    "    # # This should be called seemingly.\n",
    "    # model.build(\n",
    "    #     input_shape=(\n",
    "    #         (None, encoder_sequence_length),\n",
    "    #         (None, decoder_sequence_length)\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    history = run_training(\n",
    "        model,\n",
    "        train_ds=train_ds,\n",
    "        validation_ds=validation_ds,\n",
    "        optimizer=optimizer,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        now=now,\n",
    "        verbose=verbose,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    timestamp = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    if is_running_on_apple_silicon() or is_running_on_intel_mac():\n",
    "        filepath = f'model/summarization_model_{timestamp}.keras'\n",
    "    else:\n",
    "        filepath = f'summarization_model_{timestamp}.keras'\n",
    "    print(f\"Saving to {filepath}\")\n",
    "    model.save(filepath=filepath)\n",
    "\n",
    "    print(f\"Successfully saved model to {filepath}\")\n",
    "    return model, filepath, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size | CPU | GPU\n",
    "--- | --- | ---\n",
    "--- | 7m52s | > 25m\n",
    "32 | 1m41s | 2m26s\n",
    "64 | 1m37s | 2m5s\n",
    "128 | 1m37s | 1m49s\n",
    "256 | 1m31s | 1m40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-17 02:51:32.400680: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-08-17 02:51:32.400702: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-08-17 02:51:32.400705: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-08-17 02:51:32.400717: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-17 02:51:32.400729: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-08-17 02:51:33.344295: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ADAPT_BATCH_SIZE = 256\n",
    "\n",
    "train_ds, validation_ds, test_ds = prepare_datasets()\n",
    "vectorization_layer = keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    # max_tokens=VOCABULARY_SIZE,\n",
    "    output_mode='int',\n",
    "    ragged=True,\n",
    ")\n",
    "vectorization_layer.adapt(\n",
    "    train_ds.batch(ADAPT_BATCH_SIZE).map(\n",
    "        lambda row: '[start] ' + row['summary'] + ' ' + row['dialogue'] + ' [end]',\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    ),\n",
    "    batch_size=ADAPT_BATCH_SIZE,\n",
    ")\n",
    "# Use the maximum size of the dataset. 31907\n",
    "VOCABULARY_SIZE = len(vectorization_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'i',\n",
       " 'you',\n",
       " 'the',\n",
       " 'to',\n",
       " 'it',\n",
       " 'a',\n",
       " 'and',\n",
       " 's',\n",
       " 'is',\n",
       " 'for',\n",
       " 't',\n",
       " 'in',\n",
       " 'that',\n",
       " '[start]',\n",
       " '[end]',\n",
       " 'will',\n",
       " 'of',\n",
       " 'have']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorization_layer.get_vocabulary()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:609: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1842/1842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 102ms/step - loss: 2.3260 - masked_acc: 0.0933 - val_loss: 1.8732 - val_masked_acc: 0.1689 - learning_rate: 0.0010\n",
      "Saving to model/summarization_model_2024-08-17_11-55-40.keras\n",
      "Successfully saved model to model/summarization_model_2024-08-17_11-55-40.keras\n",
      "1.873175024986267 The best number of epocs for the validation loss is 1\n",
      "0.16890579462051392 The best number of epocs for the validation accuracy is 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 1 # 20 50\n",
    "STEPS_PER_EPOCH = None\n",
    "ENCODER_SEQUENCE_LENGTH = 128 # 128: 75% covered. max is 803.\n",
    "DECODER_SEQUENCE_LENGTH = 64 # 32: 75% covered. max is 64\n",
    "MASK_ZERO = False\n",
    "\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    train_ds, validation_ds, test_ds,\n",
    "    vectorization_layer=vectorization_layer,\n",
    "    dropout=0.35,\n",
    "    latent_dim=512,\n",
    "    encoder_sequence_length=ENCODER_SEQUENCE_LENGTH,\n",
    "    decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCABULARY_SIZE,\n",
    "    batch_size=8,\n",
    "    embedding_dim=128,\n",
    "    mask_zero=MASK_ZERO,\n",
    "    optimizer=optimizer,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    callbacks=[reduce_lr_callbacks],\n",
    ")\n",
    "plot(history=history)\n",
    "\n",
    "# optimizer = keras.optimizers.AdamW(\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "# )\n",
    "# best_epoch = max(np.argmin(history.history[f\"val_loss\"]), np.argmax(history.history[f\"val_masked_acc\"]))\n",
    "# best_epoch = best_epoch + 1\n",
    "# print(\"best_epoch is\", best_epoch)\n",
    "# model, filepath, history = build_model(\n",
    "#     train_ds.concatenate(validation_ds), None, test_ds,\n",
    "#     vectorization_layer=vectorization_layer,\n",
    "#     dropout=0.35,\n",
    "#     latent_dim=512,\n",
    "#     encoder_sequence_length=ENCODER_SEQUENCE_LENGTH,\n",
    "#     decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    "#     vocab_size=VOCABULARY_SIZE,\n",
    "#     batch_size=128,\n",
    "#     embedding_dim=128,\n",
    "#     mask_zero=MASK_ZERO,\n",
    "#     optimizer=optimizer,\n",
    "#     epochs=best_epoch,\n",
    "#     steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#     callbacks=[reduce_lr_callbacks],\n",
    "# )\n",
    "\n",
    "# y_true, y_pred = predict_dataset(\n",
    "#     model=model,\n",
    "#     iterable_dataset=tfds.as_numpy(test_ds), # The length of the test dataset is 819.\n",
    "#     decoder_sequence_length=DECODER_SEQUENCE_LENGTH\n",
    "# )\n",
    "# rouge_1_score, rouge_2_score, rouge_l_score = calculate_rouge_score(\n",
    "#     y_true=y_true,\n",
    "#     y_pred=y_pred\n",
    "# )\n",
    "# print(rouge_1_score)\n",
    "# print(rouge_2_score)\n",
    "# print(rouge_l_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_tokenizer = model.decoder_tokenizer\n",
    "vocab = decoder_tokenizer.get_vocabulary()\n",
    "index_lookup_table = dict(zip(range(len(vocab)), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] tom is going to buy a new android phone [end]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(\n",
    "    input_sentence=\"Edward: Rachel, I think I'm in ove with Bella.. rachel: Dont say anything else.. Edward: What do you mean?? rachel: Open your fu**ing door.. I'm outside\",\n",
    "    model=model,\n",
    "    lookup_table=index_lookup_table,\n",
    "    max_sequence_length=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] tom and tom are going to meet at the cinema [end]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_sequence_functionally(\n",
    "        input_sentence,\n",
    "        model,\n",
    "        input_vectorization_layer,\n",
    "        target_vectorization_layer,\n",
    "        max_sequence_length,\n",
    "        lookup_table):\n",
    "    \"\"\"\n",
    "    Generate summarized text from the input sentence.\n",
    "    :input_sentence: the original text that is summarized\n",
    "    :model: the Seq2SeqModel class model\n",
    "    :max_sequence_length: the maximum length of the summarized text\n",
    "    :lookup_table: the table holds token IDs and their actual words\n",
    "    \"\"\"\n",
    "    encoder_tokenizer = input_vectorization_layer\n",
    "    decoder_tokenizer = target_vectorization_layer\n",
    "    tokenized_input = encoder_tokenizer([input_sentence])\n",
    "\n",
    "    start_token = decoder_tokenizer(\"[start]\")[0].numpy()\n",
    "    end_token = decoder_tokenizer(\"[end]\")[0].numpy()\n",
    "\n",
    "    decoded_sentence = [start_token]\n",
    "    for i in range(max_sequence_length):\n",
    "        decoder_inputs = tf.convert_to_tensor(\n",
    "            [decoded_sentence],\n",
    "            dtype=\"int64\",\n",
    "        )\n",
    "        decoder_inputs = tf.concat(\n",
    "            [\n",
    "                decoder_inputs,\n",
    "                tf.zeros(\n",
    "                    [1, max_sequence_length - i - 1],\n",
    "                    dtype=\"int64\",\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        input = (\n",
    "            tokenized_input,\n",
    "            decoder_inputs,\n",
    "        )\n",
    "        predictions = model(input)\n",
    "        predicted_token = np.argmax(predictions[0, i, :])\n",
    "        decoded_sentence.append(predicted_token)\n",
    "        if predicted_token == end_token:\n",
    "            break\n",
    "\n",
    "    detokenized_output = []\n",
    "    for token in decoded_sentence:\n",
    "        detokenized_output.append(lookup_table[token])\n",
    "    return \" \".join(detokenized_output)\n",
    "\n",
    "input_vectorization_layer, target_vectorization_layer = prepare_tokenizer(\n",
    "    vectorization_layer=vectorization_layer,\n",
    "    encoder_sequence_length=ENCODER_SEQUENCE_LENGTH,\n",
    "    decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    "    max_tokens=vectorization_layer.vocabulary_size(),\n",
    ")\n",
    "\n",
    "decode_sequence_functionally(\n",
    "    input_sentence=\"Edward: Rachel, I think I'm in ove with Bella.. rachel: Dont say anything else.. Edward: What do you mean?? rachel: Open your fu**ing door.. I'm outside\",\n",
    "    model=model,\n",
    "    input_vectorization_layer=input_vectorization_layer,\n",
    "    target_vectorization_layer=target_vectorization_layer,\n",
    "    lookup_table=index_lookup_table,\n",
    "    max_sequence_length=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
