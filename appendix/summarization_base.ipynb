{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U pip datasets ipywidgets\n",
    "# For mac OS\n",
    "# %pip install -U tensorflow==2.16.2 tensorflow-macos==2.16.2 keras==3.4.1 keras-nlp\n",
    "# 20240803, tensorflow-text can be installed on Apple Silicon mac now!\n",
    "# %pip install tensorflow-text\n",
    "# For Intel mac\n",
    "# %pip install -U tensorflow==2.16.2 tensorflow-text keras==3.4.1 keras-nlp\n",
    "# For AWS SageMaker\n",
    "# %pip install -U tensorflow==2.16.2 tensorflow-datasets tensorflow-text keras==3.4.1 keras-nlp datasets rouge-score py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to determine where this note is running\n",
    "import platform\n",
    "\n",
    "def is_running_on_apple_silicon():\n",
    "    \"\"\"\n",
    "    Determine if this is running on Apple Silicon Mac.\n",
    "    \"\"\"\n",
    "    return platform.system() == \"Darwin\" and platform.processor() == \"arm\"\n",
    "\n",
    "def is_running_on_intel_mac():\n",
    "    \"\"\"\n",
    "    Determine if this is running on Intel Mac.\n",
    "    \"\"\"\n",
    "    return platform.system() == \"Darwin\" and platform.processor() == \"i386\"\n",
    "\n",
    "# This flag is used for tf.debugging.experimental.enable_dump_debug_info.\n",
    "# However, this makes 10 times slower.\n",
    "DEBUGGER_V2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 2.17.0 is expected. The running version is 2.17.0\n",
      "Keras 3.4.1 is expected. The running version is 3.4.1\n",
      "KerasNLP 0.12.1 is expected. The running version is 0.12.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_nlp\n",
    "print(\"Tensorflow 2.17.0 is expected. The running version is\", tf.__version__)\n",
    "print(\"Keras 3.4.1 is expected. The running version is\", keras.__version__)\n",
    "print(\"KerasNLP 0.12.1 is expected. The running version is\", keras_nlp.__version__)\n",
    "\n",
    "if is_running_on_apple_silicon() or is_running_on_intel_mac():\n",
    "    FLOAT_TYPE = tf.float32\n",
    "else:\n",
    "    \"\"\"\n",
    "    # Mixed-precision training\n",
    "    Deep Learning with Python, Second Edition\n",
    "    François Chollet\n",
    "\n",
    "    However, this makes the processing 2.x slower on M2 Apple Silicon.\n",
    "\n",
    "    Machine | 1 step\n",
    "    --- | ---\n",
    "    Intel Mac - fp32 : fp16 | 1 : 1.714\n",
    "    Apple Silicon M2 (Mac Book Pro) - fp32 : fp16 | 1 : 2.813\n",
    "    NVIDIA V100 GPU x 1 (ml.p3.2xlarge) - fp32 : fp16 | 1 : 0.875    Intel Mac - fp32 : fp16 | 1 : 1.714\n",
    "    \"\"\"\n",
    "    keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    FLOAT_TYPE = tf.float16\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "# SageMaker cannot use @keras.saving\n",
    "from keras import saving\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(history, title=None, keys=[\"loss\", \"masked_acc\"]):\n",
    "    \"\"\"\n",
    "    Display the plot that indicates the loss and accuracy.\n",
    "    :param history: history object from the tensorflow fit function.\n",
    "    :param title: title text.\n",
    "    :param keys: keys for plotting.\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "        if 'loss' in key:\n",
    "            print(\n",
    "                np.min(history.history[f\"val_{key}\"]),\n",
    "                \"The best number of epocs for the validation loss is\",\n",
    "                np.argmin(history.history[f\"val_{key}\"]) + 1,\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                np.max(history.history[f\"val_{key}\"]),\n",
    "                \"The best number of epocs for the validation accuracy is\",\n",
    "                np.argmax(history.history[f\"val_{key}\"]) + 1,\n",
    "            )\n",
    "\n",
    "    flg, axes = plt.subplots(1, 2, tight_layout=True)\n",
    "    if title is not None:\n",
    "        flg.suptitle(t=title, fontsize=14)\n",
    "    for i, key in enumerate(keys):\n",
    "        value = history.history[key]\n",
    "        val_loss = history.history[f\"val_{key}\"]\n",
    "        epochs = range(1, len(value) + 1)\n",
    "        axes[i].plot(epochs, value, label=f\"Training {key}\")\n",
    "        axes[i].plot(epochs, val_loss, label=f\"Validation {key}\")\n",
    "        axes[i].set_title(f\"Training and validation {key}\")\n",
    "        axes[i].set_xlabel(\"epochs\")\n",
    "        axes[i].set_ylabel(key)\n",
    "        axes[i].legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir(now):\n",
    "    log_dir = \"logs/fit/\" + now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    return log_dir\n",
    "\n",
    "def get_tensorboard_callback(now):\n",
    "    \"\"\"\n",
    "    Create the TensorBoard callback\n",
    "    \"\"\"\n",
    "    # @see https://www.tensorflow.org/tensorboard/get_started\n",
    "    log_dir = get_log_dir(now=now)\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1\n",
    "    )\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://github.com/keras-team/keras-nlp/blob/50e041487b1d8b30b34c5fb738db3ed3406363bc/examples/machine_translation/data.py\n",
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "def custom_standardization(input_string):\n",
    "    \"\"\"\n",
    "    Define the custom standardization to remove useless characters.\n",
    "    \"\"\"\n",
    "    s = tf.strings.lower(input_string)\n",
    "    s = tf.strings.regex_replace(s, r'\\n', ' ')\n",
    "    s = tf.strings.regex_replace(s, r'\\\\n', ' ')\n",
    "    s = tf.strings.regex_replace(s, r'<br />', ' ')\n",
    "    s = tf.strings.regex_replace(s, r\"'\", ' ')\n",
    "    s = tf.strings.regex_replace(s, r'&amp;', '')\n",
    "    s = tf.strings.regex_replace(s, r'[_\"\\-;%()|+&=*%.,!?:#$@/]', ' ')\n",
    "    s = tf.strings.regex_replace(s, r'<\\/?[^>]*>', '') # html tag\n",
    "    #s = tf.strings.regex_replace(s, r'''<(\"[^\"]*\"|'[^']*'|[^'\">])*>''', '') # html tag\n",
    "    s = tf.strings.regex_replace(s, r'https?:\\/\\/.*[\\r\\n]*', \" \") # URL\n",
    "    s = tf.strings.regex_replace(s, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
    "reduce_lr_callbacks = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_delta=0.04,\n",
    "    cooldown=8,\n",
    "    min_lr=2e-5, # 5e-4: 0.0005, 2e-5: 0.00002\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### The reason why the masked loss is required for seq2seq models\n",
    "\n",
    "The prediction y values of seq2seq models contain pad(s), which are used to align the length of every output sequence.\n",
    "In the case that most sequences are much shorter than the longest sentence and pads are not considered,\n",
    "a model that predicts only pads of sentences is highly evaluated.\n",
    "Therefore, excluding pads from the loss calculation improves the model.\n",
    "\n",
    "### The reason why the classification model does not use the masked loss function\n",
    "\n",
    "The prediction y values of classification models do not contain pad(s), which are used to align the length of every output sequence.\n",
    "It just contains the probability of each class.\n",
    "\"\"\"\n",
    "\n",
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "@saving.register_keras_serializable()\n",
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "        # nn.py:609: UserWarning:\n",
    "        # \"`sparse_categorical_crossentropy` received `from_logits=True`,\n",
    "        # but the `output` argument was produced by a Softmax activation and thus does not represent logits.\n",
    "        # Was this intended?\n",
    "        # When logits is True, softmax activation function has not processed the values.\n",
    "        from_logits=True,\n",
    "        reduction='none'\n",
    "    )\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @see https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
    "# @saving.register_keras_serializable()\n",
    "# def masked_acc(y_true, y_pred):\n",
    "#     # Calculate the loss for each item in the batch.\n",
    "#     y_pred = tf.argmax(y_pred, axis=-1) # last index\n",
    "#     y_pred = tf.cast(y_pred, dtype=y_true.dtype)\n",
    "#     match = tf.cast(y_true == y_pred, dtype=FLOAT_TYPE)\n",
    "#     mask = tf.cast(y_true != 0, dtype=FLOAT_TYPE)\n",
    "#     return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "# @see https://www.tensorflow.org/text/tutorials/transformer\n",
    "@saving.register_keras_serializable()\n",
    "def masked_acc(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=2)\n",
    "    y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "    match = y_true == y_pred\n",
    "    mask = y_true != 0\n",
    "    match = match & mask\n",
    "    match = tf.cast(match, dtype=FLOAT_TYPE)\n",
    "    mask = tf.cast(mask, dtype=FLOAT_TYPE)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_n(y_true, y_pred, order=2):\n",
    "    rouge_n = keras_nlp.metrics.RougeN(order=order)\n",
    "    return rouge_n(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "def prepare_datasets():\n",
    "    \"\"\"\n",
    "    Get training set, validation set, and test set\n",
    "    tensorflow_datasets does not work well with the SSL error.\n",
    "    Therefore, the data is obtained with the Huggingface library and converted to Tensorflow.\n",
    "    :return: train_ds\n",
    "    :return: validation_ds\n",
    "    :return: test_ds\n",
    "    \"\"\"\n",
    "    # How to convert huggingface dataset to tensorflow dataset\n",
    "    # @see https://huggingface.co/docs/datasets/v1.3.0/torch_tensorflow.html#setting-the-format\n",
    "    def convert_hf2tf(\n",
    "            dataset: datasets.DatasetDict,\n",
    "            split: list[str],\n",
    "            columns=['article', 'highlights', 'id',]):\n",
    "        dataset.set_format(\n",
    "            type='tensorflow',\n",
    "            columns=columns\n",
    "        )\n",
    "        l = []\n",
    "        for s in split:\n",
    "            d = dataset[s]\n",
    "            features = {x: d[x] for x in columns}\n",
    "            # .batch(32) is not used to show a simple sampled data below with take(1)\n",
    "            tf_dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "            l.append(tf_dataset)\n",
    "        return tuple(l)\n",
    "    ds = datasets.load_dataset(\n",
    "        'Samsung/samsum',\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    train_ds, validation_ds, test_ds = convert_hf2tf(\n",
    "        dataset=ds,\n",
    "        split=['train', 'validation', 'test'],\n",
    "        columns=['id', 'summary', 'dialogue'],\n",
    "    )\n",
    "    return train_ds, validation_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tokenizer(\n",
    "        vectorization_layer,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length,\n",
    "        max_tokens=15000):\n",
    "    \"\"\"\n",
    "    Display the plot that indicates the loss and accuracy.\n",
    "    :param vectorization_layer: obtain vocabulary.\n",
    "    :param max_tokens: In other words, this is the vocabulary size.\n",
    "    :param encoder_sequence_length: The sequence length for input.\n",
    "    :param input_output_sequence_length: The sequence length for target.\n",
    "    \"\"\"\n",
    "    vocabulary = vectorization_layer.get_vocabulary()\n",
    "\n",
    "    input_vectorization_layer = keras.layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_tokens,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=encoder_sequence_length,\n",
    "    )\n",
    "    target_vectorization_layer = keras.layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_tokens,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=decoder_sequence_length,\n",
    "    )\n",
    "    input_vectorization_layer.set_vocabulary(vocabulary)\n",
    "    target_vectorization_layer.set_vocabulary(vocabulary)\n",
    "    return input_vectorization_layer, target_vectorization_layer\n",
    "\n",
    "def build_datasets(\n",
    "        train_ds, validation_ds, test_ds,\n",
    "        vectorization_layer,\n",
    "        batch_size,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length):\n",
    "    \"\"\"\n",
    "    vectorization_layer(['This is a pen', 'I am a software engineer'])\n",
    "    #vectorization_layer(['This is a pen', 'I am a software engineer']).row_lengths().shape[0]\n",
    "    # 2\n",
    "    rows = vectorization_layer(['This is a pen', 'I am a software engineer']).row_lengths().shape[0]\n",
    "    vectorization_layer(['This is a pen', 'I am a software engineer']).to_tensor(shape=(rows, 10))\n",
    "    # .to_tensor()\n",
    "\n",
    "    RaggedTensor.to_tensor can make 0-filled Tensor\n",
    "    \"\"\"\n",
    "    def format_dataset(x):\n",
    "        # decoder_sequence_length: either the following 2.\n",
    "        # - decoder input: [start] + sentence\n",
    "        # - decoder output: sentence + [end]\n",
    "        # That is, decoder_sequence_length = sentence length + 1\n",
    "        summarized_text_length = decoder_sequence_length - 1\n",
    "\n",
    "        d = vectorization_layer(x['dialogue'])\n",
    "        r = d.row_lengths().shape[0]\n",
    "        dialogue = d.to_tensor(shape=(r, encoder_sequence_length))\n",
    "\n",
    "        start_oov = vectorization_layer(['[start]']).to_tensor(shape=(1, 1))\n",
    "        end_oov = vectorization_layer(['[end]']).to_tensor(shape=(1, 1))\n",
    "        summary = vectorization_layer(x['summary'])\n",
    "        \"\"\"\n",
    "        print(h.row_lengths().shape[0]) None\n",
    "        print(tf.shape(h)[0]) Tensor(\"RaggedShape/Cast_3:0\", shape=(), dtype=int32)\n",
    "        At the last step, the number of rows is not equal to the batch size.\n",
    "        \"\"\"\n",
    "        rows = tf.shape(summary)[0]\n",
    "        summary = summary[:rows, :summarized_text_length]\n",
    "        start_oov = tf.repeat(start_oov, repeats=rows , axis=0)\n",
    "        end_oov = tf.repeat(end_oov, repeats=rows , axis=0)\n",
    "        summary = tf.concat([start_oov, summary, end_oov], axis=1)\n",
    "\n",
    "        sequences = summary.to_tensor(shape=(\n",
    "            rows,\n",
    "            summarized_text_length + 1 + 1 # start + sentence + end\n",
    "        ))\n",
    "\n",
    "        summary_decoder_input = sequences[:, :-1] # start + sentence\n",
    "        summary_decoder_output = sequences[:, 1:] # sentence + end\n",
    "        return (\n",
    "            (\n",
    "                dialogue, # encoder input\n",
    "                summary_decoder_input, # decoder input\n",
    "            ),\n",
    "            summary_decoder_output, # decoder output\n",
    "            tf.cast((summary_decoder_output != 0), dtype=FLOAT_TYPE)\n",
    "        )\n",
    "    train_ds = train_ds.batch(batch_size).map(\n",
    "        format_dataset,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).prefetch(tf.data.AUTOTUNE).cache()\n",
    "    if validation_ds is not None:\n",
    "        validation_ds = validation_ds.batch(batch_size).map(\n",
    "            format_dataset,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        ).prefetch(tf.data.AUTOTUNE).cache()\n",
    "    test_ds = test_ds.batch(batch_size).map(\n",
    "        format_dataset,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).prefetch(tf.data.AUTOTUNE).cache()\n",
    "    return train_ds, validation_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@saving.register_keras_serializable()\n",
    "class Seq2SeqModel(keras.Model):\n",
    "    \"\"\"\n",
    "    # This class builds the seq2seq model, which can be written by functional API as follows;\n",
    "    encoder_input = keras.Input(\n",
    "        shape=(None,),\n",
    "        dtype=\"int64\",\n",
    "        name=\"encoder_input\"\n",
    "    )\n",
    "    x = keras.layers.Embedding(\n",
    "        encoder_vocabulary_size,\n",
    "        embedding_dim,\n",
    "        mask_zero=True\n",
    "    )(encoder_input)\n",
    "    encoded_output = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(latent_dim),\n",
    "        merge_mode=\"sum\"\n",
    "    )(x)\n",
    "\n",
    "    decoder_input = keras.Input(\n",
    "        shape=(None,),\n",
    "        dtype=\"int64\",\n",
    "        name=\"decoder_input\"\n",
    "    )\n",
    "    x = keras.layers.Embedding(\n",
    "        decoder_vocabulary_size,\n",
    "        embedding_dim,\n",
    "        mask_zero=True\n",
    "    )(decoder_input)\n",
    "    x = keras.layers.GRU(\n",
    "        latent_dim,\n",
    "        return_sequences=True\n",
    "    )(x, initial_state=encoded_output)\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "    output = keras.layers.Dense(\n",
    "        decoder_vocabulary_size,\n",
    "        activation=\"softmax\"\n",
    "    )(x)\n",
    "    model = keras.Model(\n",
    "        [encoder_input, decoder_input],\n",
    "        output\n",
    "    )\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_tokenizer,\n",
    "        decoder_tokenizer,\n",
    "        dropout,\n",
    "        latent_dim,\n",
    "        encoder_vocabulary_size,\n",
    "        decoder_vocabulary_size,\n",
    "        embedding_dim,\n",
    "        mask_zero,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length,\n",
    "        **kwargs):\n",
    "        super(Seq2SeqModel, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.latent_dim = latent_dim\n",
    "        self.mask_zero = mask_zero\n",
    "        self.encoder_tokenizer = encoder_tokenizer\n",
    "        self.decoder_tokenizer = decoder_tokenizer\n",
    "\n",
    "        self.encoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=encoder_vocabulary_size,\n",
    "            output_dim=embedding_dim,\n",
    "            mask_zero=mask_zero,\n",
    "            name=\"encoder_embed\",\n",
    "        )\n",
    "        self.encoder_layer = keras.layers.Bidirectional(\n",
    "            keras.layers.GRU(latent_dim),\n",
    "            merge_mode=\"sum\",\n",
    "            name=\"encoder\",\n",
    "        )\n",
    "\n",
    "        self.decoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=decoder_vocabulary_size,\n",
    "            output_dim=embedding_dim,\n",
    "            mask_zero=mask_zero,\n",
    "            name=\"decoder_embed\",\n",
    "        )\n",
    "        self.decoder_layer = keras.layers.GRU(\n",
    "            latent_dim,\n",
    "            return_sequences=True,\n",
    "            name=\"decoder\",\n",
    "        )\n",
    "\n",
    "        self.dropout = keras.layers.Dropout(dropout)\n",
    "        self.dense = keras.layers.Dense(\n",
    "            decoder_vocabulary_size,\n",
    "            name=\"dense\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        encoder_input, decoder_input = (\n",
    "            inputs[0],\n",
    "            inputs[1],\n",
    "        )\n",
    "        encoded = self.encoder_embedding(encoder_input)\n",
    "        encoded_source = self.encoder_layer(encoded)\n",
    "\n",
    "        decoded = self.decoder_embedding(decoder_input)\n",
    "        output = self.decoder_layer(decoded, initial_state=encoded_source)\n",
    "        output = self.dropout(output)\n",
    "        output = self.dense(output)\n",
    "        try:\n",
    "            # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "            # b/250038731\n",
    "            del output._keras_mask\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        This method is used to save a model into a file.\n",
    "        \"\"\"\n",
    "        config = super(Seq2SeqModel, self).get_config().copy()\n",
    "        config.update({\n",
    "            \"encoder_tokenizer\": self.encoder_tokenizer.get_config(),\n",
    "            \"decoder_tokenizer\": self.decoder_tokenizer.get_config(),\n",
    "            \"dropout\" : self.dropout,\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"encoder_vocabulary_size\": self.encoder_embedding.input_dim,\n",
    "            \"decoder_vocabulary_size\": self.decoder_embedding.input_dim,\n",
    "            \"embedding_dim\": self.encoder_embedding.output_dim,\n",
    "            \"mask_zero\": self.mask_zero,\n",
    "        })\n",
    "        return config\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        \"\"\"\n",
    "        This method is used to build a model from a saved file.\n",
    "        \"\"\"\n",
    "        encoder_tokenizer_config = config.pop(\"encoder_tokenizer\")\n",
    "        decoder_tokenizer_config = config.pop(\"decoder_tokenizer\")\n",
    "        encoder_tokenizer = keras.layers.TextVectorization.from_config(encoder_tokenizer_config)\n",
    "        decoder_tokenizer = keras.layers.TextVectorization.from_config(decoder_tokenizer_config)\n",
    "        return cls(\n",
    "            encoder_tokenizer=encoder_tokenizer,\n",
    "            decoder_tokenizer=decoder_tokenizer,\n",
    "            **config\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(\n",
    "        input_sentence,\n",
    "        model,\n",
    "        max_sequence_length,\n",
    "        lookup_table):\n",
    "    \"\"\"\n",
    "    Generate summarized text from the input sentence.\n",
    "    :input_sentence: the original text that is summarized\n",
    "    :model: the Seq2SeqModel class model\n",
    "    :max_sequence_length: the maximum length of the summarized text\n",
    "    :lookup_table: the table holds token IDs and their actual words\n",
    "    \"\"\"\n",
    "    encoder_tokenizer = model.encoder_tokenizer\n",
    "    decoder_tokenizer = model.decoder_tokenizer\n",
    "    tokenized_input = encoder_tokenizer([input_sentence])\n",
    "\n",
    "    start_token = decoder_tokenizer(\"[start]\")[0].numpy()\n",
    "    end_token = decoder_tokenizer(\"[end]\")[0].numpy()\n",
    "\n",
    "    decoded_sentence = [start_token]\n",
    "    for i in range(max_sequence_length):\n",
    "        decoder_inputs = tf.convert_to_tensor(\n",
    "            [decoded_sentence],\n",
    "            dtype=\"int64\",\n",
    "        )\n",
    "        decoder_inputs = tf.concat(\n",
    "            [\n",
    "                decoder_inputs,\n",
    "                tf.zeros(\n",
    "                    [1, max_sequence_length - i - 1],\n",
    "                    dtype=\"int64\",\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        input = (\n",
    "            tokenized_input,\n",
    "            decoder_inputs,\n",
    "        )\n",
    "        predictions = model(input)\n",
    "        predicted_token = np.argmax(predictions[0, i, :])\n",
    "        decoded_sentence.append(predicted_token)\n",
    "        if predicted_token == end_token:\n",
    "            break\n",
    "\n",
    "    detokenized_output = []\n",
    "    for token in decoded_sentence:\n",
    "        detokenized_output.append(lookup_table[token])\n",
    "    return \" \".join(detokenized_output)\n",
    "\n",
    "\n",
    "def predict_main(\n",
    "        filepath,\n",
    "        examples,\n",
    "        decoder_sequence_length):\n",
    "    \"\"\"\n",
    "    Generate summarized text with the model file.\n",
    "    :filepath: the file path specifies the model\n",
    "    :examples: the list of text that is summarized.\n",
    "    :decoder_sequence_length: the maximum length of the summarized text.\n",
    "    \"\"\"\n",
    "    loaded_model = keras.models.load_model(\n",
    "        filepath,\n",
    "        # Just in case, Seq2SeqModel is specified.\n",
    "        # However, it does not seem necessary.\n",
    "        custom_objects={\n",
    "            \"Seq2SeqModel\": Seq2SeqModel,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    decoder_tokenizer = loaded_model.decoder_tokenizer\n",
    "    vocab = decoder_tokenizer.get_vocabulary()\n",
    "    index_lookup_table = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "    summarized = []\n",
    "    for example in examples:\n",
    "        summarized.append(\n",
    "            decode_sequence(\n",
    "                example,\n",
    "                loaded_model,\n",
    "                decoder_sequence_length,\n",
    "                index_lookup_table,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        print(\"ORIGINAL SENTENCE: \", examples[i])\n",
    "        print(\"SUMMARIZED RESULT: \", summarized[i])\n",
    "\n",
    "def predict_model(\n",
    "        model,\n",
    "        examples,\n",
    "        decoder_sequence_length):\n",
    "    \"\"\"\n",
    "    Generate summarized text with the model.\n",
    "    :model: the file path specifies the model\n",
    "    :examples: the list of text that is summarized.\n",
    "    :decoder_sequence_length: the maximum length of the summarized text.\n",
    "    \"\"\"\n",
    "    decoder_tokenizer = model.decoder_tokenizer\n",
    "    vocab = decoder_tokenizer.get_vocabulary()\n",
    "    index_lookup_table = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "    summarized = []\n",
    "    for example in examples:\n",
    "        summarized.append(\n",
    "            decode_sequence(\n",
    "                example,\n",
    "                model,\n",
    "                decoder_sequence_length,\n",
    "                index_lookup_table,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        print(\"ORIGINAL SENTENCE: \", examples[i])\n",
    "        print(\"SUMMARIZED RESULT: \", summarized[i])\n",
    "\n",
    "def predict_dataset(\n",
    "        model,\n",
    "        iterable_dataset,\n",
    "        decoder_sequence_length):\n",
    "    \"\"\"\n",
    "    Generate summarized text with the model.\n",
    "    :model: the file path specifies the model\n",
    "    :iterable_dataset: the dataset, which is mainly test set, used to generate summarized text.\n",
    "    :decoder_sequence_length: the maximum length of the summarized text.\n",
    "    \"\"\"\n",
    "    decoder_tokenizer = model.decoder_tokenizer\n",
    "    vocab = decoder_tokenizer.get_vocabulary()\n",
    "    index_lookup_table = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    for entry in iterable_dataset:\n",
    "        text = entry[\"dialogue\"]\n",
    "        result = decode_sequence(\n",
    "            text,\n",
    "            model,\n",
    "            decoder_sequence_length,\n",
    "            index_lookup_table,\n",
    "        )\n",
    "        y_true = entry[\"summary\"]\n",
    "        y_true = y_true.decode('utf-8').lower()\n",
    "        y_pred = result.replace('[start]', '').replace('[end]', '').strip()\n",
    "        # print(y_true, '\\n\\t' , y_pred)\n",
    "        y_trues.append(y_true)\n",
    "        y_preds.append(y_pred)\n",
    "    return y_trues, y_preds\n",
    "\n",
    "def calculate_rouge_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    # RougeN metric\n",
    "    # @see https://keras.io/api/keras_nlp/metrics/rouge_n/\n",
    "    \"\"\"\n",
    "    rouge_n = keras_nlp.metrics.RougeN(order=2)\n",
    "    rouge_2_score = rouge_n(y_true, y_pred)\n",
    "    rouge_n = keras_nlp.metrics.RougeN(order=1)\n",
    "    rouge_1_score = rouge_n(y_true, y_pred)\n",
    "    rouge_l = keras_nlp.metrics.RougeL()\n",
    "    rouge_l_score = rouge_l(y_true, y_pred)\n",
    "    return rouge_1_score, rouge_2_score, rouge_l_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "        model,\n",
    "        train_ds,\n",
    "        validation_ds,\n",
    "        optimizer,\n",
    "        epochs,\n",
    "        steps_per_epoch,\n",
    "        now,\n",
    "        verbose,\n",
    "        callbacks=[]):\n",
    "    \"\"\"\n",
    "    Run training.\n",
    "    :train_ds: training set\n",
    "    :validation_ds: validation set\n",
    "    :optimizer: optimizer.Optimizer\n",
    "    :epochs: the number of epochs\n",
    "    :steps_per_epoch: the number of weight updates in a epoch\n",
    "    :now: timestamp\n",
    "    \"\"\"\n",
    "    metrics = [\n",
    "        masked_acc,\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "        loss=masked_loss,\n",
    "        weighted_metrics=[],\n",
    "    )\n",
    "    callbacks.append(get_tensorboard_callback(now=now))\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_ds,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "        train_ds, validation_ds, test_ds,\n",
    "        vectorization_layer,\n",
    "        dropout,\n",
    "        latent_dim,\n",
    "        encoder_sequence_length,\n",
    "        decoder_sequence_length,\n",
    "        vocab_size,\n",
    "        batch_size,\n",
    "        embedding_dim,\n",
    "        mask_zero,\n",
    "        optimizer,\n",
    "        epochs,\n",
    "        steps_per_epoch,\n",
    "        verbose=1,\n",
    "        callbacks=[]):\n",
    "    \"\"\"\n",
    "    Build the model with specified parameters.\n",
    "    :return: model: trained model\n",
    "    :return: filepath: model file path if it is saved\n",
    "    :return: history: history object to plot\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    if DEBUGGER_V2:\n",
    "        tf.debugging.experimental.enable_dump_debug_info(\n",
    "            get_log_dir(now=now),\n",
    "            tensor_debug_mode=\"FULL_HEALTH\",\n",
    "            circular_buffer_size=-1\n",
    "        )\n",
    "    input_vectorization_layer, target_vectorization_layer = prepare_tokenizer(\n",
    "        vectorization_layer=vectorization_layer,\n",
    "        encoder_sequence_length=encoder_sequence_length,\n",
    "        decoder_sequence_length=decoder_sequence_length,\n",
    "        max_tokens=vocab_size,\n",
    "    )\n",
    "    train_ds, validation_ds, test_ds = build_datasets(\n",
    "        train_ds=train_ds,\n",
    "        validation_ds=validation_ds,\n",
    "        test_ds=test_ds,\n",
    "        vectorization_layer=vectorization_layer,\n",
    "        batch_size=batch_size,\n",
    "        encoder_sequence_length=encoder_sequence_length,\n",
    "        decoder_sequence_length=decoder_sequence_length,\n",
    "    )\n",
    "\n",
    "    input_vocab_size = input_vectorization_layer.vocabulary_size()\n",
    "    target_vocab_size = target_vectorization_layer.vocabulary_size()\n",
    "\n",
    "    model = Seq2SeqModel(\n",
    "        encoder_tokenizer=input_vectorization_layer,\n",
    "        decoder_tokenizer=target_vectorization_layer,\n",
    "        dropout=dropout,\n",
    "        latent_dim=latent_dim,\n",
    "        encoder_vocabulary_size=input_vocab_size,\n",
    "        decoder_vocabulary_size=target_vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        mask_zero=mask_zero,\n",
    "        encoder_sequence_length=encoder_sequence_length,\n",
    "        decoder_sequence_length=decoder_sequence_length,\n",
    "    )\n",
    "    # # This should be called seemingly.\n",
    "    # model.build(\n",
    "    #     input_shape=(\n",
    "    #         (None, encoder_sequence_length),\n",
    "    #         (None, decoder_sequence_length)\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    history = run_training(\n",
    "        model,\n",
    "        train_ds=train_ds,\n",
    "        validation_ds=validation_ds,\n",
    "        optimizer=optimizer,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        now=now,\n",
    "        verbose=verbose,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    timestamp = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    if is_running_on_apple_silicon() or is_running_on_intel_mac():\n",
    "        filepath = f'model/summarization_model_{timestamp}.keras'\n",
    "    else:\n",
    "        filepath = f'summarization_model_{timestamp}.keras'\n",
    "    print(f\"Saving to {filepath}\")\n",
    "    model.save(filepath=filepath)\n",
    "\n",
    "    print(f\"Successfully saved model to {filepath}\")\n",
    "    return model, filepath, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size | CPU | GPU\n",
    "--- | --- | ---\n",
    "--- | 7m52s | > 25m\n",
    "32 | 1m41s | 2m26s\n",
    "64 | 1m37s | 2m5s\n",
    "128 | 1m37s | 1m49s\n",
    "256 | 1m31s | 1m40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-17 02:26:35.690799: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-08-17 02:26:35.690819: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-08-17 02:26:35.690823: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-08-17 02:26:35.690837: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-17 02:26:35.690850: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-08-17 02:26:36.629353: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ADAPT_BATCH_SIZE = 256\n",
    "\n",
    "train_ds, validation_ds, test_ds = prepare_datasets()\n",
    "vectorization_layer = keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    # max_tokens=VOCABULARY_SIZE,\n",
    "    output_mode='int',\n",
    "    ragged=True,\n",
    ")\n",
    "vectorization_layer.adapt(\n",
    "    train_ds.batch(ADAPT_BATCH_SIZE).map(\n",
    "        lambda row: '[start] ' + row['summary'] + ' ' + row['dialogue'] + ' [end]',\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    ),\n",
    "    batch_size=ADAPT_BATCH_SIZE,\n",
    ")\n",
    "# Use the maximum size of the dataset. 31907\n",
    "VOCABULARY_SIZE = len(vectorization_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitsuaki.ishimoto/.pyenv/versions/3.10.11/lib/python3.10/site-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'seq2_seq_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "2024-08-17 02:26:38.816464: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 841/3683\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:40\u001b[0m 78ms/step - loss: nan - masked_acc: 0.0028"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10 # 20 50\n",
    "STEPS_PER_EPOCH = None\n",
    "ENCODER_SEQUENCE_LENGTH = 128 # 128: 75% covered. max is 803.\n",
    "DECODER_SEQUENCE_LENGTH = 64 # 32: 75% covered. max is 64\n",
    "MASK_ZERO = True\n",
    "\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "model, filepath, history = build_model(\n",
    "    train_ds, validation_ds, test_ds,\n",
    "    vectorization_layer=vectorization_layer,\n",
    "    dropout=0.35,\n",
    "    latent_dim=512,\n",
    "    encoder_sequence_length=ENCODER_SEQUENCE_LENGTH,\n",
    "    decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCABULARY_SIZE,\n",
    "    batch_size=16,\n",
    "    embedding_dim=128,\n",
    "    mask_zero=MASK_ZERO,\n",
    "    optimizer=optimizer,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    callbacks=[reduce_lr_callbacks],\n",
    ")\n",
    "plot(history=history)\n",
    "\n",
    "# optimizer = keras.optimizers.AdamW(\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "# )\n",
    "# best_epoch = max(np.argmin(history.history[f\"val_loss\"]), np.argmax(history.history[f\"val_masked_acc\"]))\n",
    "# best_epoch = best_epoch + 1\n",
    "# print(\"best_epoch is\", best_epoch)\n",
    "# model, filepath, history = build_model(\n",
    "#     train_ds.concatenate(validation_ds), None, test_ds,\n",
    "#     vectorization_layer=vectorization_layer,\n",
    "#     dropout=0.35,\n",
    "#     latent_dim=512,\n",
    "#     encoder_sequence_length=ENCODER_SEQUENCE_LENGTH,\n",
    "#     decoder_sequence_length=DECODER_SEQUENCE_LENGTH,\n",
    "#     vocab_size=VOCABULARY_SIZE,\n",
    "#     batch_size=128,\n",
    "#     embedding_dim=128,\n",
    "#     mask_zero=MASK_ZERO,\n",
    "#     optimizer=optimizer,\n",
    "#     epochs=best_epoch,\n",
    "#     steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#     callbacks=[reduce_lr_callbacks],\n",
    "# )\n",
    "\n",
    "# y_true, y_pred = predict_dataset(\n",
    "#     model=model,\n",
    "#     iterable_dataset=tfds.as_numpy(test_ds), # The length of the test dataset is 819.\n",
    "#     decoder_sequence_length=DECODER_SEQUENCE_LENGTH\n",
    "# )\n",
    "# rouge_1_score, rouge_2_score, rouge_l_score = calculate_rouge_score(\n",
    "#     y_true=y_true,\n",
    "#     y_pred=y_pred\n",
    "# )\n",
    "# print(rouge_1_score)\n",
    "# print(rouge_2_score)\n",
    "# print(rouge_l_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '[UNK]',\n",
       " 2: 'i',\n",
       " 3: 'you',\n",
       " 4: 'the',\n",
       " 5: 'to',\n",
       " 6: 'it',\n",
       " 7: 'a',\n",
       " 8: 'and',\n",
       " 9: 's',\n",
       " 10: 'is',\n",
       " 11: 'for',\n",
       " 12: 't',\n",
       " 13: 'in',\n",
       " 14: 'that',\n",
       " 15: '[start]',\n",
       " 16: '[end]',\n",
       " 17: 'will',\n",
       " 18: 'of',\n",
       " 19: 'have',\n",
       " 20: 'but',\n",
       " 21: 'so',\n",
       " 22: 'we',\n",
       " 23: 'are',\n",
       " 24: 'be',\n",
       " 25: 'on',\n",
       " 26: 'at',\n",
       " 27: 'me',\n",
       " 28: 'what',\n",
       " 29: 'with',\n",
       " 30: 'can',\n",
       " 31: 'not',\n",
       " 32: 'he',\n",
       " 33: 'm',\n",
       " 34: 'my',\n",
       " 35: 'do',\n",
       " 36: 'know',\n",
       " 37: 'she',\n",
       " 38: 'was',\n",
       " 39: 'about',\n",
       " 40: 'they',\n",
       " 41: 'just',\n",
       " 42: 'this',\n",
       " 43: 'll',\n",
       " 44: 'no',\n",
       " 45: 'her',\n",
       " 46: 'there',\n",
       " 47: 'ok',\n",
       " 48: 'like',\n",
       " 49: 'don',\n",
       " 50: 'your',\n",
       " 51: 'go',\n",
       " 52: 'how',\n",
       " 53: 'some',\n",
       " 54: 'good',\n",
       " 55: 'going',\n",
       " 56: 'see',\n",
       " 57: 'if',\n",
       " 58: 'up',\n",
       " 59: 'time',\n",
       " 60: 'd',\n",
       " 61: 'think',\n",
       " 62: 'one',\n",
       " 63: 'as',\n",
       " 64: 'get',\n",
       " 65: 'yeah',\n",
       " 66: 'all',\n",
       " 67: 'yes',\n",
       " 68: 'sure',\n",
       " 69: 'from',\n",
       " 70: 're',\n",
       " 71: 'too',\n",
       " 72: 'has',\n",
       " 73: 'really',\n",
       " 74: 'well',\n",
       " 75: 'now',\n",
       " 76: 'him',\n",
       " 77: 'out',\n",
       " 78: 'his',\n",
       " 79: 'when',\n",
       " 80: 'come',\n",
       " 81: 'did',\n",
       " 82: 'need',\n",
       " 83: 'want',\n",
       " 84: 'would',\n",
       " 85: 'or',\n",
       " 86: 'then',\n",
       " 87: 'thanks',\n",
       " 88: 'oh',\n",
       " 89: 'them',\n",
       " 90: 'an',\n",
       " 91: 'new',\n",
       " 92: 'got',\n",
       " 93: 'should',\n",
       " 94: 'why',\n",
       " 95: 'work',\n",
       " 96: 'tom',\n",
       " 97: 'tomorrow',\n",
       " 98: 'right',\n",
       " 99: 've',\n",
       " 100: 'let',\n",
       " 101: 'u',\n",
       " 102: 'great',\n",
       " 103: 'much',\n",
       " 104: 'back',\n",
       " 105: 'take',\n",
       " 106: 'maybe',\n",
       " 107: 'john',\n",
       " 108: 'today',\n",
       " 109: 'been',\n",
       " 110: 'something',\n",
       " 111: 'had',\n",
       " 112: 'hey',\n",
       " 113: 'home',\n",
       " 114: 'am',\n",
       " 115: 'more',\n",
       " 116: 'hi',\n",
       " 117: 'meet',\n",
       " 118: 'could',\n",
       " 119: 'next',\n",
       " 120: 'still',\n",
       " 121: 'very',\n",
       " 122: 'last',\n",
       " 123: 'sorry',\n",
       " 124: 'any',\n",
       " 125: 'where',\n",
       " 126: 'kate',\n",
       " 127: 'after',\n",
       " 128: 'because',\n",
       " 129: 'by',\n",
       " 130: 'make',\n",
       " 131: 'here',\n",
       " 132: 'peter',\n",
       " 133: 'love',\n",
       " 134: 'lol',\n",
       " 135: 'didn',\n",
       " 136: 'us',\n",
       " 137: 'week',\n",
       " 138: 'place',\n",
       " 139: 'nice',\n",
       " 140: 'mary',\n",
       " 141: 'mike',\n",
       " 142: '3',\n",
       " 143: 'day',\n",
       " 144: 'buy',\n",
       " 145: 'way',\n",
       " 146: 'who',\n",
       " 147: 'were',\n",
       " 148: 'people',\n",
       " 149: 'anna',\n",
       " 150: 'only',\n",
       " 151: 'tell',\n",
       " 152: 'wants',\n",
       " 153: 'our',\n",
       " 154: 'help',\n",
       " 155: 'better',\n",
       " 156: 'talk',\n",
       " 157: 'coming',\n",
       " 158: 'p',\n",
       " 159: 'thank',\n",
       " 160: 'doesn',\n",
       " 161: 'mark',\n",
       " 162: 'already',\n",
       " 163: 'even',\n",
       " 164: 'anything',\n",
       " 165: 'look',\n",
       " 166: 'tonight',\n",
       " 167: 'give',\n",
       " 168: 'always',\n",
       " 169: 'call',\n",
       " 170: 'say',\n",
       " 171: 'jack',\n",
       " 172: 'guys',\n",
       " 173: 'party',\n",
       " 174: 'haha',\n",
       " 175: 'won',\n",
       " 176: 'over',\n",
       " 177: 'fine',\n",
       " 178: 'also',\n",
       " 179: 'try',\n",
       " 180: '2',\n",
       " 181: 'other',\n",
       " 182: 'please',\n",
       " 183: 'again',\n",
       " 184: 'wait',\n",
       " 185: 'paul',\n",
       " 186: 'idea',\n",
       " 187: 'sam',\n",
       " 188: 'year',\n",
       " 189: 'find',\n",
       " 190: 'cool',\n",
       " 191: 'their',\n",
       " 192: 'lot',\n",
       " 193: 'ask',\n",
       " 194: 'chris',\n",
       " 195: 'jane',\n",
       " 196: 'alex',\n",
       " 197: 'first',\n",
       " 198: 'before',\n",
       " 199: 'around',\n",
       " 200: 'bit',\n",
       " 201: 'mean',\n",
       " 202: 'problem',\n",
       " 203: 'hope',\n",
       " 204: 'night',\n",
       " 205: '5',\n",
       " 206: 'xd',\n",
       " 207: 'guess',\n",
       " 208: 'course',\n",
       " 209: 'yet',\n",
       " 210: 'okay',\n",
       " 211: 'which',\n",
       " 212: 'thought',\n",
       " 213: 'send',\n",
       " 214: 'bring',\n",
       " 215: 'soon',\n",
       " 216: 'later',\n",
       " 217: 'off',\n",
       " 218: 'ben',\n",
       " 219: 'than',\n",
       " 220: 'doing',\n",
       " 221: 'adam',\n",
       " 222: 'car',\n",
       " 223: 'never',\n",
       " 224: 'meeting',\n",
       " 225: 'long',\n",
       " 226: 'bad',\n",
       " 227: 'weekend',\n",
       " 228: 'sounds',\n",
       " 229: 'check',\n",
       " 230: 'tim',\n",
       " 231: 'two',\n",
       " 232: 'mom',\n",
       " 233: 'feel',\n",
       " 234: 'job',\n",
       " 235: 'same',\n",
       " 236: 'sarah',\n",
       " 237: 'happy',\n",
       " 238: 'everything',\n",
       " 239: 'remember',\n",
       " 240: 'best',\n",
       " 241: 'may',\n",
       " 242: 'ann',\n",
       " 243: 'james',\n",
       " 244: 'late',\n",
       " 245: 'looking',\n",
       " 246: 'told',\n",
       " 247: 'seen',\n",
       " 248: '30',\n",
       " 249: 'jake',\n",
       " 250: 'might',\n",
       " 251: 'does',\n",
       " 252: 'emma',\n",
       " 253: 'matt',\n",
       " 254: 'thing',\n",
       " 255: 'david',\n",
       " 256: 'gonna',\n",
       " 257: 'jim',\n",
       " 258: 'days',\n",
       " 259: 'pick',\n",
       " 260: 'stay',\n",
       " 261: 'nothing',\n",
       " 262: 'actually',\n",
       " 263: '10',\n",
       " 264: 'man',\n",
       " 265: 'morning',\n",
       " 266: 'friday',\n",
       " 267: 'went',\n",
       " 268: 'its',\n",
       " 269: 'monica',\n",
       " 270: 'school',\n",
       " 271: 'dad',\n",
       " 272: 'little',\n",
       " 273: 'yesterday',\n",
       " 274: 'though',\n",
       " 275: 'said',\n",
       " 276: 'harry',\n",
       " 277: 'minutes',\n",
       " 278: 'probably',\n",
       " 279: 'together',\n",
       " 280: 'martha',\n",
       " 281: 'george',\n",
       " 282: 'alice',\n",
       " 283: 'josh',\n",
       " 284: 'emily',\n",
       " 285: 'daniel',\n",
       " 286: 'watch',\n",
       " 287: 'things',\n",
       " 288: 'jenny',\n",
       " 289: 'wanna',\n",
       " 290: 'greg',\n",
       " 291: 'i’m',\n",
       " 292: '4',\n",
       " 293: 'laura',\n",
       " 294: 'few',\n",
       " 295: 'andy',\n",
       " 296: 'old',\n",
       " 297: 'waiting',\n",
       " 298: 'getting',\n",
       " 299: 'needs',\n",
       " 300: 'wanted',\n",
       " 301: 'frank',\n",
       " 302: 'money',\n",
       " 303: 'done',\n",
       " 304: 'quite',\n",
       " 305: 'join',\n",
       " 306: 'lucy',\n",
       " 307: 'pm',\n",
       " 308: 'dinner',\n",
       " 309: 'saturday',\n",
       " 310: 'linda',\n",
       " 311: 'left',\n",
       " 312: 'heard',\n",
       " 313: 'birthday',\n",
       " 314: '7',\n",
       " 315: 'lisa',\n",
       " 316: 'joe',\n",
       " 317: 'working',\n",
       " 318: 'thinking',\n",
       " 319: 'mia',\n",
       " 320: 'many',\n",
       " 321: 'book',\n",
       " 322: 'maria',\n",
       " 323: 'care',\n",
       " 324: '6',\n",
       " 325: 'mum',\n",
       " 326: 'olivia',\n",
       " 327: 'free',\n",
       " 328: 'luke',\n",
       " 329: 'max',\n",
       " 330: 'down',\n",
       " 331: 'house',\n",
       " 332: 'happened',\n",
       " 333: 'julia',\n",
       " 334: 'exactly',\n",
       " 335: 'fun',\n",
       " 336: 'stuff',\n",
       " 337: 'haven',\n",
       " 338: 'start',\n",
       " 339: 'anyway',\n",
       " 340: 'steve',\n",
       " 341: 'im',\n",
       " 342: 'friends',\n",
       " 343: 'henry',\n",
       " 344: 'pretty',\n",
       " 345: 'rob',\n",
       " 346: 'looks',\n",
       " 347: 'leave',\n",
       " 348: 'hello',\n",
       " 349: 'perfect',\n",
       " 350: 'jacob',\n",
       " 351: 'it’s',\n",
       " 352: 'christmas',\n",
       " 353: 'someone',\n",
       " 354: 'busy',\n",
       " 355: 'sue',\n",
       " 356: 'michael',\n",
       " 357: 'kelly',\n",
       " 358: 'food',\n",
       " 359: 'keep',\n",
       " 360: 'big',\n",
       " 361: 'true',\n",
       " 362: 'dan',\n",
       " 363: 'kim',\n",
       " 364: 'else',\n",
       " 365: '8',\n",
       " 366: 'amy',\n",
       " 367: 'found',\n",
       " 368: 'wow',\n",
       " 369: 'office',\n",
       " 370: 'visit',\n",
       " 371: 'such',\n",
       " 372: 'bill',\n",
       " 373: 'robert',\n",
       " 374: 'hour',\n",
       " 375: 'read',\n",
       " 376: 'another',\n",
       " 377: 'friend',\n",
       " 378: 'hahaha',\n",
       " 379: 'hear',\n",
       " 380: 'jeff',\n",
       " 381: 'helen',\n",
       " 382: 'andrew',\n",
       " 383: 'play',\n",
       " 384: 'having',\n",
       " 385: 'dont',\n",
       " 386: 'nick',\n",
       " 387: 'both',\n",
       " 388: 'susan',\n",
       " 389: 'phone',\n",
       " 390: 'bought',\n",
       " 391: 'worry',\n",
       " 392: 'karen',\n",
       " 393: 'hannah',\n",
       " 394: 'years',\n",
       " 395: 'eat',\n",
       " 396: 'guy',\n",
       " 397: 'made',\n",
       " 398: 'life',\n",
       " 399: 'evening',\n",
       " 400: 'don’t',\n",
       " 401: 'kevin',\n",
       " 402: 'kind',\n",
       " 403: 'away',\n",
       " 404: 'parents',\n",
       " 405: 'show',\n",
       " 406: 'into',\n",
       " 407: 'jason',\n",
       " 408: 'saw',\n",
       " 409: 'martin',\n",
       " 410: 'tina',\n",
       " 411: 'game',\n",
       " 412: 'girl',\n",
       " 413: 'forgot',\n",
       " 414: 'ago',\n",
       " 415: 'mind',\n",
       " 416: 'those',\n",
       " 417: 'these',\n",
       " 418: 'jessica',\n",
       " 419: 'end',\n",
       " 420: 'omg',\n",
       " 421: 'rachel',\n",
       " 422: 'everyone',\n",
       " 423: 'amanda',\n",
       " 424: 'sara',\n",
       " 425: 'must',\n",
       " 426: 'most',\n",
       " 427: 'kids',\n",
       " 428: 'dave',\n",
       " 429: 'believe',\n",
       " 430: 'ian',\n",
       " 431: 'anne',\n",
       " 432: 'enough',\n",
       " 433: 'room',\n",
       " 434: 'ready',\n",
       " 435: 'family',\n",
       " 436: 'stop',\n",
       " 437: 'nancy',\n",
       " 438: 'each',\n",
       " 439: 'month',\n",
       " 440: 'sent',\n",
       " 441: 'patrick',\n",
       " 442: 'pay',\n",
       " 443: 'movie',\n",
       " 444: 'sophie',\n",
       " 445: 'while',\n",
       " 446: 'eva',\n",
       " 447: 'trip',\n",
       " 448: 'amazing',\n",
       " 449: 'least',\n",
       " 450: 'bob',\n",
       " 451: 'every',\n",
       " 452: 'hours',\n",
       " 453: 'use',\n",
       " 454: 'tickets',\n",
       " 455: 'hard',\n",
       " 456: 'put',\n",
       " 457: 'shit',\n",
       " 458: 'seems',\n",
       " 459: 'o',\n",
       " 460: 'rose',\n",
       " 461: 'tony',\n",
       " 462: 'watching',\n",
       " 463: 'coffee',\n",
       " 464: 'paula',\n",
       " 465: 'change',\n",
       " 466: 'sick',\n",
       " 467: '1',\n",
       " 468: 'number',\n",
       " 469: 'being',\n",
       " 470: 'different',\n",
       " 471: 'gina',\n",
       " 472: 'thomas',\n",
       " 473: 'diana',\n",
       " 474: 'date',\n",
       " 475: 'yep',\n",
       " 476: 'weeks',\n",
       " 477: 'brian',\n",
       " 478: 'since',\n",
       " 479: 'lunch',\n",
       " 480: 'lucas',\n",
       " 481: 'victoria',\n",
       " 482: 'class',\n",
       " 483: 'isn',\n",
       " 484: 'anyone',\n",
       " 485: 'sally',\n",
       " 486: 'far',\n",
       " 487: 'eve',\n",
       " 488: 'shopping',\n",
       " 489: 'oscar',\n",
       " 490: 'charlie',\n",
       " 491: 'once',\n",
       " 492: 'whole',\n",
       " 493: 'eric',\n",
       " 494: 'patricia',\n",
       " 495: '15',\n",
       " 496: 'talking',\n",
       " 497: 'sandra',\n",
       " 498: 'plans',\n",
       " 499: 'took',\n",
       " 500: 'terry',\n",
       " 501: 'name',\n",
       " 502: 'awesome',\n",
       " 503: 'leo',\n",
       " 504: 'noah',\n",
       " 505: 'used',\n",
       " 506: 'liam',\n",
       " 507: 'called',\n",
       " 508: 'rick',\n",
       " 509: 'sth',\n",
       " 510: 'fred',\n",
       " 511: 'understand',\n",
       " 512: 'girls',\n",
       " 513: 'bye',\n",
       " 514: 'almost',\n",
       " 515: 'zoe',\n",
       " 516: 'ever',\n",
       " 517: 'fiona',\n",
       " 518: 'until',\n",
       " 519: 'miss',\n",
       " 520: 'chloe',\n",
       " 521: '20',\n",
       " 522: 'pizza',\n",
       " 523: 'fuck',\n",
       " 524: 'asked',\n",
       " 525: 'betty',\n",
       " 526: 'carol',\n",
       " 527: 'sunday',\n",
       " 528: 'ashley',\n",
       " 529: 'able',\n",
       " 530: 'wish',\n",
       " 531: 'hate',\n",
       " 532: 'drink',\n",
       " 533: 'without',\n",
       " 534: 'trying',\n",
       " 535: 'simon',\n",
       " 536: 'city',\n",
       " 537: 'grace',\n",
       " 538: 'pete',\n",
       " 539: 'sleep',\n",
       " 540: 'plan',\n",
       " 541: 'mr',\n",
       " 542: 'through',\n",
       " 543: 'project',\n",
       " 544: 'months',\n",
       " 545: 'couple',\n",
       " 546: 'taking',\n",
       " 547: 'order',\n",
       " 548: 'news',\n",
       " 549: 'definitely',\n",
       " 550: 'nina',\n",
       " 551: 'william',\n",
       " 552: 'funny',\n",
       " 553: 'megan',\n",
       " 554: 'luck',\n",
       " 555: 'ethan',\n",
       " 556: 'interesting',\n",
       " 557: 'claire',\n",
       " 558: 'write',\n",
       " 559: 'agnes',\n",
       " 560: 'wrong',\n",
       " 561: 'likes',\n",
       " 562: 'expensive',\n",
       " 563: 'agree',\n",
       " 564: 'dress',\n",
       " 565: 'monday',\n",
       " 566: 'charles',\n",
       " 567: 'wasn',\n",
       " 568: 'group',\n",
       " 569: 'leaving',\n",
       " 570: 'feeling',\n",
       " 571: 'own',\n",
       " 572: 'wendy',\n",
       " 573: 'supposed',\n",
       " 574: 'barbara',\n",
       " 575: 'wine',\n",
       " 576: 'thinks',\n",
       " 577: 'says',\n",
       " 578: 'lily',\n",
       " 579: 'alan',\n",
       " 580: 'ya',\n",
       " 581: 'started',\n",
       " 582: 'beer',\n",
       " 583: 'caroline',\n",
       " 584: 'text',\n",
       " 585: 'lost',\n",
       " 586: 'sean',\n",
       " 587: 'god',\n",
       " 588: 'maya',\n",
       " 589: 'met',\n",
       " 590: 'x',\n",
       " 591: 'jerry',\n",
       " 592: 'victor',\n",
       " 593: 'town',\n",
       " 594: 'planning',\n",
       " 595: 'mine',\n",
       " 596: 'donna',\n",
       " 597: 'baby',\n",
       " 598: 'part',\n",
       " 599: 'bus',\n",
       " 600: 'red',\n",
       " 601: 'myself',\n",
       " 602: 'i’ll',\n",
       " 603: 'samantha',\n",
       " 604: 'person',\n",
       " 605: 'afraid',\n",
       " 606: 'tired',\n",
       " 607: 'sister',\n",
       " 608: 'jay',\n",
       " 609: 'enjoy',\n",
       " 610: 'jennifer',\n",
       " 611: 'half',\n",
       " 612: 'during',\n",
       " 613: 'liz',\n",
       " 614: 'easy',\n",
       " 615: 'cannot',\n",
       " 616: 'natalie',\n",
       " 617: 'ava',\n",
       " 618: 'playing',\n",
       " 619: 'came',\n",
       " 620: 'tracy',\n",
       " 621: 'oliver',\n",
       " 622: 'train',\n",
       " 623: 'anymore',\n",
       " 624: 'ryan',\n",
       " 625: 'case',\n",
       " 626: 'ruth',\n",
       " 627: 'interested',\n",
       " 628: 'point',\n",
       " 629: 'julie',\n",
       " 630: 'tried',\n",
       " 631: 'early',\n",
       " 632: '9',\n",
       " 633: 'wouldn',\n",
       " 634: 'michelle',\n",
       " 635: 'mel',\n",
       " 636: 'lilly',\n",
       " 637: 'times',\n",
       " 638: 'joan',\n",
       " 639: 'test',\n",
       " 640: 'live',\n",
       " 641: 'glad',\n",
       " 642: 'hmm',\n",
       " 643: 'finally',\n",
       " 644: 'online',\n",
       " 645: 'nope',\n",
       " 646: 'couldn',\n",
       " 647: 'beautiful',\n",
       " 648: 'cold',\n",
       " 649: 'amelia',\n",
       " 650: 'works',\n",
       " 651: 'cause',\n",
       " 652: 'spend',\n",
       " 653: 'richard',\n",
       " 654: 'dog',\n",
       " 655: 'wedding',\n",
       " 656: 'maggie',\n",
       " 657: 'dear',\n",
       " 658: 'company',\n",
       " 659: 'beth',\n",
       " 660: 'jill',\n",
       " 661: 'brad',\n",
       " 662: 'molly',\n",
       " 663: 'asking',\n",
       " 664: 'rest',\n",
       " 665: 'drive',\n",
       " 666: 'alright',\n",
       " 667: 'phil',\n",
       " 668: 'pat',\n",
       " 669: 'marie',\n",
       " 670: 'mother',\n",
       " 671: 'shop',\n",
       " 672: 'serious',\n",
       " 673: 'crazy',\n",
       " 674: 'black',\n",
       " 675: 'bed',\n",
       " 676: 'logan',\n",
       " 677: 'broke',\n",
       " 678: 'afternoon',\n",
       " 679: 'dorothy',\n",
       " 680: 'abigail',\n",
       " 681: 'bro',\n",
       " 682: 'yourself',\n",
       " 683: 'till',\n",
       " 684: 'deal',\n",
       " 685: 'summer',\n",
       " 686: 'ella',\n",
       " 687: 'kyle',\n",
       " 688: 'jackie',\n",
       " 689: 'either',\n",
       " 690: 'classes',\n",
       " 691: 'thats',\n",
       " 692: 'making',\n",
       " 693: 'liked',\n",
       " 694: 'forget',\n",
       " 695: 'flight',\n",
       " 696: 'alone',\n",
       " 697: 'walk',\n",
       " 698: 'thx',\n",
       " 699: 'meg',\n",
       " 700: 'dude',\n",
       " 701: 'margaret',\n",
       " 702: 'june',\n",
       " 703: 'finish',\n",
       " 704: 'daisy',\n",
       " 705: 'angela',\n",
       " 706: 'thursday',\n",
       " 707: 'open',\n",
       " 708: 'larry',\n",
       " 709: 'concert',\n",
       " 710: 'boss',\n",
       " 711: 'second',\n",
       " 712: 'joseph',\n",
       " 713: 'exam',\n",
       " 714: 'tv',\n",
       " 715: 'move',\n",
       " 716: 'caron',\n",
       " 717: 'wear',\n",
       " 718: 'totally',\n",
       " 719: 'jimmy',\n",
       " 720: 'honey',\n",
       " 721: 'ha',\n",
       " 722: 'doctor',\n",
       " 723: '12',\n",
       " 724: 'weather',\n",
       " 725: 'lovely',\n",
       " 726: 'jo',\n",
       " 727: 'restaurant',\n",
       " 728: 'cinema',\n",
       " 729: 'ellie',\n",
       " 730: 'annie',\n",
       " 731: 'brother',\n",
       " 732: 'ted',\n",
       " 733: 'question',\n",
       " 734: 'mate',\n",
       " 735: 'important',\n",
       " 736: 'outside',\n",
       " 737: 'charlotte',\n",
       " 738: 'decided',\n",
       " 739: 'jamie',\n",
       " 740: 'hasn',\n",
       " 741: 'world',\n",
       " 742: 'photo',\n",
       " 743: 'available',\n",
       " 744: 'seriously',\n",
       " 745: 'jess',\n",
       " 746: 'gotta',\n",
       " 747: 'email',\n",
       " 748: 'nathan',\n",
       " 749: 'team',\n",
       " 750: 'somewhere',\n",
       " 751: 'prepare',\n",
       " 752: 'worries',\n",
       " 753: 'stupid',\n",
       " 754: 'gave',\n",
       " 755: 'possible',\n",
       " 756: 'ones',\n",
       " 757: 'instead',\n",
       " 758: 'wednesday',\n",
       " 759: 'talked',\n",
       " 760: 'problems',\n",
       " 761: 'moment',\n",
       " 762: 'cat',\n",
       " 763: 'gary',\n",
       " 764: 'makes',\n",
       " 765: 'y',\n",
       " 766: 'sometimes',\n",
       " 767: 'ron',\n",
       " 768: 'patty',\n",
       " 769: 'station',\n",
       " 770: 'music',\n",
       " 771: 'cute',\n",
       " 772: 'break',\n",
       " 773: 'front',\n",
       " 774: 'ur',\n",
       " 775: 'small',\n",
       " 776: 'poor',\n",
       " 777: 'less',\n",
       " 778: 'joanna',\n",
       " 779: 'jen',\n",
       " 780: 'vicky',\n",
       " 781: 'recently',\n",
       " 782: 'rather',\n",
       " 783: 'hair',\n",
       " 784: 'melissa',\n",
       " 785: 'ill',\n",
       " 786: 'xx',\n",
       " 787: 'knows',\n",
       " 788: 'hell',\n",
       " 789: 'gift',\n",
       " 790: 'aaron',\n",
       " 791: 'video',\n",
       " 792: 'that’s',\n",
       " 793: 'whatever',\n",
       " 794: 'ruby',\n",
       " 795: 'high',\n",
       " 796: 'yea',\n",
       " 797: 'tuesday',\n",
       " 798: 'sweet',\n",
       " 799: 'set',\n",
       " 800: 'english',\n",
       " 801: 'damn',\n",
       " 802: 'finished',\n",
       " 803: 'yup',\n",
       " 804: 'tommy',\n",
       " 805: 'photos',\n",
       " 806: 'matthew',\n",
       " 807: 'gets',\n",
       " 808: 'choose',\n",
       " 809: 'games',\n",
       " 810: 'special',\n",
       " 811: 'season',\n",
       " 812: 'real',\n",
       " 813: 'close',\n",
       " 814: 'buying',\n",
       " 815: 'jeremy',\n",
       " 816: 'taylor',\n",
       " 817: 'worried',\n",
       " 818: 'owen',\n",
       " 819: 'holly',\n",
       " 820: 'becky',\n",
       " 821: 'welcome',\n",
       " 822: 'offer',\n",
       " 823: 'nicole',\n",
       " 824: 'books',\n",
       " 825: 'weird',\n",
       " 826: 'ideas',\n",
       " 827: 'hotel',\n",
       " 828: 'amber',\n",
       " 829: 'gym',\n",
       " 830: 'cindy',\n",
       " 831: 'invited',\n",
       " 832: 'details',\n",
       " 833: 'brenda',\n",
       " 834: 'listen',\n",
       " 835: 'earlier',\n",
       " 836: 'three',\n",
       " 837: 'danny',\n",
       " 838: 'apartment',\n",
       " 839: 'saying',\n",
       " 840: 'longer',\n",
       " 841: 'you’re',\n",
       " 842: 'water',\n",
       " 843: 'ken',\n",
       " 844: 'happen',\n",
       " 845: 'dylan',\n",
       " 846: 'carl',\n",
       " 847: 'r',\n",
       " 848: 'lee',\n",
       " 849: 'difficult',\n",
       " 850: 'can’t',\n",
       " 851: 'veronica',\n",
       " 852: 'prefer',\n",
       " 853: 'cant',\n",
       " 854: 'pictures',\n",
       " 855: 'watched',\n",
       " 856: 'song',\n",
       " 857: 'excited',\n",
       " 858: 'drunk',\n",
       " 859: 'business',\n",
       " 860: 'bet',\n",
       " 861: 'bella',\n",
       " 862: 'trevor',\n",
       " 863: 'mandy',\n",
       " 864: 'flat',\n",
       " 865: 'katie',\n",
       " 866: 'suggests',\n",
       " 867: 'near',\n",
       " 868: 'imagine',\n",
       " 869: 'series',\n",
       " 870: 'missed',\n",
       " 871: 'london',\n",
       " 872: 'goes',\n",
       " 873: 'cook',\n",
       " 874: 'boyfriend',\n",
       " 875: 'staying',\n",
       " 876: 'picture',\n",
       " 877: 'contact',\n",
       " 878: 'cheap',\n",
       " 879: 'borrow',\n",
       " 880: 'list',\n",
       " 881: 'usual',\n",
       " 882: 'toby',\n",
       " 883: 'street',\n",
       " 884: 'derek',\n",
       " 885: 'store',\n",
       " 886: 'steven',\n",
       " 887: 'sophia',\n",
       " 888: 'boring',\n",
       " 889: 'seeing',\n",
       " 890: 'pub',\n",
       " 891: 'hospital',\n",
       " 892: 'children',\n",
       " 893: 'between',\n",
       " 894: 'audrey',\n",
       " 895: 'white',\n",
       " 896: 'teacher',\n",
       " 897: 'holiday',\n",
       " 898: 'comes',\n",
       " 899: 'catch',\n",
       " 900: 'angry',\n",
       " 901: 'andrea',\n",
       " 902: 'justin',\n",
       " 903: 'club',\n",
       " 904: 'super',\n",
       " 905: 'sad',\n",
       " 906: 'decide',\n",
       " 907: 'ralph',\n",
       " 908: 'knew',\n",
       " 909: 'feels',\n",
       " 910: 'post',\n",
       " 911: 'paid',\n",
       " 912: 'louise',\n",
       " 913: 'account',\n",
       " 914: 'girlfriend',\n",
       " 915: 'etc',\n",
       " 916: 'chance',\n",
       " 917: 'ah',\n",
       " 918: 'running',\n",
       " 919: 'message',\n",
       " 920: 'head',\n",
       " 921: 'especially',\n",
       " 922: '11',\n",
       " 923: 'xxx',\n",
       " 924: 'drinks',\n",
       " 925: 'recommend',\n",
       " 926: 'pass',\n",
       " 927: 'blue',\n",
       " 928: 'bar',\n",
       " 929: 'neither',\n",
       " 930: 'turn',\n",
       " 931: 'present',\n",
       " 932: 'worse',\n",
       " 933: 'share',\n",
       " 934: 'invite',\n",
       " 935: 'indeed',\n",
       " 936: 'cake',\n",
       " 937: 'sylvia',\n",
       " 938: 'jean',\n",
       " 939: 'door',\n",
       " 940: 'blake',\n",
       " 941: 'sound',\n",
       " 942: 'reading',\n",
       " 943: 'leah',\n",
       " 944: 'hugh',\n",
       " 945: 'gone',\n",
       " 946: 'fucking',\n",
       " 947: 'arrive',\n",
       " 948: 'safe',\n",
       " 949: 'lena',\n",
       " 950: 'kidding',\n",
       " 951: 'facebook',\n",
       " 952: 'ellen',\n",
       " 953: 'driving',\n",
       " 954: 'notes',\n",
       " 955: 'married',\n",
       " 956: 'clothes',\n",
       " 957: 'dean',\n",
       " 958: 'bored',\n",
       " 959: 'pam',\n",
       " 960: 'kinda',\n",
       " 961: 'usually',\n",
       " 962: 'study',\n",
       " 963: 'rebecca',\n",
       " 964: 'park',\n",
       " 965: 'lots',\n",
       " 966: 'hot',\n",
       " 967: 'evan',\n",
       " 968: 'clara',\n",
       " 969: 'c',\n",
       " 970: 'run',\n",
       " 971: 'price',\n",
       " 972: 'netflix',\n",
       " 973: 'k',\n",
       " 974: 'forward',\n",
       " 975: 'bobby',\n",
       " 976: 'stanley',\n",
       " 977: 'miranda',\n",
       " 978: 'surprise',\n",
       " 979: 'rory',\n",
       " 980: 'booked',\n",
       " 981: 'bart',\n",
       " 982: 'babe',\n",
       " 983: 'scott',\n",
       " 984: 'mason',\n",
       " 985: 'lucky',\n",
       " 986: 'internet',\n",
       " 987: 'full',\n",
       " 988: 'card',\n",
       " 989: 'stuck',\n",
       " 990: 'lola',\n",
       " 991: 'advice',\n",
       " 992: 'worth',\n",
       " 993: 'samuel',\n",
       " 994: 'others',\n",
       " 995: 'father',\n",
       " 996: '😊',\n",
       " 997: 'min',\n",
       " 998: 'janet',\n",
       " 999: 'freddie',\n",
       " ...}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_tokenizer = model.decoder_tokenizer\n",
    "vocab = decoder_tokenizer.get_vocabulary()\n",
    "index_lookup_table = dict(zip(range(len(vocab)), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] the team is in the office [end]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(\n",
    "    input_sentence=\"Edward: Rachel, I think I'm in ove with Bella.. rachel: Dont say anything else.. Edward: What do you mean?? rachel: Open your fu**ing door.. I'm outside\",\n",
    "    model=model,\n",
    "    lookup_table=index_lookup_table,\n",
    "    max_sequence_length=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
